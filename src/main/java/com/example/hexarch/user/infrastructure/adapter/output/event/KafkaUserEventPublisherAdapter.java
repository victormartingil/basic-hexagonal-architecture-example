package com.example.hexarch.user.infrastructure.adapter.output.event;

import com.example.hexarch.user.application.port.output.UserEventPublisher;
import com.example.hexarch.user.domain.event.UserCreatedEvent;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Component;

import java.util.concurrent.CompletableFuture;

/**
 * INFRASTRUCTURE LAYER - Kafka Event Publisher Adapter (Output Adapter)
 *
 * Adaptador que publica eventos de dominio a Kafka como INTEGRATION EVENTS.
 * Permite comunicaciÃ³n asÃ­ncrona con otros microservicios.
 *
 * Â¿QUÃ‰ SON INTEGRATION EVENTS?
 * - Eventos publicados a un message broker (Kafka, RabbitMQ, etc.)
 * - Permiten comunicaciÃ³n ENTRE MICROSERVICIOS diferentes
 * - Persisten en disco (durables, no se pierden si la app se cae)
 * - Pueden ser reprocessados (replay)
 *
 * DIFERENCIA CON DOMAIN EVENTS (Spring Events):
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ Domain Events (SpringEventUserEventPublisherAdapter)            â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ âœ… In-memory (rÃ¡pido)                                            â”‚
 * â”‚ âœ… Mismo servicio (JVM)                                          â”‚
 * â”‚ âŒ No duradero (se pierde si app cae)                           â”‚
 * â”‚ âŒ No funciona entre microservicios                             â”‚
 * â”‚                                                                  â”‚
 * â”‚ Ejemplo: SendWelcomeEmailListener (mismo servicio)              â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ Integration Events (ESTA CLASE - KafkaUserEventPublisherAdapter)â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ âœ… Duradero (persiste en Kafka)                                  â”‚
 * â”‚ âœ… Entre microservicios                                          â”‚
 * â”‚ âœ… Escalable (mÃºltiples consumers)                              â”‚
 * â”‚ âœ… Replay posible (volver a procesar)                           â”‚
 * â”‚ âŒ MÃ¡s complejo (infraestructura)                               â”‚
 * â”‚ âŒ Latencia mayor que in-memory                                 â”‚
 * â”‚                                                                  â”‚
 * â”‚ Ejemplo: UserEventsKafkaConsumer (otro microservicio)           â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * TOPICS Y NAMING:
 * - Usa dotted notation: "user.created", "order.placed"
 * - MÃ¡s comÃºn en la industria
 * - TambiÃ©n vÃ¡lido: "user-created" (hyphenated)
 *
 * KEYS Y PARTICIONES:
 * - Key = userId: Todos los eventos del mismo usuario van a la misma particiÃ³n
 * - Garantiza ORDEN para eventos del mismo usuario
 * - Sin key: eventos se distribuyen aleatoriamente (sin garantÃ­a de orden)
 *
 * EJEMPLO:
 * {@code
 * // Con key (userId)
 * kafkaTemplate.send("user.created", userId, event);
 *
 * // Resultado: Orden garantizado para el mismo user
 * Partition 0: UserCreated(user=123) â†’ UserUpdated(user=123) â†’ UserDeleted(user=123)
 *              â†‘ Todos en orden porque tienen la misma key
 * }
 *
 * SIN @Primary:
 * Esta clase NO tiene @Primary, asÃ­ que NO es el adapter por defecto.
 * El adapter por defecto es SpringEventUserEventPublisherAdapter.
 *
 * Para usar ESTE adapter como principal:
 * 1. Quita @Primary de SpringEventUserEventPublisherAdapter
 * 2. Agrega @Primary a esta clase
 *
 * O mejor aÃºn: Usa CompositeUserEventPublisherAdapter para publicar a AMBOS.
 *
 * ARQUITECTURA DE PUBLICACIÃ“N DUAL:
 *
 * CreateUserService
 *        â†“ (publica evento)
 * CompositeUserEventPublisherAdapter
 *        â†“
 *        â”œâ”€â†’ SpringEventUserEventPublisherAdapter â†’ SendWelcomeEmailListener (local)
 *        â””â”€â†’ KafkaUserEventPublisherAdapter â†’ Kafka â†’ UserEventsKafkaConsumer (otro MS)
 *
 * CONSUMER EN OTRO MICROSERVICIO:
 * Este adapter publica a Kafka. Luego, OTRO microservicio (Notifications Service)
 * consume los eventos:
 *
 * {@code
 * @Component
 * public class UserEventsKafkaConsumer {
 *     @KafkaListener(topics = "user.created")
 *     public void consume(UserCreatedEvent event) {
 *         notificationService.sendWelcomeEmail(event.email());
 *     }
 * }
 * }
 *
 * VENTAJAS DE KAFKA:
 * - âœ… Desacoplamiento total entre microservicios
 * - âœ… Durabilidad: eventos persistidos en disco
 * - âœ… Escalabilidad: mÃºltiples consumers pueden procesar en paralelo
 * - âœ… Replay: puedes volver a procesar eventos histÃ³ricos
 * - âœ… Tolerancia a fallos: si un consumer cae, otros siguen funcionando
 *
 * CUÃNDO USAR KAFKA:
 * - ComunicaciÃ³n entre microservicios independientes
 * - Necesitas durabilidad (no perder eventos)
 * - Necesitas replay de eventos
 * - Event sourcing
 * - Alto throughput de mensajes
 */
@Component
public class KafkaUserEventPublisherAdapter implements UserEventPublisher {

    private static final Logger logger = LoggerFactory.getLogger(KafkaUserEventPublisherAdapter.class);

    // Topic de Kafka donde se publican los eventos
    // Dotted notation es el estÃ¡ndar mÃ¡s comÃºn en la industria
    private static final String TOPIC_USER_CREATED = "user.created";

    // KafkaTemplate: Bean de Spring Kafka para publicar mensajes
    private final KafkaTemplate<String, UserCreatedEvent> kafkaTemplate;

    /**
     * Constructor con inyecciÃ³n de dependencias
     *
     * @param kafkaTemplate template configurado en KafkaConfig
     */
    public KafkaUserEventPublisherAdapter(KafkaTemplate<String, UserCreatedEvent> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    /**
     * Publica el evento de usuario creado a Kafka
     *
     * FUNCIONAMIENTO:
     * 1. Convierte el evento a JSON (automÃ¡tico con JsonSerializer)
     * 2. EnvÃ­a a Kafka con userId como KEY (para garantizar orden)
     * 3. Kafka lo distribuye a los consumers suscritos al topic "user.created"
     * 4. Devuelve CompletableFuture para manejo asÃ­ncrono
     *
     * KEY = userId:
     * - Todos los eventos del mismo usuario van a la MISMA PARTICIÃ“N
     * - Garantiza que los eventos se procesen EN ORDEN para cada usuario
     * - Ejemplo: Si tienes UserCreated, UserUpdated, UserDeleted del mismo user,
     *   se procesarÃ¡n en ese orden exacto
     *
     * TOPIC = "user.created":
     * - Naming: dotted notation (mÃ¡s comÃºn)
     * - Alternativa: "user-created" (hyphenated)
     * - Consumers se suscriben a este topic para recibir los eventos
     *
     * ASÃNCRONO:
     * - send() devuelve CompletableFuture<SendResult>
     * - No bloquea (fire and forget)
     * - Puedes agregar callbacks para manejar success/failure
     *
     * EJEMPLO DE USO CON CALLBACKS:
     * {@code
     * CompletableFuture<SendResult<String, UserCreatedEvent>> future = send(...);
     * future.whenComplete((result, ex) -> {
     *     if (ex == null) {
     *         logger.info("Evento enviado exitosamente");
     *     } else {
     *         logger.error("Error enviando evento: {}", ex.getMessage());
     *     }
     * });
     * }
     *
     * @param event evento a publicar
     */
    @Override
    public void publish(UserCreatedEvent event) {
        logger.info("ğŸ“¤ [KAFKA PUBLISHER] Publishing UserCreatedEvent to Kafka: userId={}, username={}",
                event.userId(), event.username());

        try {
            // Publicar a Kafka
            // - Topic: "user.created"
            // - Key: userId (para garantizar orden de eventos del mismo usuario)
            // - Value: event (se serializa automÃ¡ticamente a JSON)
            CompletableFuture<SendResult<String, UserCreatedEvent>> future = kafkaTemplate.send(
                    TOPIC_USER_CREATED,
                    event.userId().toString(),  // â† KEY: userId (garantiza orden)
                    event                        // â† VALUE: evento completo
            );

            // Callback para loguear resultado (opcional)
            future.whenComplete((result, ex) -> {
                if (ex == null) {
                    // Ã‰xito: evento publicado correctamente
                    logger.info("âœ… [KAFKA PUBLISHER] Event published successfully to topic '{}', " +
                                    "partition={}, offset={}",
                            TOPIC_USER_CREATED,
                            result.getRecordMetadata().partition(),
                            result.getRecordMetadata().offset());

                    logger.debug("Event details: userId={}, username={}, email={}",
                            event.userId(), event.username(), event.email());

                } else {
                    // Error: fallÃ³ la publicaciÃ³n
                    logger.error("âŒ [KAFKA PUBLISHER] Failed to publish event to Kafka: {}",
                            ex.getMessage(), ex);

                    // TODO: En un sistema real, aquÃ­ podrÃ­as:
                    // - Guardar en una "dead letter queue" (DLQ)
                    // - Reintentar con backoff exponencial
                    // - Enviar alerta a monitoreo
                    // - Guardar en BD para procesamiento posterior
                }
            });

        } catch (Exception e) {
            // Captura excepciones sÃ­ncronas (ej: Kafka no disponible)
            logger.error("âŒ [KAFKA PUBLISHER] Exception while sending event to Kafka: {}",
                    e.getMessage(), e);

            // TODO: Decidir quÃ© hacer con el error
            // OpciÃ³n 1: Lanzar excepciÃ³n (fallarÃ¡ la creaciÃ³n del usuario)
            // OpciÃ³n 2: Loguear y continuar (usuario se crea aunque falle Kafka)
            // En este caso, solo logueamos (opciÃ³n 2)
        }
    }

    /**
     * NOTAS SOBRE TOPICS:
     *
     * Para crear topics manualmente (opcional, Kafka los crea automÃ¡ticamente):
     *
     * {@code
     * kafka-topics.sh --create \
     *   --bootstrap-server localhost:9092 \
     *   --topic user.created \
     *   --partitions 3 \
     *   --replication-factor 1
     * }
     *
     * Para listar topics existentes:
     * {@code
     * kafka-topics.sh --list --bootstrap-server localhost:9092
     * }
     *
     * Para ver mensajes del topic (consumer de consola):
     * {@code
     * kafka-console-consumer.sh \
     *   --bootstrap-server localhost:9092 \
     *   --topic user.created \
     *   --from-beginning
     * }
     */
}
