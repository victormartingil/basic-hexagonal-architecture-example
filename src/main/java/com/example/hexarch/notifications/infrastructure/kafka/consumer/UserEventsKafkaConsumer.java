package com.example.hexarch.notifications.infrastructure.kafka.consumer;

import com.example.hexarch.notifications.application.service.EmailService;
import com.example.hexarch.user.domain.event.UserCreatedEvent;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

/**
 * INFRASTRUCTURE LAYER - Kafka Consumer
 *
 * Consumer que escucha eventos de Kafka del topic "user.created".
 *
 * â­ SIMULA OTRO MICROSERVICIO:
 * Este consumer representa un "Notifications Service" separado que:
 * - Es otro bounded context (otro microservicio)
 * - Escucha eventos publicados por el "User Service"
 * - Reacciona enviando notificaciones (email, SMS, push)
 *
 * ARQUITECTURA DE MICROSERVICIOS:
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ USER SERVICE (este proyecto)                                    â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ CreateUserService                                               â”‚
 * â”‚        â†“                                                        â”‚
 * â”‚ KafkaUserEventPublisherAdapter                                  â”‚
 * â”‚        â†“ publica a Kafka                                        â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *          â†“
 *     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
 *     â”‚ KAFKA  â”‚  Topic: "user.created"
 *     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
 *          â†“ consume de Kafka
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚        â†“                                                        â”‚
 * â”‚ UserEventsKafkaConsumer (ESTA CLASE)                            â”‚
 * â”‚        â†“                                                        â”‚
 * â”‚ NotificationService (simulado)                                  â”‚
 * â”‚                                                                  â”‚
 * â”‚ NOTIFICATIONS SERVICE (simulado en este proyecto)               â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * EN UN SISTEMA REAL:
 * - User Service y Notifications Service serÃ­an proyectos separados
 * - Cada uno con su propia base de datos
 * - Desplegados independientemente
 * - ComunicÃ¡ndose solo vÃ­a Kafka (async messaging)
 *
 * ESTE PROYECTO (educativo):
 * - Simula ambos servicios en el mismo proyecto
 * - Usa paquetes separados: com.example.hexarch.user vs com.example.hexarch.notifications
 * - Demuestra cÃ³mo funcionarÃ­a la comunicaciÃ³n
 *
 * Â¿QUÃ‰ HACE @KafkaListener?
 * - Escucha automÃ¡ticamente el topic "user.created"
 * - Spring Kafka deserializa el JSON a UserCreatedEvent
 * - Ejecuta el mÃ©todo consume() cada vez que llega un mensaje
 * - Maneja offsets automÃ¡ticamente (guarda posiciÃ³n de lectura)
 *
 * GROUP ID:
 * - group-id = "notifications-service"
 * - Si hay mÃºltiples instancias con el mismo group-id:
 *   â†’ Kafka reparte mensajes entre ellas (load balancing)
 * - Si hay mÃºltiples group-ids diferentes:
 *   â†’ Cada grupo recibe TODOS los mensajes (broadcast)
 *
 * EJEMPLO:
 * {@code
 * // 2 consumers con MISMO group-id
 * Consumer A (group: notifications-service) â†’ Partition 0, 2
 * Consumer B (group: notifications-service) â†’ Partition 1
 * â†‘ Comparten carga (cada mensaje lo procesa UNO)
 *
 * // 2 consumers con DIFERENTE group-id
 * Consumer A (group: notifications-service) â†’ Recibe TODOS
 * Consumer B (group: analytics-service)     â†’ Recibe TODOS
 * â†‘ Cada uno procesa todos los mensajes
 * }
 *
 * ORDEN DE PROCESAMIENTO:
 * - Mensajes con la misma KEY van a la misma PARTICIÃ“N
 * - Orden garantizado DENTRO de una particiÃ³n
 * - En nuestro caso: Key = userId â†’ eventos del mismo user en orden
 *
 * MANEJO DE ERRORES:
 * - Si este mÃ©todo lanza excepciÃ³n â†’ Kafka NO avanza el offset
 * - Kafka reintenta el mismo mensaje (segÃºn configuraciÃ³n)
 * - Para evitar loops infinitos: usa Dead Letter Topic (DLT)
 *
 * CONCURRENCY:
 * - Configurado en KafkaConfig.setConcurrency(3)
 * - 3 threads consumiendo en paralelo
 * - MÃ¡ximo = nÃºmero de particiones (3 en nuestro caso)
 */
@Component
public class UserEventsKafkaConsumer {

    private static final Logger logger = LoggerFactory.getLogger(UserEventsKafkaConsumer.class);

    // EmailService con Circuit Breaker protection
    private final EmailService emailService;

    /**
     * Constructor con inyecciÃ³n de EmailService
     *
     * @param emailService servicio de email con Circuit Breaker
     */
    public UserEventsKafkaConsumer(EmailService emailService) {
        this.emailService = emailService;
    }

    /**
     * Consume eventos de creaciÃ³n de usuario del topic "user.created"
     *
     * @KafkaListener:
     * - topics: Topic(s) a escuchar
     * - groupId: Grupo de consumers (para load balancing)
     * - containerFactory: Factory configurada en KafkaConfig
     *
     * @Payload: El evento deserializado automÃ¡ticamente desde JSON
     * @Header: Metadatos del mensaje (partition, offset, key, etc.)
     *
     * FLUJO:
     * 1. User Service publica UserCreatedEvent a Kafka
     * 2. Kafka persiste el mensaje en el topic "user.created"
     * 3. Este consumer lee el mensaje
     * 4. Spring Kafka deserializa JSON â†’ UserCreatedEvent
     * 5. Se ejecuta este mÃ©todo automÃ¡ticamente
     * 6. Procesamos el evento (enviar email, SMS, push)
     * 7. Si no hay excepciones, Kafka avanza el offset (marca como procesado)
     *
     * SIMULACIÃ“N:
     * En este ejemplo solo logueamos, pero en un sistema real aquÃ­:
     * - LlamarÃ­as a un EmailService
     * - EnviarÃ­as SMS via Twilio
     * - EnviarÃ­as push notifications
     * - RegistrarÃ­as en analytics
     *
     * @param event   el evento de usuario creado
     * @param partition la particiÃ³n de donde viene el mensaje
     * @param offset el offset del mensaje en la particiÃ³n
     * @param key la key del mensaje (en nuestro caso, userId)
     */
    @KafkaListener(
            topics = "user.created",
            groupId = "notifications-service",
            containerFactory = "kafkaListenerContainerFactory"
    )
    public void consume(
            @Payload UserCreatedEvent event,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            @Header(KafkaHeaders.RECEIVED_KEY) String key) {

        logger.info("ğŸ“¨ [KAFKA CONSUMER - NOTIFICATIONS SERVICE] Received UserCreatedEvent from Kafka");
        logger.info("    Topic: user.created");
        logger.info("    Partition: {} | Offset: {} | Key: {}", partition, offset, key);
        logger.info("    Event: userId={}, username={}, email={}",
                event.userId(), event.username(), event.email());

        try {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // SIMULACIÃ“N DE NOTIFICATIONS SERVICE
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // En un microservicio real de notificaciones, aquÃ­ harÃ­as:

            logger.info("ğŸ”” [NOTIFICATIONS SERVICE] Processing user registration notification");

            // 1. Enviar email de bienvenida
            logger.info("   âœ‰ï¸  Sending welcome email to: {}", event.email());

            // âš¡ CIRCUIT BREAKER PROTECTION
            // Esta llamada estÃ¡ protegida por Circuit Breaker (@CircuitBreaker en EmailService)
            // Si EmailService falla repetidamente:
            // 1. Circuit Breaker detecta tasa de fallos alta
            // 2. Cambia a estado OPEN
            // 3. Llama a sendEmailFallback() en lugar de sendWelcomeEmail()
            // 4. Previene cascading failures
            emailService.sendWelcomeEmail(event.email(), event.username());

            // 2. Enviar SMS de confirmaciÃ³n (opcional)
            // if (event.phoneNumber() != null) {
            //     logger.info("   ğŸ“± Sending SMS confirmation to: {}", event.phoneNumber());
            //     smsService.sendWelcomeSMS(event.phoneNumber(), event.username());
            // }

            // 3. Enviar push notification (si tiene app mÃ³vil)
            // logger.info("   ğŸ“² Sending push notification to user: {}", event.userId());
            // pushService.sendPushNotification(event.userId(), "Welcome to our platform!");

            // 4. Registrar en analytics/CRM
            // logger.info("   ğŸ“Š Registering user in CRM: {}", event.email());
            // crmService.createContact(event.email(), event.username());

            logger.info("âœ… [NOTIFICATIONS SERVICE] User registration notification sent successfully");
            logger.info("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

        } catch (Exception e) {
            // Manejo de errores
            logger.error("âŒ [NOTIFICATIONS SERVICE] Failed to process notification: {}",
                    e.getMessage(), e);

            // âš ï¸ IMPORTANTE: Decidir quÃ© hacer con el error
            //
            // OPCIÃ“N 1: Lanzar excepciÃ³n (IMPLEMENTADA)
            // - Kafka NO avanzarÃ¡ el offset
            // - ReintentarÃ¡ el mismo mensaje (segÃºn configuraciÃ³n en KafkaConfig)
            // - DespuÃ©s de N reintentos â†’ Kafka enviarÃ¡ a DLT automÃ¡ticamente
            // - DefaultErrorHandler con DeadLetterPublishingRecoverer maneja esto
            //
            // OPCIÃ“N 2: Loguear y continuar (NO lanzar excepciÃ³n)
            // - Kafka avanza el offset (mensaje marcado como procesado)
            // - El mensaje "se pierde" (no se reintenta)
            // - Ãštil si el error no es crÃ­tico
            //
            // OPCIÃ“N 3: Enviar a Dead Letter Topic (DLT) manualmente
            // - EnvÃ­as el mensaje problemÃ¡tico a otro topic manualmente
            // - Kafka avanza el offset
            // - MÃ¡s control pero mÃ¡s cÃ³digo
            //
            // En este ejemplo: OpciÃ³n 1 (lanzar excepciÃ³n)
            // Permite que Kafka maneje reintentos y DLT automÃ¡ticamente
            throw new RuntimeException("Failed to process notification", e);
            // Las notificaciones no son crÃ­ticas, el usuario ya estÃ¡ creado
        }
    }

    /**
     * EJEMPLO ALTERNATIVO: Consumer con ConsumerRecord
     *
     * Si necesitas acceso completo al registro (headers, timestamp, etc.):
     *
     * {@code
     * @KafkaListener(topics = "user.created", groupId = "notifications-service")
     * public void consumeWithRecord(ConsumerRecord<String, UserCreatedEvent> record) {
     *     UserCreatedEvent event = record.value();
     *     String key = record.key();
     *     int partition = record.partition();
     *     long offset = record.offset();
     *     long timestamp = record.timestamp();
     *
     *     logger.info("Received event: {}", event);
     *     logger.info("Metadata: partition={}, offset={}, timestamp={}",
     *         partition, offset, timestamp);
     *
     *     // Acceder a headers custom
     *     record.headers().forEach(header -> {
     *         logger.info("Header: {} = {}", header.key(), new String(header.value()));
     *     });
     * }
     * }
     */

    /**
     * EJEMPLO: Consumer en batch (procesar mÃºltiples mensajes juntos)
     *
     * MÃ¡s eficiente si tienes alto throughput:
     *
     * {@code
     * @KafkaListener(topics = "user.created", groupId = "notifications-service")
     * public void consumeBatch(List<UserCreatedEvent> events) {
     *     logger.info("Received batch of {} events", events.size());
     *
     *     events.forEach(event -> {
     *         // Procesar evento
     *         logger.info("Processing event: {}", event);
     *     });
     *
     *     logger.info("Batch processed successfully");
     * }
     * }
     */

    /**
     * COMANDOS ÃšTILES DE KAFKA:
     *
     * Ver mensajes del topic en tiempo real:
     * {@code
     * kafka-console-consumer.sh \
     *   --bootstrap-server localhost:9092 \
     *   --topic user.created \
     *   --from-beginning
     * }
     *
     * Ver consumer groups:
     * {@code
     * kafka-consumer-groups.sh \
     *   --bootstrap-server localhost:9092 \
     *   --list
     * }
     *
     * Ver lag (mensajes pendientes) de un grupo:
     * {@code
     * kafka-consumer-groups.sh \
     *   --bootstrap-server localhost:9092 \
     *   --group notifications-service \
     *   --describe
     * }
     *
     * Reset offsets (volver a procesar desde el principio):
     * {@code
     * kafka-consumer-groups.sh \
     *   --bootstrap-server localhost:9092 \
     *   --group notifications-service \
     *   --topic user.created \
     *   --reset-offsets --to-earliest \
     *   --execute
     * }
     */
}
