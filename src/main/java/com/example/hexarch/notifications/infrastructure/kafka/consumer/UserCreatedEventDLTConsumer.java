package com.example.hexarch.notifications.infrastructure.kafka.consumer;

import com.example.hexarch.user.domain.event.UserCreatedEvent;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

/**
 * INFRASTRUCTURE LAYER - Dead Letter Topic (DLT) Consumer
 *
 * Consumer que escucha el Dead Letter Topic (DLT) para mensajes fallidos.
 *
 * Â¿QUÃ‰ ES UN DLT (DEAD LETTER TOPIC)?
 * - Topic especial para mensajes que fallaron al procesarse
 * - Evita loops infinitos con mensajes problemÃ¡ticos
 * - Permite revisar/debuguear/reprocesar mensajes fallidos
 *
 * FLUJO COMPLETO:
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 1. Mensaje llega a UserEventsKafkaConsumer                          â”‚
 * â”‚    Topic: "user.created"                                            â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *              â”‚
 *              â–¼
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 2. Consumer intenta procesar el mensaje                             â”‚
 * â”‚    âŒ Falla (ej: email service down, error en cÃ³digo, etc.)         â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *              â”‚
 *              â–¼
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 3. DefaultErrorHandler reintenta automÃ¡ticamente                    â”‚
 * â”‚    â€¢ Intento 1: espera 1 segundo, reintenta â†’ Falla âŒ              â”‚
 * â”‚    â€¢ Intento 2: espera 1 segundo, reintenta â†’ Falla âŒ              â”‚
 * â”‚    â€¢ Intento 3: espera 1 segundo, reintenta â†’ Falla âŒ              â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *              â”‚
 *              â–¼
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 4. DeadLetterPublishingRecoverer envÃ­a a DLT                        â”‚
 * â”‚    Topic: "user.created.dlt"                                        â”‚
 * â”‚    Consumer original continÃºa con siguiente mensaje âœ…               â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *              â”‚
 *              â–¼
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ 5. UserCreatedEventDLTConsumer (ESTA CLASE) recibe el mensaje      â”‚
 * â”‚    â€¢ Loguea el error para investigaciÃ³n                             â”‚
 * â”‚    â€¢ Opcionalmente: guarda en BD, envÃ­a alerta, reintenta manual   â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * Â¿POR QUÃ‰ USAR DLT?
 *
 * SIN DLT:
 * - Consumer se atasca reintentando el mismo mensaje infinitamente
 * - Bloquea el procesamiento de mensajes siguientes
 * - DifÃ­cil identificar/debuguear mensajes problemÃ¡ticos
 *
 * CON DLT:
 * - âœ… Consumer no se bloquea (continÃºa con siguiente mensaje)
 * - âœ… Mensajes problemÃ¡ticos se almacenan para investigaciÃ³n
 * - âœ… Puedes reprocesar manualmente despuÃ©s de fix
 * - âœ… Monitoreo: alertas si DLT crece mucho
 *
 * CASOS DE USO REALES:
 *
 * 1. **Email service down (error transitorio)**
 *    - Mensaje va a DLT
 *    - Cuando service se recupera â†’ reprocesas DLT
 *
 * 2. **Datos invÃ¡lidos (error permanente)**
 *    - Mensaje va a DLT
 *    - Investigas el problema
 *    - Corriges datos y reprocesas
 *
 * 3. **Bug en cÃ³digo (error permanente)**
 *    - Mensaje va a DLT
 *    - Despliegas fix
 *    - Reprocesas mensajes del DLT
 *
 * QUÃ‰ HACER CON MENSAJES EN DLT:
 *
 * 1. **Loguear** (lo que hace esta clase)
 *    - Ver quÃ© mensajes fallaron
 *    - Investigar causa raÃ­z
 *
 * 2. **Guardar en BD** (recomendado para producciÃ³n)
 *    - Tabla: failed_messages (id, topic, message, error, timestamp)
 *    - Dashboard para ver mensajes fallidos
 *
 * 3. **Enviar alertas** (Slack, PagerDuty, etc.)
 *    - Si DLT crece mucho â†’ algo estÃ¡ mal
 *    - Alertar al equipo
 *
 * 4. **Reprocesar** (manualmente o automÃ¡ticamente)
 *    - Endpoint admin: POST /admin/retry-dlt
 *    - Lee mensajes del DLT y republica al topic original
 *
 * CONFIGURACIÃ“N:
 * Este consumer escucha el topic "user.created.dlt" configurado automÃ¡ticamente
 * por DeadLetterPublishingRecoverer en KafkaConfig.
 *
 * GROUP ID DIFERENTE:
 * - Consumer principal: group-id = "notifications-service"
 * - DLT Consumer: group-id = "notifications-service-dlt"
 * - Importante: grupos diferentes para que no interfieran
 */
@Component
public class UserCreatedEventDLTConsumer {

    private static final Logger logger = LoggerFactory.getLogger(UserCreatedEventDLTConsumer.class);

    /**
     * Consume mensajes fallidos del Dead Letter Topic
     *
     * Este mÃ©todo se ejecuta cuando un mensaje falla despuÃ©s de N reintentos
     * y es enviado automÃ¡ticamente al topic DLT por DeadLetterPublishingRecoverer.
     *
     * INFORMACIÃ“N DISPONIBLE:
     * - event: El evento original que fallÃ³
     * - partition, offset, key: Metadatos de Kafka
     * - Headers adicionales agregados por DeadLetterPublishingRecoverer:
     *   â€¢ kafka_dlt-original-topic: Topic original ("user.created")
     *   â€¢ kafka_dlt-exception-message: Mensaje de error
     *   â€¢ kafka_dlt-exception-stacktrace: Stack trace completo
     *
     * QUÃ‰ HACER AQUÃ:
     * 1. âœ… Loguear para debugging (lo que hacemos ahora)
     * 2. ğŸ’¾ Guardar en tabla failed_messages (recomendado producciÃ³n)
     * 3. ğŸ”” Enviar alerta si es crÃ­tico
     * 4. ğŸ“Š Incrementar mÃ©trica de errores (Prometheus/DataDog)
     * 5. ğŸ”„ Opcionalmente: reintentar con lÃ³gica custom
     *
     * @param event   el evento que fallÃ³
     * @param record  registro completo con headers y metadata
     * @param partition particiÃ³n del DLT
     * @param offset  offset del mensaje en DLT
     * @param key     clave del mensaje (userId)
     */
    @KafkaListener(
            topics = "user.created.dlt",
            groupId = "notifications-service-dlt",
            containerFactory = "kafkaListenerContainerFactory"
    )
    public void consumeFailedMessage(
            @Payload UserCreatedEvent event,
            ConsumerRecord<String, UserCreatedEvent> record,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            @Header(KafkaHeaders.RECEIVED_KEY) String key) {

        logger.error("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        logger.error("ğŸ’€ [DLT CONSUMER] Failed message received in Dead Letter Topic");
        logger.error("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        logger.error("    Topic: user.created.dlt");
        logger.error("    Partition: {} | Offset: {} | Key: {}", partition, offset, key);
        logger.error("    Event: userId={}, username={}, email={}",
                event.userId(), event.username(), event.email());

        // Extraer headers con informaciÃ³n del error
        String originalTopic = getHeaderValue(record, "kafka_dlt-original-topic");
        String exceptionMessage = getHeaderValue(record, "kafka_dlt-exception-message");
        String exceptionStacktrace = getHeaderValue(record, "kafka_dlt-exception-stacktrace");

        logger.error("    Original Topic: {}", originalTopic);
        logger.error("    Exception: {}", exceptionMessage);

        if (exceptionStacktrace != null && !exceptionStacktrace.isEmpty()) {
            logger.error("    Stack Trace (first 500 chars):");
            logger.error("    {}", exceptionStacktrace.substring(0, Math.min(500, exceptionStacktrace.length())));
        }

        logger.error("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // ACCIONES RECOMENDADAS PARA PRODUCCIÃ“N
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        try {
            // 1. GUARDAR EN BASE DE DATOS (recomendado para producciÃ³n)
            // failedMessageRepository.save(new FailedMessage(
            //     originalTopic,
            //     event.userId().toString(),
            //     objectMapper.writeValueAsString(event),
            //     exceptionMessage,
            //     exceptionStacktrace,
            //     Instant.now()
            // ));

            // 2. ENVIAR ALERTA (Slack, PagerDuty, etc.)
            // if (shouldAlert(event)) {
            //     alertService.sendAlert(
            //         "DLT Alert",
            //         "Failed to process UserCreatedEvent for user: " + event.username(),
            //         AlertSeverity.HIGH
            //     );
            // }

            // 3. INCREMENTAR MÃ‰TRICA DE ERRORES (Prometheus, DataDog)
            // meterRegistry.counter("kafka.dlt.messages",
            //     "topic", originalTopic,
            //     "error_type", getErrorType(exceptionMessage)
            // ).increment();

            // 4. REINTENTAR CON LÃ“GICA CUSTOM (si aplica)
            // if (isRetryable(exceptionMessage)) {
            //     logger.info("Scheduling retry for event: {}", event.userId());
            //     retryScheduler.scheduleRetry(event, Duration.ofMinutes(5));
            // }

            logger.info("âœ… [DLT CONSUMER] Failed message processed and logged");

        } catch (Exception e) {
            // Error procesando mensaje del DLT
            // âš ï¸ Importante: NO lanzar excepciÃ³n aquÃ­
            // Si falla, el mensaje irÃ­a a... Â¿otro DLT del DLT? ğŸ˜…
            logger.error("âŒ [DLT CONSUMER] Error processing DLT message: {}", e.getMessage(), e);
        }
    }

    /**
     * Extrae valor de un header del registro de Kafka
     *
     * @param record registro de Kafka
     * @param headerName nombre del header
     * @return valor del header como String, o null si no existe
     */
    private String getHeaderValue(ConsumerRecord<String, UserCreatedEvent> record, String headerName) {
        org.apache.kafka.common.header.Header header = record.headers().lastHeader(headerName);
        if (header != null) {
            return new String(header.value());
        }
        return null;
    }

    /**
     * EJEMPLO: Endpoint para reprocesar mensajes del DLT
     *
     * En un sistema real, podrÃ­as crear un endpoint admin para reprocesar mensajes:
     *
     * {@code
     * @RestController
     * @RequestMapping("/admin/dlt")
     * public class DLTAdminController {
     *
     *     @PostMapping("/retry")
     *     public ResponseEntity<String> retryDLTMessages(
     *             @RequestParam String topic,
     *             @RequestParam(required = false) Integer maxMessages) {
     *
     *         // 1. Consumir mensajes del DLT
     *         List<UserCreatedEvent> failedMessages = dltService.getFailedMessages(topic, maxMessages);
     *
     *         // 2. Republicar al topic original
     *         failedMessages.forEach(event -> {
     *             kafkaTemplate.send("user.created", event.userId().toString(), event);
     *         });
     *
     *         return ResponseEntity.ok("Retried " + failedMessages.size() + " messages");
     *     }
     * }
     * }
     */

    /**
     * EJEMPLO: Dashboard de monitoreo de DLT
     *
     * PodrÃ­as crear un endpoint para ver estado del DLT:
     *
     * {@code
     * @GetMapping("/admin/dlt/stats")
     * public DLTStats getDLTStats() {
     *     return new DLTStats(
     *         failedMessageRepository.count(),              // Total mensajes en DLT
     *         failedMessageRepository.countToday(),         // Mensajes hoy
     *         failedMessageRepository.findTopErrors(10)     // Top 10 errores
     *     );
     * }
     * }
     */

    /**
     * COMANDOS ÃšTILES DE KAFKA PARA DLT:
     *
     * Ver mensajes del DLT:
     * {@code
     * kafka-console-consumer.sh \
     *   --bootstrap-server localhost:9092 \
     *   --topic user.created.dlt \
     *   --from-beginning
     * }
     *
     * Contar mensajes en DLT:
     * {@code
     * kafka-run-class.sh kafka.tools.GetOffsetShell \
     *   --broker-list localhost:9092 \
     *   --topic user.created.dlt
     * }
     *
     * Eliminar topic DLT (CUIDADO - borra todos los mensajes):
     * {@code
     * kafka-topics.sh \
     *   --bootstrap-server localhost:9092 \
     *   --delete \
     *   --topic user.created.dlt
     * }
     */
}
