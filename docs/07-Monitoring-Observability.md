# üìä Monitoring & Observability - Hexarch

## √çndice
- [¬øQu√© es Observabilidad?](#qu√©-es-observabilidad)
- [Los 3 Pilares: Logs, M√©tricas y Trazas](#los-3-pilares-logs-m√©tricas-y-trazas)
- [Logs: Cu√°ndo usar cada nivel](#logs-cu√°ndo-usar-cada-nivel)
- [M√©tricas: Prometheus + Grafana](#m√©tricas-prometheus--grafana)
- [Trazas Distribuidas: Zipkin + Micrometer](#trazas-distribuidas-zipkin--micrometer)
- [Correlation ID: Tracing de Negocio](#correlation-id-tracing-de-negocio)
- [Setup Local](#setup-local)
- [Ejemplos Pr√°cticos en el C√≥digo](#ejemplos-pr√°cticos-en-el-c√≥digo)
- [Alerting](#alerting)

---

## ¬øQu√© es Observabilidad?

**Observabilidad** es la capacidad de **entender el estado interno** de un sistema bas√°ndose en sus salidas externas (logs, m√©tricas, trazas).

### **Monitoring vs Observability**

| Concepto | Definici√≥n | Ejemplo |
|----------|------------|---------|
| **Monitoring** | Verificar si el sistema funciona (**known unknowns**) | "¬øLa CPU est√° > 80%?" |
| **Observability** | Investigar **por qu√©** falla (**unknown unknowns**) | "¬øPor qu√© este request tard√≥ 5 segundos?" |

**En producci√≥n necesitas AMBOS**:
- **Monitoring**: Dashboards con m√©tricas clave (latencia, error rate, throughput)
- **Observability**: Herramientas para explorar y correlacionar eventos (logs + traces)

---

## Los 3 Pilares: Logs, M√©tricas y Trazas

### **1. LOGS** üìù
**Definici√≥n**: Eventos discretos con timestamp que describen lo que pas√≥.

**Caracter√≠sticas**:
- **Texto estructurado** (mejor JSON para parsing)
- **Timestamp** + **Nivel** (INFO, WARN, ERROR) + **Mensaje**
- **Contexto**: CorrelationId, UserId, TraceId

**Ejemplo**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: username=johndoe
‚îÇ                   ‚îÇ           ‚îÇ        ‚îÇ     ‚îÇ
Timestamp           TraceId     CorrId   Level Message
```

**Cu√°ndo usar**:
- ‚úÖ Debugging: "¬øQu√© pas√≥ justo antes del error?"
- ‚úÖ Auditor√≠a: "¬øQui√©n modific√≥ este recurso?"
- ‚úÖ Troubleshooting: Buscar patrones en fallos

**Herramientas**: ELK Stack (Elasticsearch + Logstash + Kibana), Splunk, CloudWatch Logs

---

### **2. M√âTRICAS** üìà
**Definici√≥n**: Valores num√©ricos agregados a lo largo del tiempo.

**Caracter√≠sticas**:
- **Time-series data**: (timestamp, value)
- **Agregaciones**: sum, avg, percentiles (p50, p99)
- **Eficientes**: Ocupan poco espacio (vs logs)

**Tipos de m√©tricas**:

| Tipo | Descripci√≥n | Ejemplo |
|------|-------------|---------|
| **Counter** | Contador que solo crece | `users_created_total` |
| **Gauge** | Valor instant√°neo (sube/baja) | `users_active_count` |
| **Histogram** | Distribuci√≥n de valores | `http_request_duration_seconds` |
| **Summary** | Similar a histogram + percentiles | `http_request_duration_summary` |

**Cu√°ndo usar**:
- ‚úÖ Dashboards en tiempo real
- ‚úÖ Alertas (CPU > 80%, Error rate > 5%)
- ‚úÖ SLOs (Service Level Objectives): "p99 latency < 500ms"

**Herramientas**: Prometheus, Grafana, Datadog, New Relic

---

### **3. TRAZAS DISTRIBUIDAS** üîó
**Definici√≥n**: Seguimiento de un request a trav√©s de m√∫ltiples servicios.

**Conceptos**:
- **Trace**: Request completo (ej: "Crear usuario desde API hasta BD")
- **Span**: Una operaci√≥n dentro del trace (ej: "INSERT en PostgreSQL")
- **Trace ID**: Identificador √∫nico del trace
- **Span ID**: Identificador √∫nico del span

**Ejemplo visual**:
```
Trace ID: f47ac10b-8c42-11eb-8dcd-0242ac130003

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Span 1: POST /api/v1/users         (200ms)             ‚îÇ
‚îÇ  ‚îú‚îÄ Span 2: Validate email          (5ms)              ‚îÇ
‚îÇ  ‚îú‚îÄ Span 3: Save to PostgreSQL     (50ms)              ‚îÇ
‚îÇ  ‚îî‚îÄ Span 4: Publish Kafka event   (145ms)              ‚îÇ
‚îÇ      ‚îî‚îÄ Span 5: Kafka Producer     (140ms)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Cu√°ndo usar**:
- ‚úÖ Identificar cuellos de botella (ej: "Kafka tarda 140ms")
- ‚úÖ Debugging en microservicios (trazar request entre 5+ servicios)
- ‚úÖ Entender flujo de requests

**Herramientas**: Zipkin, Jaeger, AWS X-Ray, Tempo

---

## Logs: Cu√°ndo usar cada nivel

Spring Boot usa **SLF4J + Logback** con 5 niveles de log:

### **Niveles de Log**

| Nivel | Cu√°ndo Usar | Ejemplo | En Producci√≥n |
|-------|-------------|---------|---------------|
| **TRACE** | Debugging muy detallado | `log.trace("Entering method calculateTax()")` | ‚ùå Desactivado |
| **DEBUG** | Informaci√≥n de desarrollo | `log.debug("Query executed: {}", sql)` | ‚ùå Desactivado |
| **INFO** | Eventos importantes | `log.info("User created: {}", userId)` | ‚úÖ Activado |
| **WARN** | Problemas recuperables | `log.warn("Retry attempt 2/3 failed")` | ‚úÖ Activado |
| **ERROR** | Errores que requieren atenci√≥n | `log.error("Failed to send email", ex)` | ‚úÖ Activado |

---

### **Reglas de Oro para Logging**

#### ‚úÖ **1. INFO: Eventos de negocio importantes**

**Usar para**:
- Usuario creado/modificado/eliminado
- Transacci√≥n completada
- Inicio/fin de procesos batch
- Eventos de auditor√≠a

**Ejemplo**:
```java
@Override
public UserResponse createUser(CreateUserCommand command) {
    log.info("Creating user: username={}, email={}", command.username(), command.email());

    User user = User.create(/* ... */);
    User savedUser = userRepository.save(user);

    log.info("User created successfully: userId={}, username={}",
             savedUser.getId(), savedUser.getUsername());

    return mapper.toResponse(savedUser);
}
```

**¬øCu√°ntos logs INFO?**
- ‚ùå **MAL**: 1 log por cada l√≠nea de c√≥digo (ruido)
- ‚úÖ **BIEN**: 2-3 logs por operaci√≥n importante (inicio, √©xito, fin)

---

#### ‚úÖ **2. DEBUG: Informaci√≥n de desarrollo**

**Usar para**:
- Valores de variables durante desarrollo
- SQL queries ejecutadas
- Par√°metros de entrada a m√©todos
- Estado de objetos

**Ejemplo**:
```java
@Override
public Optional<User> findByEmail(String email) {
    log.debug("Searching user by email: {}", email);

    Optional<UserEntity> entity = jpaRepository.findByEmail(email);

    log.debug("User found: {}", entity.isPresent());

    return entity.map(userMapper::toDomain);
}
```

**Importante**:
- ‚ùå **NO** usar en producci√≥n (genera demasiados logs)
- ‚úÖ Activar solo durante troubleshooting espec√≠fico

---

#### ‚úÖ **3. WARN: Problemas no cr√≠ticos**

**Usar para**:
- Reintentos fallidos (antes del √∫ltimo intento)
- Configuraci√≥n sub√≥ptima detectada
- Uso de valores por defecto
- Deprecation warnings

**Ejemplo**:
```java
@Retryable(maxAttempts = 3)
@Override
public void sendWelcomeEmail(String email) {
    try {
        emailService.send(email, "Welcome!");
        log.info("Welcome email sent to {}", email);
    } catch (EmailException ex) {
        log.warn("Failed to send email to {} (will retry)", email);
        throw ex; // Retry mechanism will catch this
    }
}
```

**¬øCu√°ndo NO usar WARN?**
- ‚ùå Errores esperados (ej: usuario no encontrado ‚Üí usar INFO)
- ‚ùå Validaci√≥n fallida ‚Üí lanzar exception, logear como ERROR si no se captura

---

#### ‚úÖ **4. ERROR: Errores cr√≠ticos**

**Usar para**:
- Exceptions no esperadas
- Fallos en servicios externos
- Inconsistencias de datos
- Cualquier cosa que requiera atenci√≥n inmediata

**Ejemplo**:
```java
@Override
public void handleUserCreatedEvent(UserCreatedEvent event) {
    try {
        emailService.sendWelcomeEmail(event.email());
        log.info("Welcome email sent for user: {}", event.userId());
    } catch (Exception ex) {
        log.error("Failed to send welcome email for user: userId={}, error={}",
                  event.userId(), ex.getMessage(), ex);
        throw ex; // Ser√° enviado a DLT
    }
}
```

**Reglas para ERROR logs**:
1. ‚úÖ **Siempre incluir la exception**: `log.error("msg", exception)`
2. ‚úÖ **Incluir contexto**: userId, transactionId, etc.
3. ‚úÖ **NO logear la misma exception m√∫ltiples veces** (contamina logs)

**Anti-pattern com√∫n**:
```java
// ‚ùå MAL: Logea 3 veces la misma exception
try {
    service.doSomething();
} catch (Exception ex) {
    log.error("Error in layer 1", ex);  // ‚ùå
    throw ex;
}

// En el caller:
try {
    layer1.call();
} catch (Exception ex) {
    log.error("Error in layer 2", ex);  // ‚ùå Duplicado
    throw ex;
}

// En el controller:
try {
    layer2.call();
} catch (Exception ex) {
    log.error("Error in controller", ex);  // ‚ùå Triplicado
    return ResponseEntity.status(500).build();
}
```

**‚úÖ BIEN: Logea solo en el boundary**:
```java
// Domain/Application: Solo lanzan exceptions (NO logean)
public User createUser(...) {
    if (userRepository.existsByEmail(email)) {
        throw new EmailAlreadyExistsException(email);  // NO log aqu√≠
    }
    return userRepository.save(user);
}

// Controller: Logea y maneja
@PostMapping("/users")
public ResponseEntity<UserResponse> createUser(@RequestBody CreateUserRequest request) {
    try {
        UserResponse response = useCase.execute(command);
        return ResponseEntity.status(201).body(response);
    } catch (EmailAlreadyExistsException ex) {
        log.warn("Email already exists: {}", request.email());  // Log en boundary
        return ResponseEntity.status(409).build();
    } catch (Exception ex) {
        log.error("Unexpected error creating user", ex);  // Log en boundary
        return ResponseEntity.status(500).build();
    }
}
```

---

#### ‚úÖ **5. TRACE: Solo para librer√≠as**

**NO usar en c√≥digo de aplicaci√≥n**. Reservado para:
- Spring Framework internals
- Hibernate SQL tracing
- Network debugging

**Activaci√≥n temporal**:
```yaml
logging:
  level:
    org.hibernate.SQL: TRACE  # Ver SQL queries
    org.springframework.web: TRACE  # Ver requests HTTP
```

---

### **Formato de Logs en Hexarch**

**Configurado en `application.yaml`**:
```yaml
logging:
  pattern:
    # Formato: timestamp [traceId,spanId] correlationId level - message
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

**Ejemplo de log**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400-e29b-41d4 INFO  - User created: userId=123, username=johndoe
‚îÇ                   ‚îÇ           ‚îÇ        ‚îÇ                    ‚îÇ     ‚îÇ
Timestamp           TraceId     SpanId   CorrelationId        Level Message
```

**Ventajas**:
- ‚úÖ Buscar todos los logs de un request espec√≠fico: `correlationId:550e8400-e29b-41d4`
- ‚úÖ Ver trace completo en Zipkin: `traceId:f47ac10b`
- ‚úÖ Debugging r√°pido: correlacionar logs entre servicios

---

## M√©tricas: Prometheus + Grafana

### **¬øQu√© es Prometheus?**

**Prometheus** es un sistema de **monitorizaci√≥n basado en m√©tricas time-series**:
- Recolecta m√©tricas mediante **pull** (scraping)
- Almacena en time-series DB
- Query language: **PromQL**
- Integraci√≥n con Grafana para visualizaci√≥n

### **¬øQu√© es Grafana?**

**Grafana** es una plataforma de **visualizaci√≥n y dashboards**:
- Conecta a m√∫ltiples datasources (Prometheus, InfluxDB, ElasticSearch)
- Dashboards interactivos
- Alertas configurables

---

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Actuator: Expone m√©tricas -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- Prometheus: Formato de m√©tricas -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

**2. Configuraci√≥n en `application.yaml`**:
```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics

  endpoint:
    prometheus:
      enabled: true

  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:local}
```

**3. Endpoint de m√©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus
```

**Respuesta**:
```
# HELP jvm_memory_used_bytes The amount of used memory
# TYPE jvm_memory_used_bytes gauge
jvm_memory_used_bytes{area="heap",id="PS Eden Space",} 1.23456789E8

# HELP http_server_requests_seconds Duration of HTTP requests
# TYPE http_server_requests_seconds summary
http_server_requests_seconds_count{exception="None",method="POST",status="201",uri="/api/v1/users",} 42.0
http_server_requests_seconds_sum{exception="None",method="POST",status="201",uri="/api/v1/users",} 2.1
```

---

### **M√©tricas Autom√°ticas (Actuator)**

Spring Boot Actuator **ya expone m√©tricas autom√°ticamente**:

| M√©trica | Descripci√≥n |
|---------|-------------|
| `jvm_memory_used_bytes` | Memoria JVM usada |
| `jvm_threads_live_threads` | Threads activos |
| `jvm_gc_pause_seconds` | Pausas de Garbage Collector |
| `http_server_requests_seconds` | Latencia de requests HTTP |
| `http_server_requests_seconds_count` | Total de requests por endpoint |
| `spring_kafka_listener_seconds` | Latencia de Kafka listeners |
| `hikaricp_connections_active` | Conexiones DB activas |
| `logback_events_total` | Total de logs por nivel |

**No necesitas c√≥digo adicional para estas m√©tricas** ‚úÖ

---

### **M√©tricas Customizadas**

Para m√©tricas de **negocio espec√≠ficas**, usa `MeterRegistry`:

#### **Ejemplo 1: Contador de usuarios creados**

**`CreateUserUseCase.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class CreateUserUseCase {

    private final UserRepositoryPort userRepository;
    private final EventPublisherPort eventPublisher;
    private final MeterRegistry meterRegistry;  // ‚Üê Inyectar

    @Override
    public UserResponse execute(CreateUserCommand command) {
        // ... validaciones ...

        User savedUser = userRepository.save(user);

        // üìä M√©trica custom: contador de usuarios creados
        meterRegistry.counter("users.created.total",
                              "status", "success",
                              "environment", environment)
                     .increment();

        log.info("User created: userId={}, username={}", savedUser.getId(), savedUser.getUsername());

        eventPublisher.publish(userCreatedEvent);

        return mapper.toResponse(savedUser);
    }
}
```

**M√©trica expuesta**:
```
# HELP users_created_total Total number of users created
# TYPE users_created_total counter
users_created_total{status="success",environment="production"} 42.0
```

---

#### **Ejemplo 2: Gauge de usuarios activos**

**`UserMetricsService.java`**:
```java
@Service
@RequiredArgsConstructor
public class UserMetricsService {

    private final UserRepositoryPort userRepository;
    private final MeterRegistry meterRegistry;

    @PostConstruct
    public void registerMetrics() {
        // üìä Gauge: valor que fluct√∫a (sube/baja)
        Gauge.builder("users.active.count", userRepository, repo -> repo.countByEnabled(true))
             .description("Number of active users")
             .register(meterRegistry);
    }
}
```

**M√©trica expuesta**:
```
# HELP users_active_count Number of active users
# TYPE users_active_count gauge
users_active_count 156.0
```

---

#### **Ejemplo 3: Timer de operaciones**

**`EmailService.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class EmailService {

    private final MeterRegistry meterRegistry;

    @CircuitBreaker(name = "emailService", fallbackMethod = "sendEmailFallback")
    @Retry(name = "emailService")
    public void sendWelcomeEmail(String email) {
        // üìä Timer: mide duraci√≥n de operaci√≥n
        Timer.Sample sample = Timer.start(meterRegistry);

        try {
            // Simular env√≠o de email (aqu√≠ ir√≠a integraci√≥n con SMTP/SES)
            Thread.sleep(100);

            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "success"));

            log.info("Welcome email sent to {}", email);
        } catch (Exception ex) {
            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "failure"));
            throw new EmailServiceException("Failed to send email", ex);
        }
    }
}
```

**M√©trica expuesta**:
```
# HELP email_send_duration_seconds Email send duration
# TYPE email_send_duration_seconds summary
email_send_duration_seconds_count{type="welcome",status="success"} 42.0
email_send_duration_seconds_sum{type="welcome",status="success"} 4.2
email_send_duration_seconds{type="welcome",status="success",quantile="0.5",} 0.098
email_send_duration_seconds{type="welcome",status="success",quantile="0.99",} 0.15
```

---

### **Dashboards en Grafana**

**1. A√±adir Prometheus como datasource**:
- URL: `http://prometheus:9090`
- Access: Server (default)

**2. Importar dashboard JVM (Micrometer)**:
- Dashboard ID: `4701` (JVM Micrometer)
- [https://grafana.com/grafana/dashboards/4701](https://grafana.com/grafana/dashboards/4701)

**3. Dashboard custom para Users**:

**Panel 1: Total usuarios creados**
```promql
# Query PromQL
rate(users_created_total[5m])
```

**Panel 2: Usuarios activos (gauge)**
```promql
users_active_count
```

**Panel 3: Latencia p99 de POST /users**
```promql
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket{uri="/api/v1/users", method="POST"}[5m])
)
```

**Panel 4: Error rate**
```promql
rate(http_server_requests_seconds_count{status=~"5.."}[5m]) /
rate(http_server_requests_seconds_count[5m]) * 100
```

**Captura de pantalla** (ejemplo):
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Users Dashboard                             [Last 1 hour ‚ñº] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Total Users     ‚îÇ  ‚îÇ Active Users    ‚îÇ  ‚îÇ Error Rate   ‚îÇ‚îÇ
‚îÇ  ‚îÇ      1,234      ‚îÇ  ‚îÇ       156       ‚îÇ  ‚îÇ    0.5%      ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ POST /users - p99 Latency                                ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà 120ms                            ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Trazas Distribuidas: Zipkin + Micrometer

### **¬øQu√© es Zipkin?**

**Zipkin** es un sistema de **distributed tracing** que:
- Recolecta spans de m√∫ltiples servicios
- Correlaciona spans en un trace completo
- Visualiza el flujo de requests
- Identifica cuellos de botella

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Micrometer Tracing (OpenTelemetry compatible) -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>

<!-- Zipkin Reporter -->
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

**2. Configuraci√≥n en `application.yaml`**:
```yaml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% en dev, 0.1 (10%) en prod

  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans
```

**3. Acceder a Zipkin UI**:
```bash
# URL
http://localhost:9411/zipkin/

# Buscar traces por:
# - serviceName: hexarch
# - traceId: f47ac10b-8c42-11eb-8dcd-0242ac130003
# - minDuration: > 500ms (encontrar lentos)
```

---

### **Visualizaci√≥n de Traces**

**Trace completo: POST /api/v1/users**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Trace: f47ac10b-8c42-11eb-8dcd-0242ac130003 (250ms total)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ ‚îå‚îÄ POST /api/v1/users ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (250ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ                                                              ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îå‚îÄ CreateUserUseCase.execute() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (200ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                          ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ PostgresUserRepository.save() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (40ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ INSERT INTO users ...                           ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                          ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ KafkaEventPublisher.publish() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (150ms) ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ kafka.send(user.created)                        ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üîç Insight: Kafka tarda 150ms de 250ms totales (60% del tiempo)
```

**An√°lisis**:
- Total: 250ms
- PostgreSQL: 40ms (16%)
- Kafka: 150ms (60%) ‚Üê **Cuello de botella**
- L√≥gica aplicaci√≥n: 10ms (4%)
- Overhead: 50ms (20%)

**Acci√≥n**: Optimizar Kafka (async, batching, compression)

---

### **Spans Autom√°ticos**

Spring Boot **ya crea spans autom√°ticamente** para:
- ‚úÖ HTTP requests (`spring-webmvc`)
- ‚úÖ JPA queries (`spring-data-jpa`)
- ‚úÖ Kafka producers/consumers (`spring-kafka`)
- ‚úÖ RestTemplate/WebClient calls
- ‚úÖ JDBC queries

**No necesitas c√≥digo adicional** ‚úÖ

---

### **Spans Manuales (Custom)**

Para operaciones espec√≠ficas, usa `@NewSpan` o `Tracer`:

```java
@Service
@RequiredArgsConstructor
public class ComplexBusinessLogic {

    private final Tracer tracer;

    public void processOrder(Order order) {
        // Crear span manual
        Span span = tracer.nextSpan().name("process-order");

        try (Tracer.SpanInScope ws = tracer.withSpan(span.start())) {
            // A√±adir tags al span
            span.tag("order.id", order.getId());
            span.tag("order.amount", String.valueOf(order.getAmount()));

            // L√≥gica de negocio compleja
            validateOrder(order);
            calculateTax(order);
            saveOrder(order);

        } finally {
            span.end();
        }
    }
}
```

---

## Correlation ID: Tracing de Negocio

### **¬øQu√© es Correlation ID?**

**Correlation ID** es un **identificador de negocio** que:
- Correlaciona logs entre m√∫ltiples servicios
- Es independiente de Trace ID (t√©cnico)
- Se propaga en header HTTP: `X-Correlation-ID`

**Diferencias**:

| Concepto | Prop√≥sito | Scope | Ejemplo |
|----------|-----------|-------|---------|
| **Trace ID** | Tracing t√©cnico | Request HTTP completo | `f47ac10b-8c42-11eb` |
| **Correlation ID** | Tracing de negocio | Proceso completo (m√∫ltiples requests) | `order-2024-001` |

**Ejemplo**:
```
Usuario hace pedido:
1. POST /orders ‚Üí correlationId: order-2024-001
2. Kafka: OrderCreatedEvent ‚Üí correlationId: order-2024-001
3. Payment Service procesa ‚Üí correlationId: order-2024-001
4. Notification Service env√≠a email ‚Üí correlationId: order-2024-001

Buscar logs: "order-2024-001" ‚Üí Ves TODO el flujo
```

---

### **Implementaci√≥n en Hexarch**

**`CorrelationIdFilter.java`**:
```java
@Component
@Order(1) // Ejecutar PRIMERO
@Slf4j
public class CorrelationIdFilter extends OncePerRequestFilter {

    private static final String CORRELATION_ID_HEADER = "X-Correlation-ID";
    private static final String CORRELATION_ID_MDC_KEY = "correlationId";

    @Override
    protected void doFilterInternal(
            HttpServletRequest request,
            HttpServletResponse response,
            FilterChain filterChain
    ) throws ServletException, IOException {

        // 1. Obtener o generar Correlation ID
        String correlationId = extractOrGenerateCorrelationId(request);

        // 2. A√±adir al MDC para logs
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId);

        // 3. A√±adir header a response
        response.setHeader(CORRELATION_ID_HEADER, correlationId);

        try {
            filterChain.doFilter(request, response);
        } finally {
            // 4. Limpiar MDC (evita memory leaks)
            MDC.remove(CORRELATION_ID_MDC_KEY);
        }
    }

    private String extractOrGenerateCorrelationId(HttpServletRequest request) {
        String correlationId = request.getHeader(CORRELATION_ID_HEADER);

        if (correlationId == null || correlationId.isBlank()) {
            correlationId = UUID.randomUUID().toString();
            log.debug("Generated new Correlation ID: {}", correlationId);
        } else {
            log.debug("Using existing Correlation ID: {}", correlationId);
        }

        return correlationId;
    }
}
```

**Uso**:
```bash
# Request CON Correlation ID
curl -H "X-Correlation-ID: my-custom-id-123" \
     http://localhost:8080/api/v1/users/550e8400

# Logs:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - Fetching user: 550e8400
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - User found: johndoe

# Request SIN Correlation ID (se genera autom√°ticamente)
curl http://localhost:8080/api/v1/users/550e8400

# Response header:
X-Correlation-ID: 7c3e1f2a-9b8d-4e7f-a1c2-3d4e5f6a7b8c
```

---

## Gesti√≥n de Logs: ELK vs Loki

### **¬øD√≥nde ver los logs?**

#### **Desarrollo Local** üñ•Ô∏è
Los logs se muestran en la **consola** (stdout):
```bash
./mvnw spring-boot:run
# Ves logs en tiempo real:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: userId=123
```

#### **Producci√≥n** üè¢
En producci√≥n necesitas **agregaci√≥n de logs** porque:
- ‚ùå M√∫ltiples instancias (10+ pods) ‚Üí No puedes hacer `kubectl logs` en cada uno
- ‚ùå Logs ef√≠meros ‚Üí Si el pod muere, los logs se pierden
- ‚ùå Sin b√∫squeda ‚Üí No puedes buscar "todos los logs con correlationId=X"

**Soluci√≥n**: Sistema centralizado de logs

---

### **Opci√≥n 1: ELK Stack (Elasticsearch + Logstash + Kibana)** üî•

**Componentes**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Logstash    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Elasticsearch   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Kibana  ‚îÇ
‚îÇ (Spring)    ‚îÇ     ‚îÇ (Procesa)    ‚îÇ     ‚îÇ (Almacena)      ‚îÇ     ‚îÇ (UI)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros**:
- ‚úÖ Muy maduro (10+ a√±os en producci√≥n)
- ‚úÖ B√∫squeda full-text potente (encuentra cualquier palabra en logs)
- ‚úÖ Dashboards ricos en Kibana
- ‚úÖ Integraci√≥n con APM, Machine Learning, alertas avanzadas

**Contras**:
- ‚ùå **Pesado**: Elasticsearch consume ~2GB RAM m√≠nimo
- ‚ùå **Complejo**: Requiere expertise para configurar/mantener
- ‚ùå **Costoso**: Infraestructura cara a escala

**Cu√°ndo usar**:
- Empresas grandes con equipo dedicado
- Necesitas b√∫squeda full-text avanzada
- Ya tienes Elasticsearch en la empresa

---

### **Opci√≥n 2: Grafana Loki + Promtail** ‚≠ê **Recomendado**

**Componentes**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Promtail    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Loki        ‚îÇ
‚îÇ (Spring)    ‚îÇ     ‚îÇ (Agente)     ‚îÇ     ‚îÇ (Almacena)      ‚îÇ
‚îÇ  stdout     ‚îÇ     ‚îÇ Lee logs     ‚îÇ     ‚îÇ Logs indexados  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                                                   ‚ñº
                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                          ‚îÇ    Grafana      ‚îÇ
                                          ‚îÇ Logs + M√©tricas ‚îÇ
                                          ‚îÇ    + Traces     ‚îÇ
                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros**:
- ‚úÖ **Ligero**: ~200MB RAM (10x menos que Elasticsearch)
- ‚úÖ **Simple**: Configuraci√≥n m√≠nima
- ‚úÖ **Unified Observability**: Todo en Grafana (logs + m√©tricas + traces)
- ‚úÖ **Correlaci√≥n f√°cil**: Ver logs y m√©tricas del mismo timestamp
- ‚úÖ **Gratis y open-source**

**Contras**:
- ‚ùå No hace b√∫squeda full-text (usa labels e √≠ndices)
- ‚ùå Menos features que Kibana (pero suficientes para 90% casos)

**Cu√°ndo usar**:
- Proyectos peque√±os/medianos
- Quieres simplicidad
- Ya usas Grafana para m√©tricas (sinergia)

**Diferencia clave**:
- **Elasticsearch**: Indexa TODO el texto ‚Üí Puedes buscar cualquier palabra
- **Loki**: Indexa solo labels (app, level, host) ‚Üí M√°s r√°pido y ligero

---

### **Comparativa R√°pida**

| Aspecto | ELK Stack | Loki + Grafana |
|---------|-----------|----------------|
| **Setup** | Complejo | Simple |
| **RAM** | ~2GB+ | ~200MB |
| **B√∫squeda** | Full-text | Labels + grep |
| **UI** | Kibana | Grafana |
| **Curva aprendizaje** | Alta | Baja |
| **Costo infra** | Alto | Bajo |
| **Observability** | Solo logs | Logs + M√©tricas + Traces |

---

## Setup Local

### **Docker Compose completo (con Loki)**

**`docker-compose-observability.yml`**:
```yaml
version: '3.8'

services:
  # PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hexarch_db
      POSTGRES_USER: hexarch
      POSTGRES_PASSWORD: hexarch123
    ports:
      - "5432:5432"

  # Kafka + Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Prometheus (m√©tricas)
  prometheus:
    image: prom/prometheus:v2.50.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'

  # Loki (almacena logs)
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml

  # Promtail (env√≠a logs a Loki)
  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml
      - ./logs:/var/log/hexarch  # Logs de la app
    command: -config.file=/etc/promtail/config.yml

  # Grafana (dashboards: logs + m√©tricas + traces)
  grafana:
    image: grafana/grafana:10.3.0
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources

  # Zipkin (distributed tracing)
  zipkin:
    image: openzipkin/zipkin:3.0
    ports:
      - "9411:9411"
```

---

### **Configuraci√≥n de Loki**

**`monitoring/loki/loki-config.yml`**:
```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 168h

storage_config:
  boltdb:
    directory: /tmp/loki/index
  filesystem:
    directory: /tmp/loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: false
  retention_period: 0s
```

---

### **Configuraci√≥n de Promtail**

**`monitoring/promtail/promtail-config.yml`**:
```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Logs de Hexarch (Spring Boot)
  - job_name: hexarch
    static_configs:
      - targets:
          - localhost
        labels:
          job: hexarch
          app: hexarch-user-service
          __path__: /var/log/hexarch/spring.log

    # Pipeline para parsear logs
    pipeline_stages:
      # Regex para extraer campos del log
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+) \[(?P<traceId>[^\,]+),(?P<spanId>[^\]]+)\] (?P<correlationId>\S+) (?P<level>\S+)\s+-\s+(?P<message>.*)$'

      # Extraer labels para indexar (b√∫squedas r√°pidas)
      - labels:
          level:
          traceId:
          correlationId:

      # Timestamp del log
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05'
```

---

### **Configuraci√≥n de Grafana Datasources**

**`monitoring/grafana/datasources/datasources.yml`**:
```yaml
apiVersion: 1

datasources:
  # Prometheus (m√©tricas)
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: false

  # Loki (logs)
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
    jsonData:
      maxLines: 1000

  # Zipkin (traces)
  - name: Zipkin
    type: zipkin
    access: proxy
    url: http://zipkin:9411
```

---

### **Configurar Spring Boot para escribir logs a archivo**

**`application.yaml`**:
```yaml
logging:
  file:
    name: logs/spring.log  # Promtail leer√° de aqu√≠
    max-size: 100MB
    max-history: 30  # Mantener 30 d√≠as

  pattern:
    # Mismo formato que consola (para parsear con Promtail)
    file: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

---

### **Comandos**

```bash
# 1. Crear directorios
mkdir -p monitoring/{loki,promtail,grafana/datasources,prometheus}
mkdir -p logs

# 2. Crear archivos de configuraci√≥n (copiar YAML de arriba)

# 3. Levantar infraestructura
docker-compose -f docker-compose-observability.yml up -d

# 4. Verificar servicios
docker-compose ps

# 5. Ejecutar aplicaci√≥n
./mvnw spring-boot:run

# 6. Acceder a UIs
# Prometheus: http://localhost:9090
# Grafana:    http://localhost:3000 (admin/admin)
# Zipkin:     http://localhost:9411
# Loki API:   http://localhost:3100/metrics
```

---

## Buscar Logs en Grafana

### **1. Acceder a Grafana**
```
http://localhost:3000
Login: admin / admin
```

### **2. Ir a Explore**
```
Men√∫ lateral ‚Üí Explore (√≠cono de br√∫jula)
Datasource: Loki
```

### **3. Ejemplos de Queries LogQL**

#### **Todos los logs de la app**:
```logql
{job="hexarch"}
```

#### **Solo logs de ERROR**:
```logql
{job="hexarch", level="ERROR"}
```

#### **Buscar por Correlation ID**:
```logql
{job="hexarch", correlationId="550e8400-e29b-41d4"}
```

#### **Buscar por Trace ID**:
```logql
{job="hexarch", traceId="f47ac10b"}
```

#### **Filtrar por contenido (grep-like)**:
```logql
{job="hexarch"} |= "User created"
```

#### **Logs de los √∫ltimos 5 minutos con ERROR**:
```logql
{job="hexarch", level="ERROR"} [5m]
```

#### **Contar errores por minuto**:
```logql
rate({job="hexarch", level="ERROR"}[1m])
```

---

### **4. Correlaci√≥n: Logs + M√©tricas + Traces**

**Escenario**: Usuario reporta "la creaci√≥n de usuario est√° lenta"

**Paso 1**: Ver m√©trica de latencia
```
Datasource: Prometheus
Query: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket{uri="/api/v1/users"}[5m]))
```

**Paso 2**: Identificar request lento
```
Datasource: Zipkin
Search: minDuration > 500ms
```

**Paso 3**: Ver logs de ese trace
```
Datasource: Loki
Query: {job="hexarch", traceId="f47ac10b"}
```

**Resultado**: Ves TODA la historia del request lento üéØ

---

### **5. Dashboard Unificado en Grafana**

**Panel 1: M√©tricas**
```
Requests/sec, Error rate, Latency p99
```

**Panel 2: Logs en tiempo real**
```logql
{job="hexarch"} | level="ERROR"
```

**Panel 3: Trace spans**
```
Zipkin: requests m√°s lentos
```

**Captura de pantalla** (ejemplo):
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Hexarch Observability Dashboard          [Last 15 min ‚ñº]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìä M√âTRICAS                                                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ ‚îÇ Req/s   ‚îÇ ‚îÇ Errors  ‚îÇ ‚îÇ p99     ‚îÇ ‚îÇ Users   ‚îÇ          ‚îÇ
‚îÇ ‚îÇ  42     ‚îÇ ‚îÇ  0.5%   ‚îÇ ‚îÇ 120ms   ‚îÇ ‚îÇ  1,234  ‚îÇ          ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ üìù LOGS (√∫ltimos 50)                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ 10:30:00 [f47ac] 550e INFO  - User created: id=123  ‚îÇ  ‚îÇ
‚îÇ ‚îÇ 10:30:01 [a23bc] 7f2a WARN  - Retry attempt 2/3     ‚îÇ  ‚îÇ
‚îÇ ‚îÇ 10:30:02 [c45de] 9d4b ERROR - Email send failed     ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ üîó TRACES (slowest 10)                                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ POST /users - 520ms [Ver span timeline]             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ GET /users/123 - 380ms [Ver span timeline]          ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Soluciones Cloud (Managed)

Si tu empresa usa **cloud providers**, puedes usar servicios managed que eliminan el trabajo de mantener la infraestructura:

### **AWS**

**CloudWatch**:
- **CloudWatch Logs**: Almacena logs de ECS/EKS/Lambda
- **CloudWatch Metrics**: M√©tricas custom + m√©tricas de AWS services
- **CloudWatch Insights**: Queries sobre logs (SQL-like)
- **X-Ray**: Distributed tracing

**Setup**:
```yaml
# application.yaml
logging:
  config: classpath:logback-spring-cloudwatch.xml

management:
  metrics:
    export:
      cloudwatch:
        namespace: Hexarch
        enabled: true
```

**Pros**:
- ‚úÖ Cero mantenimiento
- ‚úÖ Integraci√≥n nativa con servicios AWS
- ‚úÖ Escalabilidad autom√°tica

**Contras**:
- ‚ùå Caro a escala (factura por GB de logs)
- ‚ùå UI no tan buena como Grafana/Kibana
- ‚ùå Vendor lock-in

---

### **Azure**

**Azure Monitor**:
- **Log Analytics**: Logs centralizados (usa KQL query language)
- **Application Insights**: APM + distributed tracing
- **Metrics**: M√©tricas custom

**Setup**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>com.microsoft.azure</groupId>
    <artifactId>applicationinsights-spring-boot-starter</artifactId>
</dependency>
```

```yaml
# application.yaml
azure:
  application-insights:
    instrumentation-key: ${APPINSIGHTS_INSTRUMENTATIONKEY}
```

---

### **Google Cloud Platform**

**Cloud Logging (antes Stackdriver)**:
- Logs centralizados
- Integraci√≥n con GKE, Cloud Run, App Engine
- Queries con Log Explorer

**Cloud Trace**: Distributed tracing

---

### **Datadog / New Relic / Splunk** üí∞

Soluciones **SaaS todo-en-uno**:

**Datadog**:
```yaml
# application.yaml
management:
  metrics:
    export:
      datadog:
        api-key: ${DD_API_KEY}
        application-key: ${DD_APP_KEY}
        enabled: true
```

**Pros**:
- ‚úÖ UI excelente (mejor que cloud providers)
- ‚úÖ APM + Logs + M√©tricas + Traces unificado
- ‚úÖ Alerting avanzado
- ‚úÖ Machine Learning para anomaly detection

**Contras**:
- ‚ùå **Muy caro**: $15-50 USD/host/mes
- ‚ùå Vendor lock-in

**Cu√°ndo usar**: Empresas con presupuesto que quieren lo mejor sin complicaciones

---

### **Comparativa: On-Premise vs Cloud**

| Aspecto | Loki/ELK (Self-hosted) | Cloud Managed (AWS/Azure/GCP) | SaaS (Datadog/New Relic) |
|---------|------------------------|-------------------------------|--------------------------|
| **Costo** | Infra + tiempo de setup | Pay-per-use (puede ser caro) | Caro (~$20/host/mes) |
| **Mantenimiento** | T√∫ lo mantienes | Proveedor cloud | Proveedor SaaS |
| **Escalabilidad** | Manual | Autom√°tica | Autom√°tica |
| **UI** | Grafana/Kibana (muy buena) | B√°sica | Excelente |
| **Vendor Lock-in** | ‚ùå No | ‚ö†Ô∏è Medio | ‚úÖ S√≠ |
| **Setup** | Complejo | Medio | Simple (agente) |

---

### **Recomendaci√≥n seg√∫n contexto**

#### **Startup/Proyecto personal**:
‚Üí **Grafana Loki** (gratis, simple, suficiente)

#### **Empresa peque√±a/mediana** (< 50 servicios):
‚Üí **Loki** si tienes DevOps o **CloudWatch/Azure Monitor** si usas cloud

#### **Empresa grande** (50+ servicios):
‚Üí **ELK Stack** (self-hosted) o **Datadog** (si tienes presupuesto)

#### **Regulaciones estrictas** (banca, salud):
‚Üí **ELK on-premise** (control total de datos)

---

## Mejores Pr√°cticas de Logs en Producci√≥n

### **1. Structured Logging (JSON)**

**Problema**: Logs de texto son dif√≠ciles de parsear
```
2024-01-15 10:30:00 User johndoe created with ID 123
```

**Soluci√≥n**: JSON structured logs
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "traceId": "f47ac10b",
  "correlationId": "550e8400",
  "message": "User created",
  "userId": "123",
  "username": "johndoe"
}
```

**Configurar en Spring Boot**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

```xml
<!-- logback-spring.xml -->
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
        <includeMdcKeyName>traceId</includeMdcKeyName>
        <includeMdcKeyName>spanId</includeMdcKeyName>
        <includeMdcKeyName>correlationId</includeMdcKeyName>
    </encoder>
</appender>
```

**Beneficio**: F√°cil de parsear y buscar en Elasticsearch/Loki

---

### **2. Log Retention Policy**

**No guardes logs para siempre** (costoso y poco √∫til):

| Tipo | Retention | Raz√≥n |
|------|-----------|-------|
| **DEBUG** | 1 d√≠a | Solo para troubleshooting activo |
| **INFO** | 30 d√≠as | Suficiente para an√°lisis reciente |
| **WARN** | 90 d√≠as | Detectar problemas recurrentes |
| **ERROR** | 180 d√≠as | Cumplimiento y an√°lisis de incidentes |

**Configurar en Loki**:
```yaml
limits_config:
  retention_period: 720h  # 30 d√≠as
```

**Configurar en Elasticsearch**:
```bash
# Borrar √≠ndices m√°s viejos de 30 d√≠as
curator delete indices --older-than 30 --time-unit days
```

---

### **3. Log Sampling**

**Problema**: Demasiados logs en producci√≥n (millones/d√≠a)

**Soluci√≥n**: Sample logs de INFO, loguea todos los ERROR

```java
@Component
public class SamplingLogger {

    private final Logger log = LoggerFactory.getLogger(SamplingLogger.class);
    private final Random random = new Random();
    private final double sampleRate = 0.1; // 10%

    public void infoSampled(String message, Object... args) {
        if (random.nextDouble() < sampleRate) {
            log.info(message, args);
        }
    }

    public void error(String message, Throwable ex) {
        log.error(message, ex);  // SIEMPRE loguea errores
    }
}
```

---

### **4. Sensitive Data Masking**

**NUNCA loguees datos sensibles**:
- ‚ùå Passwords
- ‚ùå N√∫meros de tarjeta de cr√©dito
- ‚ùå API keys / tokens
- ‚ùå PII (Personally Identifiable Information): SSN, DNI, etc.

**MAL**:
```java
log.info("User login: username={}, password={}", username, password);  // ‚ùå NUNCA
```

**BIEN**:
```java
log.info("User login: username={}", username);  // ‚úÖ Sin password

// Si necesitas loguear email (PII), enmascara
log.info("User created: email={}", maskEmail(email));
// Output: "User created: email=j***@example.com"
```

**Enmascarar autom√°ticamente**:
```java
public class SensitiveDataConverter extends ClassicConverter {
    private static final Pattern EMAIL = Pattern.compile("([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})");

    @Override
    public String convert(ILoggingEvent event) {
        String message = event.getFormattedMessage();
        return EMAIL.matcher(message).replaceAll("***@$2");
    }
}
```

---

### **5. Correlation ID Best Practices**

**Propagar Correlation ID a TODOS los servicios downstream**:

```java
@Component
public class RestTemplateInterceptor implements ClientHttpRequestInterceptor {

    @Override
    public ClientHttpResponse intercept(
            HttpRequest request,
            byte[] body,
            ClientHttpRequestExecution execution
    ) throws IOException {

        // Obtener Correlation ID del MDC
        String correlationId = MDC.get("correlationId");

        // A√±adirlo al header del request saliente
        if (correlationId != null) {
            request.getHeaders().add("X-Correlation-ID", correlationId);
        }

        return execution.execute(request, body);
    }
}
```

**Resultado**: Puedes trazar un request a trav√©s de 10+ microservicios con un solo ID üéØ

---

### **6. Log Levels en Producci√≥n**

**Configuraci√≥n recomendada**:
```yaml
logging:
  level:
    root: INFO  # Default para todo

    # Tu aplicaci√≥n: INFO
    com.example.hexarch: INFO

    # Librer√≠as externas: WARN (reducir ruido)
    org.springframework: WARN
    org.hibernate: WARN
    com.zaxxer.hikari: WARN

    # DEBUG solo para troubleshooting
    # com.example.hexarch.user.infrastructure: DEBUG  # Descomentar si necesitas debug
```

**Cambio din√°mico** (sin reiniciar app):
```bash
# Activar DEBUG temporalmente para un package
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "DEBUG"}'

# Volver a INFO
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "INFO"}'
```

---

## Ejemplos Pr√°cticos en el C√≥digo

### **Ubicaci√≥n en Hexarch**

```
src/main/java/
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îî‚îÄ‚îÄ application/
‚îÇ       ‚îî‚îÄ‚îÄ service/
‚îÇ           ‚îî‚îÄ‚îÄ CreateUserUseCase.java       ‚Üê Logs INFO + M√©trica counter
‚îÇ
‚îú‚îÄ‚îÄ notifications/
‚îÇ   ‚îî‚îÄ‚îÄ application/
‚îÇ       ‚îî‚îÄ‚îÄ service/
‚îÇ           ‚îî‚îÄ‚îÄ EmailService.java            ‚Üê Logs WARN/ERROR + Timer metric
‚îÇ
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ       ‚îî‚îÄ‚îÄ web/
‚îÇ           ‚îî‚îÄ‚îÄ CorrelationIdFilter.java     ‚Üê Correlation ID propagation
‚îÇ
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ MetricsConfig.java                   ‚Üê M√©tricas customizadas
```

---

### **Ver m√©tricas en acci√≥n**

**1. Crear usuario**:
```bash
curl -X POST http://localhost:8080/api/v1/users \
  -H "Content-Type: application/json" \
  -d '{"username": "johndoe", "email": "john@example.com"}'
```

**2. Ver logs** (consola):
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Creating user: username=johndoe
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - User created: userId=123
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Publishing event: UserCreatedEvent
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Event published to Kafka topic: user.created
```

**3. Ver m√©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus | grep users_created
# users_created_total{status="success",environment="local"} 1.0
```

**4. Ver trace en Zipkin**:
- URL: http://localhost:9411
- Buscar trace: `f47ac10b-8c42-11eb-8dcd-0242ac130003`
- Ver timeline de spans

---

## Alerting

### **Alertas en Prometheus**

**`monitoring/prometheus/alerts.yml`**:
```yaml
groups:
  - name: hexarch_alerts
    interval: 30s
    rules:
      # CPU alta
      - alert: HighCPUUsage
        expr: process_cpu_usage > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"

      # Error rate alta
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / rate(http_server_requests_seconds_count[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}% (threshold: 5%)"

      # Latencia p99 alta
      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p99 latency detected"
          description: "p99 latency is {{ $value }}s (threshold: 500ms)"
```

---

### **Notificaciones en Grafana**

**Configurar Slack**:
```yaml
# monitoring/grafana/alerting/notification-channels.yml
apiVersion: 1

notifiers:
  - name: slack
    type: slack
    uid: slack1
    settings:
      url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
      recipient: '#alerts'
      username: Grafana
```

---

## Checklist de Observabilidad

### ‚úÖ **Logs**
- [x] Usar SLF4J + Logback
- [x] Formato estructurado con correlationId
- [x] Nivel correcto (INFO para eventos, ERROR para fallos)
- [x] NO logear la misma exception m√∫ltiples veces
- [x] Incluir contexto (userId, traceId, correlationId)

### ‚úÖ **M√©tricas**
- [x] Actuator habilitado con endpoint `/actuator/prometheus`
- [x] M√©tricas customizadas de negocio (users.created.total)
- [x] Tags para filtrar (environment, status)
- [x] Dashboards en Grafana

### ‚úÖ **Trazas**
- [x] Micrometer Tracing configurado
- [x] Zipkin endpoint configurado
- [x] Sampling rate ajustado (100% dev, 10% prod)
- [x] Correlation ID propagado entre servicios

### ‚úÖ **Alerting**
- [x] Alertas configuradas (CPU, error rate, latency)
- [x] Notificaciones a Slack/PagerDuty
- [x] Runbooks documentados (qu√© hacer cuando alerta se dispara)

---

## Recursos

- [Micrometer Documentation](https://micrometer.io/docs)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Zipkin Documentation](https://zipkin.io/)
- [OpenTelemetry](https://opentelemetry.io/)
- [SLF4J Documentation](https://www.slf4j.org/manual.html)

---

**√öltima actualizaci√≥n**: 2025-10-30
