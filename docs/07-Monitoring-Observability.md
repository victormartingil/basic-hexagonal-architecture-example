# üìä Monitoring & Observability - Hexarch

## √çndice
- [¬øQu√© es Observabilidad?](#qu√©-es-observabilidad)
- [Los 3 Pilares: Logs, M√©tricas y Trazas](#los-3-pilares-logs-m√©tricas-y-trazas)
- [Logs: Cu√°ndo usar cada nivel](#logs-cu√°ndo-usar-cada-nivel)
- [M√©tricas: Prometheus + Grafana](#m√©tricas-prometheus--grafana)
- [Trazas Distribuidas: Zipkin + Micrometer](#trazas-distribuidas-zipkin--micrometer)
- [Propagaci√≥n de TraceId/SpanId: Deep Dive](#propagaci√≥n-de-traceidspanid-deep-dive) ‚≠ê **NUEVO**
  - C√≥mo se genera el TraceId/SpanId
  - Propagaci√≥n en HTTP (W3C Trace Context)
  - Propagaci√≥n en Kafka (headers autom√°ticos)
  - Flujo End-to-End completo (POST /api/v1/users)
  - C√≥mo buscar y analizar trazas en Zipkin UI
  - Ejemplo pr√°ctico: Troubleshooting de errores
  - Configuraci√≥n de sampling para producci√≥n
- [Correlation ID: Tracing de Negocio](#correlation-id-tracing-de-negocio)
- [Setup Local](#setup-local)
- [Ejemplos Pr√°cticos en el C√≥digo](#ejemplos-pr√°cticos-en-el-c√≥digo)
- [Alerting](#alerting)

---

## ¬øQu√© es Observabilidad?

**Observabilidad** es la capacidad de **entender el estado interno** de un sistema bas√°ndose en sus salidas externas (logs, m√©tricas, trazas).

### **Monitoring vs Observability**

| Concepto | Definici√≥n | Ejemplo |
|----------|------------|---------|
| **Monitoring** | Verificar si el sistema funciona (**known unknowns**) | "¬øLa CPU est√° > 80%?" |
| **Observability** | Investigar **por qu√©** falla (**unknown unknowns**) | "¬øPor qu√© este request tard√≥ 5 segundos?" |

**En producci√≥n necesitas AMBOS**:
- **Monitoring**: Dashboards con m√©tricas clave (latencia, error rate, throughput)
- **Observability**: Herramientas para explorar y correlacionar eventos (logs + traces)

---

## Los 3 Pilares: Logs, M√©tricas y Trazas

### **1. LOGS** üìù
**Definici√≥n**: Eventos discretos con timestamp que describen lo que pas√≥.

**Caracter√≠sticas**:
- **Texto estructurado** (mejor JSON para parsing)
- **Timestamp** + **Nivel** (INFO, WARN, ERROR) + **Mensaje**
- **Contexto**: CorrelationId, UserId, TraceId

**Ejemplo**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: username=johndoe
‚îÇ                   ‚îÇ           ‚îÇ        ‚îÇ     ‚îÇ
Timestamp           TraceId     CorrId   Level Message
```

**Cu√°ndo usar**:
- ‚úÖ Debugging: "¬øQu√© pas√≥ justo antes del error?"
- ‚úÖ Auditor√≠a: "¬øQui√©n modific√≥ este recurso?"
- ‚úÖ Troubleshooting: Buscar patrones en fallos

**Herramientas**: ELK Stack (Elasticsearch + Logstash + Kibana), Splunk, CloudWatch Logs

---

### **2. M√âTRICAS** üìà
**Definici√≥n**: Valores num√©ricos agregados a lo largo del tiempo.

**Caracter√≠sticas**:
- **Time-series data**: (timestamp, value)
- **Agregaciones**: sum, avg, percentiles (p50, p99)
- **Eficientes**: Ocupan poco espacio (vs logs)

**Tipos de m√©tricas**:

| Tipo | Descripci√≥n | Ejemplo |
|------|-------------|---------|
| **Counter** | Contador que solo crece | `users_created_total` |
| **Gauge** | Valor instant√°neo (sube/baja) | `users_active_count` |
| **Histogram** | Distribuci√≥n de valores | `http_request_duration_seconds` |
| **Summary** | Similar a histogram + percentiles | `http_request_duration_summary` |

**Cu√°ndo usar**:
- ‚úÖ Dashboards en tiempo real
- ‚úÖ Alertas (CPU > 80%, Error rate > 5%)
- ‚úÖ SLOs (Service Level Objectives): "p99 latency < 500ms"

**Herramientas**: Prometheus, Grafana, Datadog, New Relic

---

### **3. TRAZAS DISTRIBUIDAS** üîó
**Definici√≥n**: Seguimiento de un request a trav√©s de m√∫ltiples servicios.

**Conceptos**:
- **Trace**: Request completo (ej: "Crear usuario desde API hasta BD")
- **Span**: Una operaci√≥n dentro del trace (ej: "INSERT en PostgreSQL")
- **Trace ID**: Identificador √∫nico del trace
- **Span ID**: Identificador √∫nico del span

**Ejemplo visual**:
```
Trace ID: f47ac10b-8c42-11eb-8dcd-0242ac130003

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Span 1: POST /api/v1/users         (200ms)             ‚îÇ
‚îÇ  ‚îú‚îÄ Span 2: Validate email          (5ms)              ‚îÇ
‚îÇ  ‚îú‚îÄ Span 3: Save to PostgreSQL     (50ms)              ‚îÇ
‚îÇ  ‚îî‚îÄ Span 4: Publish Kafka event   (145ms)              ‚îÇ
‚îÇ      ‚îî‚îÄ Span 5: Kafka Producer     (140ms)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Cu√°ndo usar**:
- ‚úÖ Identificar cuellos de botella (ej: "Kafka tarda 140ms")
- ‚úÖ Debugging en microservicios (trazar request entre 5+ servicios)
- ‚úÖ Entender flujo de requests

**Herramientas**: Zipkin, Jaeger, AWS X-Ray, Tempo

---

## Logs: Cu√°ndo usar cada nivel

Spring Boot usa **SLF4J + Logback** con 5 niveles de log:

### **Niveles de Log**

| Nivel | Cu√°ndo Usar | Ejemplo | En Producci√≥n |
|-------|-------------|---------|---------------|
| **TRACE** | Debugging muy detallado | `log.trace("Entering method calculateTax()")` | ‚ùå Desactivado |
| **DEBUG** | Informaci√≥n de desarrollo | `log.debug("Query executed: {}", sql)` | ‚ùå Desactivado |
| **INFO** | Eventos importantes | `log.info("User created: {}", userId)` | ‚úÖ Activado |
| **WARN** | Problemas recuperables | `log.warn("Retry attempt 2/3 failed")` | ‚úÖ Activado |
| **ERROR** | Errores que requieren atenci√≥n | `log.error("Failed to send email", ex)` | ‚úÖ Activado |

---

### **Reglas de Oro para Logging**

#### ‚úÖ **1. INFO: Eventos de negocio importantes**

**Usar para**:
- Usuario creado/modificado/eliminado
- Transacci√≥n completada
- Inicio/fin de procesos batch
- Eventos de auditor√≠a

**Ejemplo**:
```java
@Override
public UserResponse createUser(CreateUserCommand command) {
    log.info("Creating user: username={}, email={}", command.username(), command.email());

    User user = User.create(/* ... */);
    User savedUser = userRepository.save(user);

    log.info("User created successfully: userId={}, username={}",
             savedUser.getId(), savedUser.getUsername());

    return mapper.toResponse(savedUser);
}
```

**¬øCu√°ntos logs INFO?**
- ‚ùå **MAL**: 1 log por cada l√≠nea de c√≥digo (ruido)
- ‚úÖ **BIEN**: 2-3 logs por operaci√≥n importante (inicio, √©xito, fin)

---

#### ‚úÖ **2. DEBUG: Informaci√≥n de desarrollo**

**Usar para**:
- Valores de variables durante desarrollo
- SQL queries ejecutadas
- Par√°metros de entrada a m√©todos
- Estado de objetos

**Ejemplo**:
```java
@Override
public Optional<User> findByEmail(String email) {
    log.debug("Searching user by email: {}", email);

    Optional<UserEntity> entity = jpaRepository.findByEmail(email);

    log.debug("User found: {}", entity.isPresent());

    return entity.map(userMapper::toDomain);
}
```

**Importante**:
- ‚ùå **NO** usar en producci√≥n (genera demasiados logs)
- ‚úÖ Activar solo durante troubleshooting espec√≠fico

---

#### ‚úÖ **3. WARN: Problemas no cr√≠ticos**

**Usar para**:
- Reintentos fallidos (antes del √∫ltimo intento)
- Configuraci√≥n sub√≥ptima detectada
- Uso de valores por defecto
- Deprecation warnings

**Ejemplo**:
```java
@Retryable(maxAttempts = 3)
@Override
public void sendWelcomeEmail(String email) {
    try {
        emailService.send(email, "Welcome!");
        log.info("Welcome email sent to {}", email);
    } catch (EmailException ex) {
        log.warn("Failed to send email to {} (will retry)", email);
        throw ex; // Retry mechanism will catch this
    }
}
```

**¬øCu√°ndo NO usar WARN?**
- ‚ùå Errores esperados (ej: usuario no encontrado ‚Üí usar INFO)
- ‚ùå Validaci√≥n fallida ‚Üí lanzar exception, logear como ERROR si no se captura

---

#### ‚úÖ **4. ERROR: Errores cr√≠ticos**

**Usar para**:
- Exceptions no esperadas
- Fallos en servicios externos
- Inconsistencias de datos
- Cualquier cosa que requiera atenci√≥n inmediata

**Ejemplo**:
```java
@Override
public void handleUserCreatedEvent(UserCreatedEvent event) {
    try {
        emailService.sendWelcomeEmail(event.email());
        log.info("Welcome email sent for user: {}", event.userId());
    } catch (Exception ex) {
        log.error("Failed to send welcome email for user: userId={}, error={}",
                  event.userId(), ex.getMessage(), ex);
        throw ex; // Ser√° enviado a DLT
    }
}
```

**Reglas para ERROR logs**:
1. ‚úÖ **Siempre incluir la exception**: `log.error("msg", exception)`
2. ‚úÖ **Incluir contexto**: userId, transactionId, etc.
3. ‚úÖ **NO logear la misma exception m√∫ltiples veces** (contamina logs)

**Anti-pattern com√∫n**:
```java
// ‚ùå MAL: Logea 3 veces la misma exception
try {
    service.doSomething();
} catch (Exception ex) {
    log.error("Error in layer 1", ex);  // ‚ùå
    throw ex;
}

// En el caller:
try {
    layer1.call();
} catch (Exception ex) {
    log.error("Error in layer 2", ex);  // ‚ùå Duplicado
    throw ex;
}

// En el controller:
try {
    layer2.call();
} catch (Exception ex) {
    log.error("Error in controller", ex);  // ‚ùå Triplicado
    return ResponseEntity.status(500).build();
}
```

**‚úÖ BIEN: Logea solo en el boundary**:
```java
// Domain/Application: Solo lanzan exceptions (NO logean)
public User createUser(...) {
    if (userRepository.existsByEmail(email)) {
        throw new EmailAlreadyExistsException(email);  // NO log aqu√≠
    }
    return userRepository.save(user);
}

// Controller: Logea y maneja
@PostMapping("/users")
public ResponseEntity<UserResponse> createUser(@RequestBody CreateUserRequest request) {
    try {
        UserResponse response = useCase.execute(command);
        return ResponseEntity.status(201).body(response);
    } catch (EmailAlreadyExistsException ex) {
        log.warn("Email already exists: {}", request.email());  // Log en boundary
        return ResponseEntity.status(409).build();
    } catch (Exception ex) {
        log.error("Unexpected error creating user", ex);  // Log en boundary
        return ResponseEntity.status(500).build();
    }
}
```

---

#### ‚úÖ **5. TRACE: Solo para librer√≠as**

**NO usar en c√≥digo de aplicaci√≥n**. Reservado para:
- Spring Framework internals
- Hibernate SQL tracing
- Network debugging

**Activaci√≥n temporal**:
```yaml
logging:
  level:
    org.hibernate.SQL: TRACE  # Ver SQL queries
    org.springframework.web: TRACE  # Ver requests HTTP
```

---

### **Formato de Logs en Hexarch**

**Configurado en `application.yaml`**:
```yaml
logging:
  pattern:
    # Formato: timestamp [traceId,spanId] correlationId level - message
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

**Ejemplo de log**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400-e29b-41d4 INFO  - User created: userId=123, username=johndoe
‚îÇ                   ‚îÇ           ‚îÇ        ‚îÇ                    ‚îÇ     ‚îÇ
Timestamp           TraceId     SpanId   CorrelationId        Level Message
```

**Ventajas**:
- ‚úÖ Buscar todos los logs de un request espec√≠fico: `correlationId:550e8400-e29b-41d4`
- ‚úÖ Ver trace completo en Zipkin: `traceId:f47ac10b`
- ‚úÖ Debugging r√°pido: correlacionar logs entre servicios

---

## M√©tricas: Prometheus + Grafana

### **¬øQu√© es Prometheus?**

**Prometheus** es un sistema de **monitorizaci√≥n basado en m√©tricas time-series**:
- Recolecta m√©tricas mediante **pull** (scraping)
- Almacena en time-series DB
- Query language: **PromQL**
- Integraci√≥n con Grafana para visualizaci√≥n

### **¬øQu√© es Grafana?**

**Grafana** es una plataforma de **visualizaci√≥n y dashboards**:
- Conecta a m√∫ltiples datasources (Prometheus, InfluxDB, ElasticSearch)
- Dashboards interactivos
- Alertas configurables

---

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Actuator: Expone m√©tricas -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- Prometheus: Formato de m√©tricas -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

**2. Configuraci√≥n en `application.yaml`**:
```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics

  endpoint:
    prometheus:
      enabled: true

  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:local}
```

**3. Endpoint de m√©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus
```

**Respuesta**:
```
# HELP jvm_memory_used_bytes The amount of used memory
# TYPE jvm_memory_used_bytes gauge
jvm_memory_used_bytes{area="heap",id="PS Eden Space",} 1.23456789E8

# HELP http_server_requests_seconds Duration of HTTP requests
# TYPE http_server_requests_seconds summary
http_server_requests_seconds_count{exception="None",method="POST",status="201",uri="/api/v1/users",} 42.0
http_server_requests_seconds_sum{exception="None",method="POST",status="201",uri="/api/v1/users",} 2.1
```

---

### **M√©tricas Autom√°ticas (Actuator)**

Spring Boot Actuator **ya expone m√©tricas autom√°ticamente**:

| M√©trica | Descripci√≥n |
|---------|-------------|
| `jvm_memory_used_bytes` | Memoria JVM usada |
| `jvm_threads_live_threads` | Threads activos |
| `jvm_gc_pause_seconds` | Pausas de Garbage Collector |
| `http_server_requests_seconds` | Latencia de requests HTTP |
| `http_server_requests_seconds_count` | Total de requests por endpoint |
| `spring_kafka_listener_seconds` | Latencia de Kafka listeners |
| `hikaricp_connections_active` | Conexiones DB activas |
| `logback_events_total` | Total de logs por nivel |

**No necesitas c√≥digo adicional para estas m√©tricas** ‚úÖ

---

### **M√©tricas Customizadas**

Para m√©tricas de **negocio espec√≠ficas**, usa `MeterRegistry`:

#### **Ejemplo 1: Contador de usuarios creados**

**`CreateUserUseCase.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class CreateUserUseCase {

    private final UserRepositoryPort userRepository;
    private final EventPublisherPort eventPublisher;
    private final MeterRegistry meterRegistry;  // ‚Üê Inyectar

    @Override
    public UserResponse execute(CreateUserCommand command) {
        // ... validaciones ...

        User savedUser = userRepository.save(user);

        // üìä M√©trica custom: contador de usuarios creados
        meterRegistry.counter("users.created.total",
                              "status", "success",
                              "environment", environment)
                     .increment();

        log.info("User created: userId={}, username={}", savedUser.getId(), savedUser.getUsername());

        eventPublisher.publish(userCreatedEvent);

        return mapper.toResponse(savedUser);
    }
}
```

**M√©trica expuesta**:
```
# HELP users_created_total Total number of users created
# TYPE users_created_total counter
users_created_total{status="success",environment="production"} 42.0
```

---

#### **Ejemplo 2: Gauge de usuarios activos**

**`UserMetricsService.java`**:
```java
@Service
@RequiredArgsConstructor
public class UserMetricsService {

    private final UserRepositoryPort userRepository;
    private final MeterRegistry meterRegistry;

    @PostConstruct
    public void registerMetrics() {
        // üìä Gauge: valor que fluct√∫a (sube/baja)
        Gauge.builder("users.active.count", userRepository, repo -> repo.countByEnabled(true))
             .description("Number of active users")
             .register(meterRegistry);
    }
}
```

**M√©trica expuesta**:
```
# HELP users_active_count Number of active users
# TYPE users_active_count gauge
users_active_count 156.0
```

---

#### **Ejemplo 3: Timer de operaciones**

**`EmailService.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class EmailService {

    private final MeterRegistry meterRegistry;

    @CircuitBreaker(name = "emailService", fallbackMethod = "sendEmailFallback")
    @Retry(name = "emailService")
    public void sendWelcomeEmail(String email) {
        // üìä Timer: mide duraci√≥n de operaci√≥n
        Timer.Sample sample = Timer.start(meterRegistry);

        try {
            // Simular env√≠o de email (aqu√≠ ir√≠a integraci√≥n con SMTP/SES)
            Thread.sleep(100);

            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "success"));

            log.info("Welcome email sent to {}", email);
        } catch (Exception ex) {
            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "failure"));
            throw new EmailServiceException("Failed to send email", ex);
        }
    }
}
```

**M√©trica expuesta**:
```
# HELP email_send_duration_seconds Email send duration
# TYPE email_send_duration_seconds summary
email_send_duration_seconds_count{type="welcome",status="success"} 42.0
email_send_duration_seconds_sum{type="welcome",status="success"} 4.2
email_send_duration_seconds{type="welcome",status="success",quantile="0.5",} 0.098
email_send_duration_seconds{type="welcome",status="success",quantile="0.99",} 0.15
```

---

### **Dashboards en Grafana**

**1. A√±adir Prometheus como datasource**:
- URL: `http://prometheus:9090`
- Access: Server (default)

**2. Importar dashboard JVM (Micrometer)**:
- Dashboard ID: `4701` (JVM Micrometer)
- [https://grafana.com/grafana/dashboards/4701](https://grafana.com/grafana/dashboards/4701)

**3. Dashboard custom para Users**:

**Panel 1: Total usuarios creados**
```promql
# Query PromQL
rate(users_created_total[5m])
```

**Panel 2: Usuarios activos (gauge)**
```promql
users_active_count
```

**Panel 3: Latencia p99 de POST /users**
```promql
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket{uri="/api/v1/users", method="POST"}[5m])
)
```

**Panel 4: Error rate**
```promql
rate(http_server_requests_seconds_count{status=~"5.."}[5m]) /
rate(http_server_requests_seconds_count[5m]) * 100
```

**Captura de pantalla** (ejemplo):
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Users Dashboard                             [Last 1 hour ‚ñº] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Total Users     ‚îÇ  ‚îÇ Active Users    ‚îÇ  ‚îÇ Error Rate   ‚îÇ‚îÇ
‚îÇ  ‚îÇ      1,234      ‚îÇ  ‚îÇ       156       ‚îÇ  ‚îÇ    0.5%      ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ POST /users - p99 Latency                                ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà 120ms                            ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Trazas Distribuidas: Zipkin + Micrometer

### **¬øQu√© es Zipkin?**

**Zipkin** es un sistema de **distributed tracing** que:
- Recolecta spans de m√∫ltiples servicios
- Correlaciona spans en un trace completo
- Visualiza el flujo de requests
- Identifica cuellos de botella

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Micrometer Tracing (OpenTelemetry compatible) -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>

<!-- Zipkin Reporter -->
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

**2. Configuraci√≥n en `application.yaml`**:
```yaml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% en dev, 0.1 (10%) en prod

  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans
```

**3. Acceder a Zipkin UI**:
```bash
# URL
http://localhost:9411/zipkin/

# Buscar traces por:
# - serviceName: hexarch
# - traceId: f47ac10b-8c42-11eb-8dcd-0242ac130003
# - minDuration: > 500ms (encontrar lentos)
```

---

### **Visualizaci√≥n de Traces**

**Trace completo: POST /api/v1/users**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Trace: f47ac10b-8c42-11eb-8dcd-0242ac130003 (250ms total)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ ‚îå‚îÄ POST /api/v1/users ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (250ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ                                                              ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îå‚îÄ CreateUserUseCase.execute() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (200ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                          ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ PostgresUserRepository.save() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (40ms) ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ INSERT INTO users ...                           ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                          ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ KafkaEventPublisher.publish() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (150ms) ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ kafka.send(user.created)                        ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üîç Insight: Kafka tarda 150ms de 250ms totales (60% del tiempo)
```

**An√°lisis**:
- Total: 250ms
- PostgreSQL: 40ms (16%)
- Kafka: 150ms (60%) ‚Üê **Cuello de botella**
- L√≥gica aplicaci√≥n: 10ms (4%)
- Overhead: 50ms (20%)

**Acci√≥n**: Optimizar Kafka (async, batching, compression)

---

### **Spans Autom√°ticos**

Spring Boot **ya crea spans autom√°ticamente** para:
- ‚úÖ HTTP requests (`spring-webmvc`)
- ‚úÖ JPA queries (`spring-data-jpa`)
- ‚úÖ Kafka producers/consumers (`spring-kafka`)
- ‚úÖ RestTemplate/WebClient calls
- ‚úÖ JDBC queries

**No necesitas c√≥digo adicional** ‚úÖ

---

### **Spans Manuales (Custom)**

Para operaciones espec√≠ficas, usa `@NewSpan` o `Tracer`:

```java
@Service
@RequiredArgsConstructor
public class ComplexBusinessLogic {

    private final Tracer tracer;

    public void processOrder(Order order) {
        // Crear span manual
        Span span = tracer.nextSpan().name("process-order");

        try (Tracer.SpanInScope ws = tracer.withSpan(span.start())) {
            // A√±adir tags al span
            span.tag("order.id", order.getId());
            span.tag("order.amount", String.valueOf(order.getAmount()));

            // L√≥gica de negocio compleja
            validateOrder(order);
            calculateTax(order);
            saveOrder(order);

        } finally {
            span.end();
        }
    }
}
```

---

## Propagaci√≥n de TraceId/SpanId: Deep Dive

### **¬øC√≥mo se Genera el TraceId y SpanId?**

**Micrometer Tracing** (integrado con Spring Boot) genera autom√°ticamente estos identificadores:

| ID | Descripci√≥n | Formato | Ejemplo |
|----|-------------|---------|---------|
| **Trace ID** | Identificador √∫nico del request completo | 128-bit hex | `f47ac10b8c4211eb8dcd0242ac130003` |
| **Span ID** | Identificador √∫nico de cada operaci√≥n | 64-bit hex | `1a2b3c4d5e6f7890` |
| **Parent Span ID** | ID del span padre (si existe) | 64-bit hex | `0a1b2c3d4e5f6789` |

**Generaci√≥n autom√°tica**:
1. **Primer request** (sin header de tracing):
   - Micrometer genera un **nuevo Trace ID** aleatorio
   - Genera el **primer Span ID** (span ra√≠z)
   - Parent Span ID = null (es el span root)

2. **Operaciones hijas** (dentro del mismo servicio):
   - **Trace ID se mantiene** (mismo request)
   - Se genera un **nuevo Span ID** para cada operaci√≥n
   - Parent Span ID = Span ID del padre

3. **Llamadas entre servicios** (HTTP/Kafka):
   - **Trace ID se propaga** (mismo request distribuido)
   - Se genera un **nuevo Span ID** en el servicio destino
   - Parent Span ID = Span ID del servicio origen

---

### **Propagaci√≥n en HTTP (W3C Trace Context)**

**Micrometer Tracing usa el est√°ndar W3C Trace Context** para propagar trazas en HTTP.

#### **Header: `traceparent`**

Formato: `00-{trace-id}-{parent-id}-{trace-flags}`

**Ejemplo real**:
```http
traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-1a2b3c4d5e6f7890-01
             ‚îÇ  ‚îÇ                                ‚îÇ                ‚îÇ
             ‚îÇ  Trace ID (128-bit)               Span ID (64-bit) Flags (01 = sampled)
             Version (00)
```

**Flags**:
- `01` = Sampled (se est√° trackeando este request)
- `00` = Not sampled (no se trackea - ahorra overhead)

#### **Header: `tracestate` (Opcional)**

Formato: `vendor1=value1,vendor2=value2`

**Ejemplo**:
```http
tracestate: zipkin=sampled,datadog=s:1;o:rum
```

Permite a cada vendor a√±adir su metadata custom.

---

### **Propagaci√≥n en Kafka**

**Micrometer Tracing propaga autom√°ticamente el contexto en headers de Kafka**.

#### **Headers de Kafka con Tracing**

Cuando produces un mensaje a Kafka, Micrometer a√±ade estos headers:

| Header Key | Valor | Descripci√≥n |
|------------|-------|-------------|
| `traceparent` | `00-{trace-id}-{span-id}-01` | W3C Trace Context (mismo formato HTTP) |
| `tracestate` | (opcional) | Vendor-specific metadata |
| `X-B3-TraceId` | `{trace-id}` | Formato B3 (backward compatibility) |
| `X-B3-SpanId` | `{span-id}` | Formato B3 |
| `X-B3-ParentSpanId` | `{parent-span-id}` | Formato B3 |
| `X-B3-Sampled` | `1` o `0` | Si est√° siendo sampled |

**Ejemplo de headers en Kafka**:
```
traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-2b3c4d5e6f7a8b9c-01
X-B3-TraceId: f47ac10b8c4211eb8dcd0242ac130003
X-B3-SpanId: 2b3c4d5e6f7a8b9c
X-B3-ParentSpanId: 1a2b3c4d5e6f7890
X-B3-Sampled: 1
```

#### **Consumer Lee los Headers**

Cuando el consumer recibe el mensaje:
1. **Spring Kafka** lee autom√°ticamente los headers de tracing
2. **Micrometer Tracing** extrae el Trace ID y Span ID
3. **Contin√∫a la traza** en el consumer (mismo Trace ID)
4. **Crea nuevo Span** para el procesamiento del consumer

**NO necesitas c√≥digo manual** - es autom√°tico ‚úÖ

---

### **Flujo End-to-End: POST /api/v1/users**

Veamos c√≥mo se propaga el traceId en un flujo completo de este proyecto:

#### **Paso 1: Request HTTP al API**

**Cliente**:
```bash
curl -X POST http://localhost:8080/api/v1/users \
  -H "Content-Type: application/json" \
  -d '{"username": "johndoe", "email": "john@example.com"}'
```

**Spring Boot recibe el request**:
- ‚ùì ¬øTiene header `traceparent`? ‚Üí NO (request nuevo)
- ‚úÖ **Micrometer genera Trace ID**: `f47ac10b8c4211eb8dcd0242ac130003`
- ‚úÖ **Span ID (HTTP)**: `1a2b3c4d5e6f7890`

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,1a2b3c4d5e6f7890] INFO - Received POST /api/v1/users
                    ‚îÇ                                       ‚îÇ
                    Trace ID                                Span ID (HTTP span)
```

---

#### **Paso 2: UserController ‚Üí CreateUserService**

**C√≥digo** (`UserController.java:42`):
```java
@PostMapping
public ResponseEntity<UserResponse> createUser(@RequestBody @Valid CreateUserRequest request) {
    // Trace ID se propaga autom√°ticamente (ThreadLocal)
    CreateUserCommand command = userRestMapper.toCommand(request);
    UserResult result = createUserUseCase.execute(command);
    return ResponseEntity.status(201).body(userRestMapper.toResponse(result));
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `2b3c4d5e6f7a8b9c` (para el Service)
- Parent Span ID: `1a2b3c4d5e6f7890` (el HTTP span)

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - Creating user: username=johndoe
```

---

#### **Paso 3: CreateUserService ‚Üí PostgreSQL**

**C√≥digo** (`CreateUserService.java:119`):
```java
User user = User.create(command.username(), command.email());
User savedUser = userRepository.save(user);  // ‚Üê Span autom√°tico de JPA
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `3c4d5e6f7a8b9cde` (para la query SQL)
- Parent Span ID: `2b3c4d5e6f7a8b9c` (el Service span)

**Query SQL ejecutada**:
```sql
INSERT INTO users (id, username, email, enabled, created_at)
VALUES ('550e8400-...', 'johndoe', 'john@example.com', true, '2024-01-15 10:30:00')
```

**Span en Zipkin**:
- Nombre: `INSERT users`
- Duraci√≥n: `40ms`
- Tags: `db.system=postgresql`, `db.statement=INSERT INTO users...`

---

#### **Paso 4: CreateUserService ‚Üí Kafka Producer**

**C√≥digo** (`CreateUserService.java:138`):
```java
UserCreatedEvent event = UserCreatedEvent.from(
    savedUser.getId(),
    savedUser.getUsername().getValue(),
    savedUser.getEmail().getValue()
);
userEventPublisher.publish(event);  // ‚Üê Span autom√°tico de Kafka
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `4d5e6f7a8b9cdef0` (para Kafka send)
- Parent Span ID: `2b3c4d5e6f7a8b9c` (el Service span)

**Headers de Kafka enviados**:
```
Key: 550e8400-e29b-41d4-a716-446655440000 (userId)
Headers:
  - traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-4d5e6f7a8b9cdef0-01
  - X-B3-TraceId: f47ac10b8c4211eb8dcd0242ac130003
  - X-B3-SpanId: 4d5e6f7a8b9cdef0
  - X-B3-ParentSpanId: 2b3c4d5e6f7a8b9c
  - X-B3-Sampled: 1
```

**Span en Zipkin**:
- Nombre: `send user.created`
- Duraci√≥n: `150ms`
- Tags: `messaging.system=kafka`, `messaging.destination=user.created`

---

#### **Paso 5: Kafka Consumer (Servicio de Notificaciones)**

**Consumer recibe el mensaje** (`UserEventsKafkaConsumer.java:45`):

```java
@KafkaListener(topics = "user.created", groupId = "notifications-service")
public void handleUserCreated(UserCreatedEvent event, @Header(KafkaHeaders.RECEIVED_KEY) String key) {
    // Micrometer Tracing lee los headers autom√°ticamente
    log.info("Received UserCreatedEvent: userId={}", event.userId());
    emailService.sendWelcomeEmail(event.email(), event.username());
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo - propagado desde Kafka headers)
- **Nuevo Span ID**: `5e6f7a8b9cdef012` (para el consumer)
- Parent Span ID: `4d5e6f7a8b9cdef0` (el Kafka producer span)

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,5e6f7a8b9cdef012] INFO - Received UserCreatedEvent: userId=550e8400...
```

**Span en Zipkin**:
- Nombre: `poll user.created`
- Duraci√≥n: `5ms`
- Tags: `messaging.system=kafka`, `messaging.source=user.created`

---

#### **Paso 6: EmailService (con Circuit Breaker)**

**C√≥digo** (`EmailService.java:25`):
```java
@CircuitBreaker(name = "emailService", fallbackMethod = "sendEmailFallback")
public void sendWelcomeEmail(String email, String username) {
    log.info("Sending welcome email to {}", email);
    // Simulaci√≥n de env√≠o de email
    // En producci√≥n: llamada a SendGrid, SES, etc.
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `6f7a8b9cdef01234` (para el email send)
- Parent Span ID: `5e6f7a8b9cdef012` (el consumer span)

**Span en Zipkin**:
- Nombre: `sendWelcomeEmail`
- Duraci√≥n: `100ms`
- Tags: `email.recipient=john@example.com`, `circuit-breaker=emailService`

---

### **Visualizaci√≥n Completa en Zipkin**

Cuando buscas el Trace ID `f47ac10b8c4211eb8dcd0242ac130003` en Zipkin, ves:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Trace: f47ac10b8c4211eb8dcd0242ac130003                    Total: 295ms         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                  ‚îÇ
‚îÇ ‚îå‚îÄ POST /api/v1/users ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 295ms ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ Span ID: 1a2b3c4d5e6f7890                                                    ‚îÇ‚îÇ
‚îÇ ‚îÇ Service: hexarch                                                              ‚îÇ‚îÇ
‚îÇ ‚îÇ Tags: http.method=POST, http.status_code=201                                 ‚îÇ‚îÇ
‚îÇ ‚îÇ                                                                               ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îå‚îÄ CreateUserService.execute() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 290ms ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ Span ID: 2b3c4d5e6f7a8b9c                                                ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ Service: hexarch                                                          ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                                           ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ INSERT users ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 40ms ‚îÄ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Span ID: 3c4d5e6f7a8b9cde                                            ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Service: hexarch                                                      ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Tags: db.system=postgresql, db.statement=INSERT INTO users...        ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                                           ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ send user.created ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 150ms ‚îÄ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Span ID: 4d5e6f7a8b9cdef0                                            ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Service: hexarch                                                      ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Tags: messaging.system=kafka, messaging.destination=user.created     ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ
‚îÇ ‚îÇ                                                                               ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îå‚îÄ poll user.created ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 105ms ‚îÄ‚îÄ‚îê‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ Span ID: 5e6f7a8b9cdef012                                                ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ Service: notifications-service                                            ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ Tags: messaging.system=kafka, messaging.source=user.created              ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ                                                                           ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îå‚îÄ sendWelcomeEmail ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 100ms ‚îÄ‚îê‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Span ID: 6f7a8b9cdef01234                                            ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Service: notifications-service                                        ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Tags: email.recipient=john@example.com, circuit-breaker=emailService ‚îÇ‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ‚îÇ
‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**An√°lisis del Timeline**:
- HTTP Request: `0ms - 295ms` (295ms total)
- Service execution: `0ms - 290ms` (290ms)
  - PostgreSQL INSERT: `0ms - 40ms` (40ms)
  - Kafka send: `40ms - 190ms` (150ms) ‚Üê **60% del tiempo**
- Kafka consumer: `190ms - 295ms` (105ms)
  - Email send: `195ms - 295ms` (100ms) ‚Üê **95% del consumer**

**Insights**:
1. Kafka produce es el cuello de botella (150ms de 295ms = 51%)
2. Email send tambi√©n es lento (100ms)
3. PostgreSQL es eficiente (40ms)

---

### **C√≥mo Buscar y Analizar Trazas en Zipkin UI**

#### **1. Acceder a Zipkin**

```bash
# Levantar Zipkin con docker-compose
docker-compose up -d zipkin

# Acceder a Zipkin UI
http://localhost:9411
```

---

#### **2. Buscar Trazas por Criterio**

**Filtros disponibles**:

| Filtro | Descripci√≥n | Ejemplo |
|--------|-------------|---------|
| **Service Name** | Filtrar por servicio | `hexarch` |
| **Span Name** | Filtrar por operaci√≥n espec√≠fica | `POST /api/v1/users` |
| **Tags** | Buscar por tags custom | `http.status_code=500` |
| **Duration** | Min/Max duraci√≥n | `> 500ms` (encontrar lentos) |
| **Limit** | N√∫mero de resultados | `10`, `50`, `100` |
| **Lookback** | Ventana de tiempo | `Last hour`, `Last 15 minutes` |

---

#### **3. Buscar Errores (Status 5xx)**

**Objetivo**: Encontrar todas las trazas con errores en las √∫ltimas 24 horas.

**Pasos**:

1. **Click en "Search"** (lupa arriba a la derecha)

2. **Configurar filtros**:
   ```
   Service Name: hexarch
   Tags: error=true
   Lookback: 24 hours
   Limit: 50
   ```

3. **Click en "Run Query"**

4. **Resultado**: Lista de trazas ordenadas por timestamp

**Ejemplo de traza con error**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Trace: a1b2c3d4e5f67890 (ERROR)                  Total: 50ms     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ POST /api/v1/users ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 50ms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ ERROR: UserAlreadyExistsException                             ‚îÇ‚îÇ
‚îÇ ‚îÇ Tags: http.status_code=409, error=true                        ‚îÇ‚îÇ
‚îÇ ‚îÇ Stack Trace:                                                  ‚îÇ‚îÇ
‚îÇ ‚îÇ   com.example.hexarch.user.domain.exception                   ‚îÇ‚îÇ
‚îÇ ‚îÇ     .UserAlreadyExistsException: Username 'johndoe' exists    ‚îÇ‚îÇ
‚îÇ ‚îÇ   at CreateUserService.execute(CreateUserService.java:108)    ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

#### **4. Buscar Trazas Lentas (Performance)**

**Objetivo**: Encontrar requests que tardan m√°s de 500ms.

**Pasos**:

1. **Click en "Search"**

2. **Configurar filtros**:
   ```
   Service Name: hexarch
   Min Duration: 500ms
   Lookback: 1 hour
   Limit: 20
   ```

3. **Click en "Run Query"**

4. **Ordenar por duraci√≥n** (columna "Duration")

**An√°lisis**:
- Click en una traza espec√≠fica
- Ver el timeline (waterfall chart)
- Identificar el span m√°s lento (barra m√°s larga)
- Ver tags del span para entender el contexto

**Ejemplo**:
```
POST /api/v1/users - 1250ms
  ‚îú‚îÄ CreateUserService - 1245ms
  ‚îÇ  ‚îú‚îÄ PostgreSQL INSERT - 45ms  ‚úÖ Normal
  ‚îÇ  ‚îî‚îÄ Kafka send - 1200ms  ‚ö†Ô∏è SLOW! (96% del tiempo)
```

**Acci√≥n**: Investigar por qu√© Kafka tarda 1200ms (network issue? broker overloaded?)

---

#### **5. Buscar por Trace ID Espec√≠fico**

**Caso de uso**: Un usuario reporta un error y te da el Trace ID de su request.

**Pasos**:

1. **Click en "Search"**

2. **Pegar Trace ID**:
   ```
   Trace ID: f47ac10b8c4211eb8dcd0242ac130003
   ```

3. **Click en "Run Query"**

4. **Ver traza completa**:
   - Timeline de todos los spans
   - Latencias de cada operaci√≥n
   - Tags y annotations
   - Logs asociados (si est√°n configurados)

---

#### **6. Analizar Dependencies (Service Map)**

**Objetivo**: Ver c√≥mo se comunican los servicios entre s√≠.

**Pasos**:

1. **Click en "Dependencies"** (men√∫ superior)

2. **Seleccionar ventana de tiempo**:
   ```
   Lookback: Last hour
   ```

3. **Resultado**: Grafo de dependencias

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   hexarch   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚ñ∫ PostgreSQL (40ms avg)
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚ñ∫ Kafka (150ms avg)
              ‚îÇ
              ‚îî‚îÄ‚îÄ‚ñ∫ notifications-service
                      ‚îÇ
                      ‚îî‚îÄ‚îÄ‚ñ∫ EmailService (100ms avg)
```

**Insights**:
- Latencia promedio entre servicios
- N√∫mero de llamadas
- Error rate por conexi√≥n
- Cuellos de botella visuales

---

#### **7. Comparar Trazas (Before vs After Optimization)**

**Caso de uso**: Optimizaste Kafka y quieres comparar el performance.

**Pasos**:

1. **Buscar trazas ANTES de la optimizaci√≥n**:
   ```
   Service Name: hexarch
   Span Name: send user.created
   Lookback: Last 7 days (antes del deploy)
   ```
   - Duraci√≥n promedio: `150ms`

2. **Buscar trazas DESPU√âS de la optimizaci√≥n**:
   ```
   Service Name: hexarch
   Span Name: send user.created
   Lookback: Last hour (despu√©s del deploy)
   ```
   - Duraci√≥n promedio: `50ms`

3. **Resultado**: Mejora del 67% (de 150ms ‚Üí 50ms) ‚úÖ

---

### **Ejemplo Pr√°ctico: Troubleshooting de un Error Real**

**Escenario**: Un usuario reporta que no recibe el email de bienvenida.

#### **Paso 1: Obtener el Trace ID**

**Opci√≥n A**: Del log de la aplicaci√≥n
```bash
# Buscar en logs por email del usuario
grep "john@example.com" /var/log/hexarch/application.log

# Output:
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - Creating user: email=john@example.com
```

**Opci√≥n B**: Del response HTTP (si lo incluyes en headers)
```bash
curl -v http://localhost:8080/api/v1/users ...
< X-Trace-Id: f47ac10b8c4211eb8dcd0242ac130003
```

---

#### **Paso 2: Buscar la Traza en Zipkin**

1. Pegar Trace ID en Zipkin: `f47ac10b8c4211eb8dcd0242ac130003`
2. Click "Run Query"

---

#### **Paso 3: Analizar el Timeline**

**Resultado en Zipkin**:
```
POST /api/v1/users - 295ms ‚úÖ
  ‚îú‚îÄ CreateUserService - 290ms ‚úÖ
  ‚îÇ  ‚îú‚îÄ INSERT users - 40ms ‚úÖ
  ‚îÇ  ‚îî‚îÄ send user.created - 150ms ‚úÖ
  ‚îî‚îÄ poll user.created - MISSING ‚ùå ‚Üê El consumer no proces√≥ el mensaje!
```

**Observaci√≥n**: El mensaje se envi√≥ a Kafka correctamente, pero NO hay span del consumer.

---

#### **Paso 4: Investigar el Consumer**

**Posibles causas**:
1. ‚úÖ **Consumer no est√° corriendo** ‚Üí Revisar `docker-compose ps`
2. ‚úÖ **Consumer tiene errores** ‚Üí Revisar logs del consumer
3. ‚úÖ **Message en Dead Letter Topic** ‚Üí Revisar topic `user.created.dlt`
4. ‚úÖ **Circuit Breaker OPEN** ‚Üí EmailService est√° fallando

**Verificar logs del consumer**:
```bash
docker-compose logs notifications-service | grep "john@example.com"

# Output:
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,5e6f7a8b9cdef012] ERROR - Circuit breaker OPEN - Email no enviado a john@example.com
```

**Root Cause Encontrado**: Circuit Breaker est√° OPEN porque el servicio de email (SendGrid, SES, etc.) est√° ca√≠do.

---

#### **Paso 5: Verificar Circuit Breaker**

```bash
# Revisar m√©tricas de Circuit Breaker
curl http://localhost:8080/actuator/metrics/resilience4j.circuitbreaker.state

{
  "name": "resilience4j.circuitbreaker.state",
  "measurements": [
    { "statistic": "VALUE", "value": 1.0 }  // 1.0 = OPEN
  ],
  "availableTags": [
    { "tag": "name", "values": ["emailService"] }
  ]
}
```

**Confirmado**: Circuit Breaker est√° OPEN.

---

#### **Paso 6: Soluci√≥n**

1. **Verificar servicio externo** (SendGrid, SES): ¬øEst√° disponible?
2. **Esperar a que Circuit Breaker pase a HALF_OPEN** (despu√©s de `wait-duration`)
3. **Reprocesar mensajes del DLT** (Dead Letter Topic) cuando el servicio se recupere

---

### **Configuraci√≥n de Sampling (Producci√≥n)**

En producci√≥n, **no trackees el 100% de los requests** (overhead alto).

**Recomendaciones de sampling**:

| Tr√°fico | Sampling Rate | Justificaci√≥n |
|---------|---------------|---------------|
| **< 100 req/s** | `1.0` (100%) | Bajo overhead, trackea todo |
| **100-1000 req/s** | `0.1` (10%) | Balance entre overhead y visibilidad |
| **> 1000 req/s** | `0.01` (1%) | Solo para identificar patrones, no debugging individual |

**Configuraci√≥n en `application.yaml`**:
```yaml
management:
  tracing:
    sampling:
      probability: ${TRACING_SAMPLING_RATE:0.1}  # 10% por defecto
```

**Variables de entorno por environment**:
```bash
# Local/Dev: 100% sampling
TRACING_SAMPLING_RATE=1.0

# Staging: 50% sampling
TRACING_SAMPLING_RATE=0.5

# Production: 10% sampling
TRACING_SAMPLING_RATE=0.1

# Production (alta carga): 1% sampling
TRACING_SAMPLING_RATE=0.01
```

---

### **Mejores Pr√°cticas de Tracing**

#### **1. A√±adir Tags Custom en Spans**

**Tags √∫tiles**:
```java
@Service
public class CreateUserService {

    private final Tracer tracer;

    public UserResult execute(CreateUserCommand command) {
        // Obtener span actual
        Span span = tracer.currentSpan();

        if (span != null) {
            // A√±adir tags de negocio
            span.tag("user.username", command.username());
            span.tag("user.email", command.email());
            span.tag("business.operation", "user-registration");
        }

        // ... resto de la l√≥gica
    }
}
```

**Beneficio**: Filtrar en Zipkin por `user.username=johndoe` o `business.operation=user-registration`.

---

#### **2. Propagar Trace ID en Responses HTTP**

**A√±ade el Trace ID al response header** para que el cliente pueda reportarlo en caso de error.

**C√≥digo** (`GlobalResponseFilter.java`):
```java
@Component
public class TraceIdResponseFilter implements Filter {

    private final Tracer tracer;

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
            throws IOException, ServletException {

        HttpServletResponse httpResponse = (HttpServletResponse) response;

        // Obtener Trace ID actual
        Span span = tracer.currentSpan();
        if (span != null) {
            String traceId = span.context().traceId();
            httpResponse.setHeader("X-Trace-Id", traceId);
        }

        chain.doFilter(request, response);
    }
}
```

**Response**:
```http
HTTP/1.1 201 Created
X-Trace-Id: f47ac10b8c4211eb8dcd0242ac130003
Content-Type: application/json
...
```

**Beneficio**: El cliente puede reportar el Trace ID en soporte: "Mi request con Trace ID `f47ac10b...` fall√≥".

---

#### **3. Logging con Trace ID**

Micrometer Tracing **autom√°ticamente a√±ade Trace ID y Span ID a los logs** (ya est√° configurado en este proyecto).

**Log format en `logback-spring.xml`**:
```xml
<pattern>%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %5p - %m%n</pattern>
```

**Output**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - User created: userId=550e8400
```

**Beneficio**: Correlacionar logs con trazas en Zipkin.

---

#### **4. Monitorizar Latencias con Alertas**

**Crear alerta en Grafana**:
```promql
# Latencia p99 de POST /api/v1/users > 500ms
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket{
    uri="/api/v1/users",
    method="POST"
  }[5m])
) > 0.5
```

**Acci√≥n**: Si se dispara, buscar trazas en Zipkin con `Min Duration: 500ms` para identificar el cuello de botella.

---

## Correlation ID: Tracing de Negocio

### **¬øQu√© es Correlation ID?**

**Correlation ID** es un **identificador de negocio** que:
- Correlaciona logs entre m√∫ltiples servicios
- Es independiente de Trace ID (t√©cnico)
- Se propaga en header HTTP: `X-Correlation-ID`

**Diferencias**:

| Concepto | Prop√≥sito | Scope | Ejemplo |
|----------|-----------|-------|---------|
| **Trace ID** | Tracing t√©cnico | Request HTTP completo | `f47ac10b-8c42-11eb` |
| **Correlation ID** | Tracing de negocio | Proceso completo (m√∫ltiples requests) | `order-2024-001` |

**Ejemplo**:
```
Usuario hace pedido:
1. POST /orders ‚Üí correlationId: order-2024-001
2. Kafka: OrderCreatedEvent ‚Üí correlationId: order-2024-001
3. Payment Service procesa ‚Üí correlationId: order-2024-001
4. Notification Service env√≠a email ‚Üí correlationId: order-2024-001

Buscar logs: "order-2024-001" ‚Üí Ves TODO el flujo
```

---

### **Implementaci√≥n en Hexarch**

**`CorrelationIdFilter.java`**:
```java
@Component
@Order(1) // Ejecutar PRIMERO
@Slf4j
public class CorrelationIdFilter extends OncePerRequestFilter {

    private static final String CORRELATION_ID_HEADER = "X-Correlation-ID";
    private static final String CORRELATION_ID_MDC_KEY = "correlationId";

    @Override
    protected void doFilterInternal(
            HttpServletRequest request,
            HttpServletResponse response,
            FilterChain filterChain
    ) throws ServletException, IOException {

        // 1. Obtener o generar Correlation ID
        String correlationId = extractOrGenerateCorrelationId(request);

        // 2. A√±adir al MDC para logs
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId);

        // 3. A√±adir header a response
        response.setHeader(CORRELATION_ID_HEADER, correlationId);

        try {
            filterChain.doFilter(request, response);
        } finally {
            // 4. Limpiar MDC (evita memory leaks)
            MDC.remove(CORRELATION_ID_MDC_KEY);
        }
    }

    private String extractOrGenerateCorrelationId(HttpServletRequest request) {
        String correlationId = request.getHeader(CORRELATION_ID_HEADER);

        if (correlationId == null || correlationId.isBlank()) {
            correlationId = UUID.randomUUID().toString();
            log.debug("Generated new Correlation ID: {}", correlationId);
        } else {
            log.debug("Using existing Correlation ID: {}", correlationId);
        }

        return correlationId;
    }
}
```

**Uso**:
```bash
# Request CON Correlation ID
curl -H "X-Correlation-ID: my-custom-id-123" \
     http://localhost:8080/api/v1/users/550e8400

# Logs:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - Fetching user: 550e8400
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - User found: johndoe

# Request SIN Correlation ID (se genera autom√°ticamente)
curl http://localhost:8080/api/v1/users/550e8400

# Response header:
X-Correlation-ID: 7c3e1f2a-9b8d-4e7f-a1c2-3d4e5f6a7b8c
```

---

## Gesti√≥n de Logs: ELK vs Loki

### **¬øD√≥nde ver los logs?**

#### **Desarrollo Local** üñ•Ô∏è
Los logs se muestran en la **consola** (stdout):
```bash
./mvnw spring-boot:run
# Ves logs en tiempo real:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: userId=123
```

#### **Producci√≥n** üè¢
En producci√≥n necesitas **agregaci√≥n de logs** porque:
- ‚ùå M√∫ltiples instancias (10+ pods) ‚Üí No puedes hacer `kubectl logs` en cada uno
- ‚ùå Logs ef√≠meros ‚Üí Si el pod muere, los logs se pierden
- ‚ùå Sin b√∫squeda ‚Üí No puedes buscar "todos los logs con correlationId=X"

**Soluci√≥n**: Sistema centralizado de logs

---

### **Opci√≥n 1: ELK Stack (Elasticsearch + Logstash + Kibana)** üî•

**Componentes**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Logstash    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Elasticsearch   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Kibana  ‚îÇ
‚îÇ (Spring)    ‚îÇ     ‚îÇ (Procesa)    ‚îÇ     ‚îÇ (Almacena)      ‚îÇ     ‚îÇ (UI)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros**:
- ‚úÖ Muy maduro (10+ a√±os en producci√≥n)
- ‚úÖ B√∫squeda full-text potente (encuentra cualquier palabra en logs)
- ‚úÖ Dashboards ricos en Kibana
- ‚úÖ Integraci√≥n con APM, Machine Learning, alertas avanzadas

**Contras**:
- ‚ùå **Pesado**: Elasticsearch consume ~2GB RAM m√≠nimo
- ‚ùå **Complejo**: Requiere expertise para configurar/mantener
- ‚ùå **Costoso**: Infraestructura cara a escala

**Cu√°ndo usar**:
- Empresas grandes con equipo dedicado
- Necesitas b√∫squeda full-text avanzada
- Ya tienes Elasticsearch en la empresa

---

### **Opci√≥n 2: Grafana Loki + Promtail** ‚≠ê **Recomendado**

**Componentes**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   App       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Promtail    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Loki        ‚îÇ
‚îÇ (Spring)    ‚îÇ     ‚îÇ (Agente)     ‚îÇ     ‚îÇ (Almacena)      ‚îÇ
‚îÇ  stdout     ‚îÇ     ‚îÇ Lee logs     ‚îÇ     ‚îÇ Logs indexados  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                                                   ‚ñº
                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                          ‚îÇ    Grafana      ‚îÇ
                                          ‚îÇ Logs + M√©tricas ‚îÇ
                                          ‚îÇ    + Traces     ‚îÇ
                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros**:
- ‚úÖ **Ligero**: ~200MB RAM (10x menos que Elasticsearch)
- ‚úÖ **Simple**: Configuraci√≥n m√≠nima
- ‚úÖ **Unified Observability**: Todo en Grafana (logs + m√©tricas + traces)
- ‚úÖ **Correlaci√≥n f√°cil**: Ver logs y m√©tricas del mismo timestamp
- ‚úÖ **Gratis y open-source**

**Contras**:
- ‚ùå No hace b√∫squeda full-text (usa labels e √≠ndices)
- ‚ùå Menos features que Kibana (pero suficientes para 90% casos)

**Cu√°ndo usar**:
- Proyectos peque√±os/medianos
- Quieres simplicidad
- Ya usas Grafana para m√©tricas (sinergia)

**Diferencia clave**:
- **Elasticsearch**: Indexa TODO el texto ‚Üí Puedes buscar cualquier palabra
- **Loki**: Indexa solo labels (app, level, host) ‚Üí M√°s r√°pido y ligero

---

### **Comparativa R√°pida**

| Aspecto | ELK Stack | Loki + Grafana |
|---------|-----------|----------------|
| **Setup** | Complejo | Simple |
| **RAM** | ~2GB+ | ~200MB |
| **B√∫squeda** | Full-text | Labels + grep |
| **UI** | Kibana | Grafana |
| **Curva aprendizaje** | Alta | Baja |
| **Costo infra** | Alto | Bajo |
| **Observability** | Solo logs | Logs + M√©tricas + Traces |

---

## Setup Local

### **Docker Compose completo (con Loki)**

**`docker-compose-observability.yml`**:
```yaml
version: '3.8'

services:
  # PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hexarch_db
      POSTGRES_USER: hexarch
      POSTGRES_PASSWORD: hexarch123
    ports:
      - "5432:5432"

  # Kafka + Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Prometheus (m√©tricas)
  prometheus:
    image: prom/prometheus:v2.50.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'

  # Loki (almacena logs)
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml

  # Promtail (env√≠a logs a Loki)
  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml
      - ./logs:/var/log/hexarch  # Logs de la app
    command: -config.file=/etc/promtail/config.yml

  # Grafana (dashboards: logs + m√©tricas + traces)
  grafana:
    image: grafana/grafana:10.3.0
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources

  # Zipkin (distributed tracing)
  zipkin:
    image: openzipkin/zipkin:3.0
    ports:
      - "9411:9411"
```

---

### **Configuraci√≥n de Loki**

**`monitoring/loki/loki-config.yml`**:
```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 168h

storage_config:
  boltdb:
    directory: /tmp/loki/index
  filesystem:
    directory: /tmp/loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: false
  retention_period: 0s
```

---

### **Configuraci√≥n de Promtail**

**`monitoring/promtail/promtail-config.yml`**:
```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Logs de Hexarch (Spring Boot)
  - job_name: hexarch
    static_configs:
      - targets:
          - localhost
        labels:
          job: hexarch
          app: hexarch-user-service
          __path__: /var/log/hexarch/spring.log

    # Pipeline para parsear logs
    pipeline_stages:
      # Regex para extraer campos del log
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+) \[(?P<traceId>[^\,]+),(?P<spanId>[^\]]+)\] (?P<correlationId>\S+) (?P<level>\S+)\s+-\s+(?P<message>.*)$'

      # Extraer labels para indexar (b√∫squedas r√°pidas)
      - labels:
          level:
          traceId:
          correlationId:

      # Timestamp del log
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05'
```

---

### **Configuraci√≥n de Grafana Datasources**

**`monitoring/grafana/datasources/datasources.yml`**:
```yaml
apiVersion: 1

datasources:
  # Prometheus (m√©tricas)
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: false

  # Loki (logs)
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
    jsonData:
      maxLines: 1000

  # Zipkin (traces)
  - name: Zipkin
    type: zipkin
    access: proxy
    url: http://zipkin:9411
```

---

### **Configurar Spring Boot para escribir logs a archivo**

**`application.yaml`**:
```yaml
logging:
  file:
    name: logs/spring.log  # Promtail leer√° de aqu√≠
    max-size: 100MB
    max-history: 30  # Mantener 30 d√≠as

  pattern:
    # Mismo formato que consola (para parsear con Promtail)
    file: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

---

### **Comandos**

```bash
# 1. Crear directorios
mkdir -p monitoring/{loki,promtail,grafana/datasources,prometheus}
mkdir -p logs

# 2. Crear archivos de configuraci√≥n (copiar YAML de arriba)

# 3. Levantar infraestructura
docker-compose -f docker-compose-observability.yml up -d

# 4. Verificar servicios
docker-compose ps

# 5. Ejecutar aplicaci√≥n
./mvnw spring-boot:run

# 6. Acceder a UIs
# Prometheus: http://localhost:9090
# Grafana:    http://localhost:3000 (admin/admin)
# Zipkin:     http://localhost:9411
# Loki API:   http://localhost:3100/metrics
```

---

## Buscar Logs en Grafana

### **1. Acceder a Grafana**
```
http://localhost:3000
Login: admin / admin
```

### **2. Ir a Explore**
```
Men√∫ lateral ‚Üí Explore (√≠cono de br√∫jula)
Datasource: Loki
```

### **3. Ejemplos de Queries LogQL**

#### **Todos los logs de la app**:
```logql
{job="hexarch"}
```

#### **Solo logs de ERROR**:
```logql
{job="hexarch", level="ERROR"}
```

#### **Buscar por Correlation ID**:
```logql
{job="hexarch", correlationId="550e8400-e29b-41d4"}
```

#### **Buscar por Trace ID**:
```logql
{job="hexarch", traceId="f47ac10b"}
```

#### **Filtrar por contenido (grep-like)**:
```logql
{job="hexarch"} |= "User created"
```

#### **Logs de los √∫ltimos 5 minutos con ERROR**:
```logql
{job="hexarch", level="ERROR"} [5m]
```

#### **Contar errores por minuto**:
```logql
rate({job="hexarch", level="ERROR"}[1m])
```

---

### **4. Correlaci√≥n: Logs + M√©tricas + Traces**

**Escenario**: Usuario reporta "la creaci√≥n de usuario est√° lenta"

**Paso 1**: Ver m√©trica de latencia
```
Datasource: Prometheus
Query: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket{uri="/api/v1/users"}[5m]))
```

**Paso 2**: Identificar request lento
```
Datasource: Zipkin
Search: minDuration > 500ms
```

**Paso 3**: Ver logs de ese trace
```
Datasource: Loki
Query: {job="hexarch", traceId="f47ac10b"}
```

**Resultado**: Ves TODA la historia del request lento üéØ

---

### **5. Dashboard Unificado en Grafana**

**Panel 1: M√©tricas**
```
Requests/sec, Error rate, Latency p99
```

**Panel 2: Logs en tiempo real**
```logql
{job="hexarch"} | level="ERROR"
```

**Panel 3: Trace spans**
```
Zipkin: requests m√°s lentos
```

**Captura de pantalla** (ejemplo):
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Hexarch Observability Dashboard          [Last 15 min ‚ñº]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìä M√âTRICAS                                                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ ‚îÇ Req/s   ‚îÇ ‚îÇ Errors  ‚îÇ ‚îÇ p99     ‚îÇ ‚îÇ Users   ‚îÇ          ‚îÇ
‚îÇ ‚îÇ  42     ‚îÇ ‚îÇ  0.5%   ‚îÇ ‚îÇ 120ms   ‚îÇ ‚îÇ  1,234  ‚îÇ          ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ üìù LOGS (√∫ltimos 50)                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ 10:30:00 [f47ac] 550e INFO  - User created: id=123  ‚îÇ  ‚îÇ
‚îÇ ‚îÇ 10:30:01 [a23bc] 7f2a WARN  - Retry attempt 2/3     ‚îÇ  ‚îÇ
‚îÇ ‚îÇ 10:30:02 [c45de] 9d4b ERROR - Email send failed     ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ üîó TRACES (slowest 10)                                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ POST /users - 520ms [Ver span timeline]             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ GET /users/123 - 380ms [Ver span timeline]          ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Soluciones Cloud (Managed)

Si tu empresa usa **cloud providers**, puedes usar servicios managed que eliminan el trabajo de mantener la infraestructura:

### **AWS**

**CloudWatch**:
- **CloudWatch Logs**: Almacena logs de ECS/EKS/Lambda
- **CloudWatch Metrics**: M√©tricas custom + m√©tricas de AWS services
- **CloudWatch Insights**: Queries sobre logs (SQL-like)
- **X-Ray**: Distributed tracing

**Setup**:
```yaml
# application.yaml
logging:
  config: classpath:logback-spring-cloudwatch.xml

management:
  metrics:
    export:
      cloudwatch:
        namespace: Hexarch
        enabled: true
```

**Pros**:
- ‚úÖ Cero mantenimiento
- ‚úÖ Integraci√≥n nativa con servicios AWS
- ‚úÖ Escalabilidad autom√°tica

**Contras**:
- ‚ùå Caro a escala (factura por GB de logs)
- ‚ùå UI no tan buena como Grafana/Kibana
- ‚ùå Vendor lock-in

---

### **Azure**

**Azure Monitor**:
- **Log Analytics**: Logs centralizados (usa KQL query language)
- **Application Insights**: APM + distributed tracing
- **Metrics**: M√©tricas custom

**Setup**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>com.microsoft.azure</groupId>
    <artifactId>applicationinsights-spring-boot-starter</artifactId>
</dependency>
```

```yaml
# application.yaml
azure:
  application-insights:
    instrumentation-key: ${APPINSIGHTS_INSTRUMENTATIONKEY}
```

---

### **Google Cloud Platform**

**Cloud Logging (antes Stackdriver)**:
- Logs centralizados
- Integraci√≥n con GKE, Cloud Run, App Engine
- Queries con Log Explorer

**Cloud Trace**: Distributed tracing

---

### **Datadog / New Relic / Splunk** üí∞

Soluciones **SaaS todo-en-uno**:

**Datadog**:
```yaml
# application.yaml
management:
  metrics:
    export:
      datadog:
        api-key: ${DD_API_KEY}
        application-key: ${DD_APP_KEY}
        enabled: true
```

**Pros**:
- ‚úÖ UI excelente (mejor que cloud providers)
- ‚úÖ APM + Logs + M√©tricas + Traces unificado
- ‚úÖ Alerting avanzado
- ‚úÖ Machine Learning para anomaly detection

**Contras**:
- ‚ùå **Muy caro**: $15-50 USD/host/mes
- ‚ùå Vendor lock-in

**Cu√°ndo usar**: Empresas con presupuesto que quieren lo mejor sin complicaciones

---

### **Comparativa: On-Premise vs Cloud**

| Aspecto | Loki/ELK (Self-hosted) | Cloud Managed (AWS/Azure/GCP) | SaaS (Datadog/New Relic) |
|---------|------------------------|-------------------------------|--------------------------|
| **Costo** | Infra + tiempo de setup | Pay-per-use (puede ser caro) | Caro (~$20/host/mes) |
| **Mantenimiento** | T√∫ lo mantienes | Proveedor cloud | Proveedor SaaS |
| **Escalabilidad** | Manual | Autom√°tica | Autom√°tica |
| **UI** | Grafana/Kibana (muy buena) | B√°sica | Excelente |
| **Vendor Lock-in** | ‚ùå No | ‚ö†Ô∏è Medio | ‚úÖ S√≠ |
| **Setup** | Complejo | Medio | Simple (agente) |

---

### **Recomendaci√≥n seg√∫n contexto**

#### **Startup/Proyecto personal**:
‚Üí **Grafana Loki** (gratis, simple, suficiente)

#### **Empresa peque√±a/mediana** (< 50 servicios):
‚Üí **Loki** si tienes DevOps o **CloudWatch/Azure Monitor** si usas cloud

#### **Empresa grande** (50+ servicios):
‚Üí **ELK Stack** (self-hosted) o **Datadog** (si tienes presupuesto)

#### **Regulaciones estrictas** (banca, salud):
‚Üí **ELK on-premise** (control total de datos)

---

## Mejores Pr√°cticas de Logs en Producci√≥n

### **1. Structured Logging (JSON)**

**Problema**: Logs de texto son dif√≠ciles de parsear
```
2024-01-15 10:30:00 User johndoe created with ID 123
```

**Soluci√≥n**: JSON structured logs
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "traceId": "f47ac10b",
  "correlationId": "550e8400",
  "message": "User created",
  "userId": "123",
  "username": "johndoe"
}
```

**Configurar en Spring Boot**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

```xml
<!-- logback-spring.xml -->
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
        <includeMdcKeyName>traceId</includeMdcKeyName>
        <includeMdcKeyName>spanId</includeMdcKeyName>
        <includeMdcKeyName>correlationId</includeMdcKeyName>
    </encoder>
</appender>
```

**Beneficio**: F√°cil de parsear y buscar en Elasticsearch/Loki

---

### **2. Log Retention Policy**

**No guardes logs para siempre** (costoso y poco √∫til):

| Tipo | Retention | Raz√≥n |
|------|-----------|-------|
| **DEBUG** | 1 d√≠a | Solo para troubleshooting activo |
| **INFO** | 30 d√≠as | Suficiente para an√°lisis reciente |
| **WARN** | 90 d√≠as | Detectar problemas recurrentes |
| **ERROR** | 180 d√≠as | Cumplimiento y an√°lisis de incidentes |

**Configurar en Loki**:
```yaml
limits_config:
  retention_period: 720h  # 30 d√≠as
```

**Configurar en Elasticsearch**:
```bash
# Borrar √≠ndices m√°s viejos de 30 d√≠as
curator delete indices --older-than 30 --time-unit days
```

---

### **3. Log Sampling**

**Problema**: Demasiados logs en producci√≥n (millones/d√≠a)

**Soluci√≥n**: Sample logs de INFO, loguea todos los ERROR

```java
@Component
public class SamplingLogger {

    private final Logger log = LoggerFactory.getLogger(SamplingLogger.class);
    private final Random random = new Random();
    private final double sampleRate = 0.1; // 10%

    public void infoSampled(String message, Object... args) {
        if (random.nextDouble() < sampleRate) {
            log.info(message, args);
        }
    }

    public void error(String message, Throwable ex) {
        log.error(message, ex);  // SIEMPRE loguea errores
    }
}
```

---

### **4. Sensitive Data Masking**

**NUNCA loguees datos sensibles**:
- ‚ùå Passwords
- ‚ùå N√∫meros de tarjeta de cr√©dito
- ‚ùå API keys / tokens
- ‚ùå PII (Personally Identifiable Information): SSN, DNI, etc.

**MAL**:
```java
log.info("User login: username={}, password={}", username, password);  // ‚ùå NUNCA
```

**BIEN**:
```java
log.info("User login: username={}", username);  // ‚úÖ Sin password

// Si necesitas loguear email (PII), enmascara
log.info("User created: email={}", maskEmail(email));
// Output: "User created: email=j***@example.com"
```

**Enmascarar autom√°ticamente**:
```java
public class SensitiveDataConverter extends ClassicConverter {
    private static final Pattern EMAIL = Pattern.compile("([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})");

    @Override
    public String convert(ILoggingEvent event) {
        String message = event.getFormattedMessage();
        return EMAIL.matcher(message).replaceAll("***@$2");
    }
}
```

---

### **5. Correlation ID Best Practices**

**Propagar Correlation ID a TODOS los servicios downstream**:

```java
@Component
public class RestTemplateInterceptor implements ClientHttpRequestInterceptor {

    @Override
    public ClientHttpResponse intercept(
            HttpRequest request,
            byte[] body,
            ClientHttpRequestExecution execution
    ) throws IOException {

        // Obtener Correlation ID del MDC
        String correlationId = MDC.get("correlationId");

        // A√±adirlo al header del request saliente
        if (correlationId != null) {
            request.getHeaders().add("X-Correlation-ID", correlationId);
        }

        return execution.execute(request, body);
    }
}
```

**Resultado**: Puedes trazar un request a trav√©s de 10+ microservicios con un solo ID üéØ

---

### **6. Log Levels en Producci√≥n**

**Configuraci√≥n recomendada**:
```yaml
logging:
  level:
    root: INFO  # Default para todo

    # Tu aplicaci√≥n: INFO
    com.example.hexarch: INFO

    # Librer√≠as externas: WARN (reducir ruido)
    org.springframework: WARN
    org.hibernate: WARN
    com.zaxxer.hikari: WARN

    # DEBUG solo para troubleshooting
    # com.example.hexarch.user.infrastructure: DEBUG  # Descomentar si necesitas debug
```

**Cambio din√°mico** (sin reiniciar app):
```bash
# Activar DEBUG temporalmente para un package
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "DEBUG"}'

# Volver a INFO
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "INFO"}'
```

---

## Ejemplos Pr√°cticos en el C√≥digo

### **Ubicaci√≥n en Hexarch**

```
src/main/java/
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îî‚îÄ‚îÄ application/
‚îÇ       ‚îî‚îÄ‚îÄ service/
‚îÇ           ‚îî‚îÄ‚îÄ CreateUserUseCase.java       ‚Üê Logs INFO + M√©trica counter
‚îÇ
‚îú‚îÄ‚îÄ notifications/
‚îÇ   ‚îî‚îÄ‚îÄ application/
‚îÇ       ‚îî‚îÄ‚îÄ service/
‚îÇ           ‚îî‚îÄ‚îÄ EmailService.java            ‚Üê Logs WARN/ERROR + Timer metric
‚îÇ
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ       ‚îî‚îÄ‚îÄ web/
‚îÇ           ‚îî‚îÄ‚îÄ CorrelationIdFilter.java     ‚Üê Correlation ID propagation
‚îÇ
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ MetricsConfig.java                   ‚Üê M√©tricas customizadas
```

---

### **Ver m√©tricas en acci√≥n**

**1. Crear usuario**:
```bash
curl -X POST http://localhost:8080/api/v1/users \
  -H "Content-Type: application/json" \
  -d '{"username": "johndoe", "email": "john@example.com"}'
```

**2. Ver logs** (consola):
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Creating user: username=johndoe
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - User created: userId=123
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Publishing event: UserCreatedEvent
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Event published to Kafka topic: user.created
```

**3. Ver m√©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus | grep users_created
# users_created_total{status="success",environment="local"} 1.0
```

**4. Ver trace en Zipkin**:
- URL: http://localhost:9411
- Buscar trace: `f47ac10b-8c42-11eb-8dcd-0242ac130003`
- Ver timeline de spans

---

## Alerting

### **Alertas en Prometheus**

**`monitoring/prometheus/alerts.yml`**:
```yaml
groups:
  - name: hexarch_alerts
    interval: 30s
    rules:
      # CPU alta
      - alert: HighCPUUsage
        expr: process_cpu_usage > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"

      # Error rate alta
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / rate(http_server_requests_seconds_count[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}% (threshold: 5%)"

      # Latencia p99 alta
      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p99 latency detected"
          description: "p99 latency is {{ $value }}s (threshold: 500ms)"
```

---

### **Notificaciones en Grafana**

**Configurar Slack**:
```yaml
# monitoring/grafana/alerting/notification-channels.yml
apiVersion: 1

notifiers:
  - name: slack
    type: slack
    uid: slack1
    settings:
      url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
      recipient: '#alerts'
      username: Grafana
```

---

## Checklist de Observabilidad

### ‚úÖ **Logs**
- [x] Usar SLF4J + Logback
- [x] Formato estructurado con correlationId
- [x] Nivel correcto (INFO para eventos, ERROR para fallos)
- [x] NO logear la misma exception m√∫ltiples veces
- [x] Incluir contexto (userId, traceId, correlationId)

### ‚úÖ **M√©tricas**
- [x] Actuator habilitado con endpoint `/actuator/prometheus`
- [x] M√©tricas customizadas de negocio (users.created.total)
- [x] Tags para filtrar (environment, status)
- [x] Dashboards en Grafana

### ‚úÖ **Trazas**
- [x] Micrometer Tracing configurado
- [x] Zipkin endpoint configurado
- [x] Sampling rate ajustado (100% dev, 10% prod)
- [x] Correlation ID propagado entre servicios

### ‚úÖ **Alerting**
- [x] Alertas configuradas (CPU, error rate, latency)
- [x] Notificaciones a Slack/PagerDuty
- [x] Runbooks documentados (qu√© hacer cuando alerta se dispara)

---

## Recursos

- [Micrometer Documentation](https://micrometer.io/docs)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Zipkin Documentation](https://zipkin.io/)
- [OpenTelemetry](https://opentelemetry.io/)
- [SLF4J Documentation](https://www.slf4j.org/manual.html)

---

**√öltima actualizaci√≥n**: 2025-10-30
