# ğŸ“Š Monitoring & Observability - Hexarch

## Ãndice
- [Â¿QuÃ© es Observabilidad?](#quÃ©-es-observabilidad)
- [Los 3 Pilares: Logs, MÃ©tricas y Trazas](#los-3-pilares-logs-mÃ©tricas-y-trazas)
- [Logs: CuÃ¡ndo usar cada nivel](#logs-cuÃ¡ndo-usar-cada-nivel)
- [MÃ©tricas: Prometheus + Grafana](#mÃ©tricas-prometheus--grafana)
- [Trazas Distribuidas: Zipkin + Micrometer](#trazas-distribuidas-zipkin--micrometer)
- [PropagaciÃ³n de TraceId/SpanId: Deep Dive](#propagaciÃ³n-de-traceidspanid-deep-dive) â­ **NUEVO**
  - CÃ³mo se genera el TraceId/SpanId
  - PropagaciÃ³n en HTTP (W3C Trace Context)
  - PropagaciÃ³n en Kafka (headers automÃ¡ticos)
  - Flujo End-to-End completo (POST /api/v1/users)
  - CÃ³mo buscar y analizar trazas en Zipkin UI
  - Ejemplo prÃ¡ctico: Troubleshooting de errores
  - ConfiguraciÃ³n de sampling para producciÃ³n
- [Correlation ID: Tracing de Negocio](#correlation-id-tracing-de-negocio)
- [Setup Local](#setup-local)
- [Ejemplos PrÃ¡cticos en el CÃ³digo](#ejemplos-prÃ¡cticos-en-el-cÃ³digo)
- [Alerting](#alerting)

---

## Â¿QuÃ© es Observabilidad?

**Observabilidad** es la capacidad de **entender el estado interno** de un sistema basÃ¡ndose en sus salidas externas (logs, mÃ©tricas, trazas).

### **Monitoring vs Observability**

| Concepto | DefiniciÃ³n | Ejemplo |
|----------|------------|---------|
| **Monitoring** | Verificar si el sistema funciona (**known unknowns**) | "Â¿La CPU estÃ¡ > 80%?" |
| **Observability** | Investigar **por quÃ©** falla (**unknown unknowns**) | "Â¿Por quÃ© este request tardÃ³ 5 segundos?" |

**En producciÃ³n necesitas AMBOS**:
- **Monitoring**: Dashboards con mÃ©tricas clave (latencia, error rate, throughput)
- **Observability**: Herramientas para explorar y correlacionar eventos (logs + traces)

---

## Los 3 Pilares: Logs, MÃ©tricas y Trazas

### **1. LOGS** ğŸ“
**DefiniciÃ³n**: Eventos discretos con timestamp que describen lo que pasÃ³.

**CaracterÃ­sticas**:
- **Texto estructurado** (mejor JSON para parsing)
- **Timestamp** + **Nivel** (INFO, WARN, ERROR) + **Mensaje**
- **Contexto**: CorrelationId, UserId, TraceId

**Ejemplo**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: username=johndoe
â”‚                   â”‚           â”‚        â”‚     â”‚
Timestamp           TraceId     CorrId   Level Message
```

**CuÃ¡ndo usar**:
- âœ… Debugging: "Â¿QuÃ© pasÃ³ justo antes del error?"
- âœ… AuditorÃ­a: "Â¿QuiÃ©n modificÃ³ este recurso?"
- âœ… Troubleshooting: Buscar patrones en fallos

**Herramientas**: ELK Stack (Elasticsearch + Logstash + Kibana), Splunk, CloudWatch Logs

---

### **2. MÃ‰TRICAS** ğŸ“ˆ
**DefiniciÃ³n**: Valores numÃ©ricos agregados a lo largo del tiempo.

**CaracterÃ­sticas**:
- **Time-series data**: (timestamp, value)
- **Agregaciones**: sum, avg, percentiles (p50, p99)
- **Eficientes**: Ocupan poco espacio (vs logs)

**Tipos de mÃ©tricas**:

| Tipo | DescripciÃ³n | Ejemplo |
|------|-------------|---------|
| **Counter** | Contador que solo crece | `users_created_total` |
| **Gauge** | Valor instantÃ¡neo (sube/baja) | `users_active_count` |
| **Histogram** | DistribuciÃ³n de valores | `http_request_duration_seconds` |
| **Summary** | Similar a histogram + percentiles | `http_request_duration_summary` |

**CuÃ¡ndo usar**:
- âœ… Dashboards en tiempo real
- âœ… Alertas (CPU > 80%, Error rate > 5%)
- âœ… SLOs (Service Level Objectives): "p99 latency < 500ms"

**Herramientas**: Prometheus, Grafana, Datadog, New Relic

---

### **3. TRAZAS DISTRIBUIDAS** ğŸ”—
**DefiniciÃ³n**: Seguimiento de un request a travÃ©s de mÃºltiples servicios.

**Conceptos**:
- **Trace**: Request completo (ej: "Crear usuario desde API hasta BD")
- **Span**: Una operaciÃ³n dentro del trace (ej: "INSERT en PostgreSQL")
- **Trace ID**: Identificador Ãºnico del trace
- **Span ID**: Identificador Ãºnico del span

**Ejemplo visual**:
```
Trace ID: f47ac10b-8c42-11eb-8dcd-0242ac130003

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Span 1: POST /api/v1/users         (200ms)             â”‚
â”‚  â”œâ”€ Span 2: Validate email          (5ms)              â”‚
â”‚  â”œâ”€ Span 3: Save to PostgreSQL     (50ms)              â”‚
â”‚  â””â”€ Span 4: Publish Kafka event   (145ms)              â”‚
â”‚      â””â”€ Span 5: Kafka Producer     (140ms)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CuÃ¡ndo usar**:
- âœ… Identificar cuellos de botella (ej: "Kafka tarda 140ms")
- âœ… Debugging en microservicios (trazar request entre 5+ servicios)
- âœ… Entender flujo de requests

**Herramientas**: Zipkin, Jaeger, AWS X-Ray, Tempo

---

## Logs: CuÃ¡ndo usar cada nivel

Spring Boot usa **SLF4J + Logback** con 5 niveles de log:

### **Niveles de Log**

| Nivel | CuÃ¡ndo Usar | Ejemplo | En ProducciÃ³n |
|-------|-------------|---------|---------------|
| **TRACE** | Debugging muy detallado | `log.trace("Entering method calculateTax()")` | âŒ Desactivado |
| **DEBUG** | InformaciÃ³n de desarrollo | `log.debug("Query executed: {}", sql)` | âŒ Desactivado |
| **INFO** | Eventos importantes | `log.info("User created: {}", userId)` | âœ… Activado |
| **WARN** | Problemas recuperables | `log.warn("Retry attempt 2/3 failed")` | âœ… Activado |
| **ERROR** | Errores que requieren atenciÃ³n | `log.error("Failed to send email", ex)` | âœ… Activado |

---

### **Reglas de Oro para Logging**

#### âœ… **1. INFO: Eventos de negocio importantes**

**Usar para**:
- Usuario creado/modificado/eliminado
- TransacciÃ³n completada
- Inicio/fin de procesos batch
- Eventos de auditorÃ­a

**Ejemplo**:
```java
@Override
public UserResponse createUser(CreateUserCommand command) {
    log.info("Creating user: username={}, email={}", command.username(), command.email());

    User user = User.create(/* ... */);
    User savedUser = userRepository.save(user);

    log.info("User created successfully: userId={}, username={}",
             savedUser.getId(), savedUser.getUsername());

    return mapper.toResponse(savedUser);
}
```

**Â¿CuÃ¡ntos logs INFO?**
- âŒ **MAL**: 1 log por cada lÃ­nea de cÃ³digo (ruido)
- âœ… **BIEN**: 2-3 logs por operaciÃ³n importante (inicio, Ã©xito, fin)

---

#### âœ… **2. DEBUG: InformaciÃ³n de desarrollo**

**Usar para**:
- Valores de variables durante desarrollo
- SQL queries ejecutadas
- ParÃ¡metros de entrada a mÃ©todos
- Estado de objetos

**Ejemplo**:
```java
@Override
public Optional<User> findByEmail(String email) {
    log.debug("Searching user by email: {}", email);

    Optional<UserEntity> entity = jpaRepository.findByEmail(email);

    log.debug("User found: {}", entity.isPresent());

    return entity.map(userMapper::toDomain);
}
```

**Importante**:
- âŒ **NO** usar en producciÃ³n (genera demasiados logs)
- âœ… Activar solo durante troubleshooting especÃ­fico

---

#### âœ… **3. WARN: Problemas no crÃ­ticos**

**Usar para**:
- Reintentos fallidos (antes del Ãºltimo intento)
- ConfiguraciÃ³n subÃ³ptima detectada
- Uso de valores por defecto
- Deprecation warnings

**Ejemplo**:
```java
@Retryable(maxAttempts = 3)
@Override
public void sendWelcomeEmail(String email) {
    try {
        emailService.send(email, "Welcome!");
        log.info("Welcome email sent to {}", email);
    } catch (EmailException ex) {
        log.warn("Failed to send email to {} (will retry)", email);
        throw ex; // Retry mechanism will catch this
    }
}
```

**Â¿CuÃ¡ndo NO usar WARN?**
- âŒ Errores esperados (ej: usuario no encontrado â†’ usar INFO)
- âŒ ValidaciÃ³n fallida â†’ lanzar exception, logear como ERROR si no se captura

---

#### âœ… **4. ERROR: Errores crÃ­ticos**

**Usar para**:
- Exceptions no esperadas
- Fallos en servicios externos
- Inconsistencias de datos
- Cualquier cosa que requiera atenciÃ³n inmediata

**Ejemplo**:
```java
@Override
public void handleUserCreatedEvent(UserCreatedEvent event) {
    try {
        emailService.sendWelcomeEmail(event.email());
        log.info("Welcome email sent for user: {}", event.userId());
    } catch (Exception ex) {
        log.error("Failed to send welcome email for user: userId={}, error={}",
                  event.userId(), ex.getMessage(), ex);
        throw ex; // SerÃ¡ enviado a DLT
    }
}
```

**Reglas para ERROR logs**:
1. âœ… **Siempre incluir la exception**: `log.error("msg", exception)`
2. âœ… **Incluir contexto**: userId, transactionId, etc.
3. âœ… **NO logear la misma exception mÃºltiples veces** (contamina logs)

**Anti-pattern comÃºn**:
```java
// âŒ MAL: Logea 3 veces la misma exception
try {
    service.doSomething();
} catch (Exception ex) {
    log.error("Error in layer 1", ex);  // âŒ
    throw ex;
}

// En el caller:
try {
    layer1.call();
} catch (Exception ex) {
    log.error("Error in layer 2", ex);  // âŒ Duplicado
    throw ex;
}

// En el controller:
try {
    layer2.call();
} catch (Exception ex) {
    log.error("Error in controller", ex);  // âŒ Triplicado
    return ResponseEntity.status(500).build();
}
```

**âœ… BIEN: Logea solo en el boundary**:
```java
// Domain/Application: Solo lanzan exceptions (NO logean)
public User createUser(...) {
    if (userRepository.existsByEmail(email)) {
        throw new EmailAlreadyExistsException(email);  // NO log aquÃ­
    }
    return userRepository.save(user);
}

// Controller: Logea y maneja
@PostMapping("/users")
public ResponseEntity<UserResponse> createUser(@RequestBody CreateUserRequest request) {
    try {
        UserResponse response = useCase.execute(command);
        return ResponseEntity.status(201).body(response);
    } catch (EmailAlreadyExistsException ex) {
        log.warn("Email already exists: {}", request.email());  // Log en boundary
        return ResponseEntity.status(409).build();
    } catch (Exception ex) {
        log.error("Unexpected error creating user", ex);  // Log en boundary
        return ResponseEntity.status(500).build();
    }
}
```

---

#### âœ… **5. TRACE: Solo para librerÃ­as**

**NO usar en cÃ³digo de aplicaciÃ³n**. Reservado para:
- Spring Framework internals
- Hibernate SQL tracing
- Network debugging

**ActivaciÃ³n temporal**:
```yaml
logging:
  level:
    org.hibernate.SQL: TRACE  # Ver SQL queries
    org.springframework.web: TRACE  # Ver requests HTTP
```

---

### **Formato de Logs en Hexarch**

**Configurado en `application.yaml`**:
```yaml
logging:
  pattern:
    # Formato: timestamp [traceId,spanId] correlationId level - message
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

**Ejemplo de log**:
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400-e29b-41d4 INFO  - User created: userId=123, username=johndoe
â”‚                   â”‚           â”‚        â”‚                    â”‚     â”‚
Timestamp           TraceId     SpanId   CorrelationId        Level Message
```

**Ventajas**:
- âœ… Buscar todos los logs de un request especÃ­fico: `correlationId:550e8400-e29b-41d4`
- âœ… Ver trace completo en Zipkin: `traceId:f47ac10b`
- âœ… Debugging rÃ¡pido: correlacionar logs entre servicios

---

## MÃ©tricas: Prometheus + Grafana

### **Â¿QuÃ© es Prometheus?**

**Prometheus** es un sistema de **monitorizaciÃ³n basado en mÃ©tricas time-series**:
- Recolecta mÃ©tricas mediante **pull** (scraping)
- Almacena en time-series DB
- Query language: **PromQL**
- IntegraciÃ³n con Grafana para visualizaciÃ³n

### **Â¿QuÃ© es Grafana?**

**Grafana** es una plataforma de **visualizaciÃ³n y dashboards**:
- Conecta a mÃºltiples datasources (Prometheus, InfluxDB, ElasticSearch)
- Dashboards interactivos
- Alertas configurables

---

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Actuator: Expone mÃ©tricas -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- Prometheus: Formato de mÃ©tricas -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

**2. ConfiguraciÃ³n en `application.yaml`**:
```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics

  endpoint:
    prometheus:
      enabled: true

  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:local}
```

**3. Endpoint de mÃ©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus
```

**Respuesta**:
```
# HELP jvm_memory_used_bytes The amount of used memory
# TYPE jvm_memory_used_bytes gauge
jvm_memory_used_bytes{area="heap",id="PS Eden Space",} 1.23456789E8

# HELP http_server_requests_seconds Duration of HTTP requests
# TYPE http_server_requests_seconds summary
http_server_requests_seconds_count{exception="None",method="POST",status="201",uri="/api/v1/users",} 42.0
http_server_requests_seconds_sum{exception="None",method="POST",status="201",uri="/api/v1/users",} 2.1
```

---

### **MÃ©tricas AutomÃ¡ticas (Actuator)**

Spring Boot Actuator **ya expone mÃ©tricas automÃ¡ticamente**:

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| `jvm_memory_used_bytes` | Memoria JVM usada |
| `jvm_threads_live_threads` | Threads activos |
| `jvm_gc_pause_seconds` | Pausas de Garbage Collector |
| `http_server_requests_seconds` | Latencia de requests HTTP |
| `http_server_requests_seconds_count` | Total de requests por endpoint |
| `spring_kafka_listener_seconds` | Latencia de Kafka listeners |
| `hikaricp_connections_active` | Conexiones DB activas |
| `logback_events_total` | Total de logs por nivel |

**No necesitas cÃ³digo adicional para estas mÃ©tricas** âœ…

---

### **MÃ©tricas Customizadas**

Para mÃ©tricas de **negocio especÃ­ficas**, usa `MeterRegistry`:

#### **Ejemplo 1: Contador de usuarios creados**

**`CreateUserUseCase.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class CreateUserUseCase {

    private final UserRepositoryPort userRepository;
    private final EventPublisherPort eventPublisher;
    private final MeterRegistry meterRegistry;  // â† Inyectar

    @Override
    public UserResponse execute(CreateUserCommand command) {
        // ... validaciones ...

        User savedUser = userRepository.save(user);

        // ğŸ“Š MÃ©trica custom: contador de usuarios creados
        meterRegistry.counter("users.created.total",
                              "status", "success",
                              "environment", environment)
                     .increment();

        log.info("User created: userId={}, username={}", savedUser.getId(), savedUser.getUsername());

        eventPublisher.publish(userCreatedEvent);

        return mapper.toResponse(savedUser);
    }
}
```

**MÃ©trica expuesta**:
```
# HELP users_created_total Total number of users created
# TYPE users_created_total counter
users_created_total{status="success",environment="production"} 42.0
```

---

#### **Ejemplo 2: Gauge de usuarios activos**

**`UserMetricsService.java`**:
```java
@Service
@RequiredArgsConstructor
public class UserMetricsService {

    private final UserRepositoryPort userRepository;
    private final MeterRegistry meterRegistry;

    @PostConstruct
    public void registerMetrics() {
        // ğŸ“Š Gauge: valor que fluctÃºa (sube/baja)
        Gauge.builder("users.active.count", userRepository, repo -> repo.countByEnabled(true))
             .description("Number of active users")
             .register(meterRegistry);
    }
}
```

**MÃ©trica expuesta**:
```
# HELP users_active_count Number of active users
# TYPE users_active_count gauge
users_active_count 156.0
```

---

#### **Ejemplo 3: Timer de operaciones**

**`EmailService.java`**:
```java
@Service
@RequiredArgsConstructor
@Slf4j
public class EmailService {

    private final MeterRegistry meterRegistry;

    @CircuitBreaker(name = "emailService", fallbackMethod = "sendEmailFallback")
    @Retry(name = "emailService")
    public void sendWelcomeEmail(String email) {
        // ğŸ“Š Timer: mide duraciÃ³n de operaciÃ³n
        Timer.Sample sample = Timer.start(meterRegistry);

        try {
            // Simular envÃ­o de email (aquÃ­ irÃ­a integraciÃ³n con SMTP/SES)
            Thread.sleep(100);

            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "success"));

            log.info("Welcome email sent to {}", email);
        } catch (Exception ex) {
            sample.stop(meterRegistry.timer("email.send.duration",
                                            "type", "welcome",
                                            "status", "failure"));
            throw new EmailServiceException("Failed to send email", ex);
        }
    }
}
```

**MÃ©trica expuesta**:
```
# HELP email_send_duration_seconds Email send duration
# TYPE email_send_duration_seconds summary
email_send_duration_seconds_count{type="welcome",status="success"} 42.0
email_send_duration_seconds_sum{type="welcome",status="success"} 4.2
email_send_duration_seconds{type="welcome",status="success",quantile="0.5",} 0.098
email_send_duration_seconds{type="welcome",status="success",quantile="0.99",} 0.15
```

---

### **Dashboards en Grafana**

**1. AÃ±adir Prometheus como datasource**:
- URL: `http://prometheus:9090`
- Access: Server (default)

**2. Importar dashboard JVM (Micrometer)**:
- Dashboard ID: `4701` (JVM Micrometer)
- [https://grafana.com/grafana/dashboards/4701](https://grafana.com/grafana/dashboards/4701)

**3. Dashboard custom para Users**:

**Panel 1: Total usuarios creados**
```promql
# Query PromQL
rate(users_created_total[5m])
```

**Panel 2: Usuarios activos (gauge)**
```promql
users_active_count
```

**Panel 3: Latencia p99 de POST /users**
```promql
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket{uri="/api/v1/users", method="POST"}[5m])
)
```

**Panel 4: Error rate**
```promql
rate(http_server_requests_seconds_count{status=~"5.."}[5m]) /
rate(http_server_requests_seconds_count[5m]) * 100
```

**Captura de pantalla** (ejemplo):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Users Dashboard                             [Last 1 hour â–¼] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Total Users     â”‚  â”‚ Active Users    â”‚  â”‚ Error Rate   â”‚â”‚
â”‚  â”‚      1,234      â”‚  â”‚       156       â”‚  â”‚    0.5%      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ POST /users - p99 Latency                                â”‚â”‚
â”‚  â”‚ â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ 120ms                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Trazas Distribuidas: Zipkin + Micrometer

### **Â¿QuÃ© es Zipkin?**

**Zipkin** es un sistema de **distributed tracing** que:
- Recolecta spans de mÃºltiples servicios
- Correlaciona spans en un trace completo
- Visualiza el flujo de requests
- Identifica cuellos de botella

### **Setup en Hexarch**

**1. Dependencias en `pom.xml`**:
```xml
<!-- Micrometer Tracing (OpenTelemetry compatible) -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>

<!-- Zipkin Reporter -->
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

**2. ConfiguraciÃ³n en `application.yaml`**:
```yaml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% en dev, 0.1 (10%) en prod

  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans
```

**3. Acceder a Zipkin UI**:
```bash
# URL
http://localhost:9411/zipkin/

# Buscar traces por:
# - serviceName: hexarch
# - traceId: f47ac10b-8c42-11eb-8dcd-0242ac130003
# - minDuration: > 500ms (encontrar lentos)
```

---

### **VisualizaciÃ³n de Traces**

**Trace completo: POST /api/v1/users**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace: f47ac10b-8c42-11eb-8dcd-0242ac130003 (250ms total)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ â”Œâ”€ POST /api/v1/users â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (250ms) â”€â”€â”€â”â”‚
â”‚ â”‚                                                              â”‚â”‚
â”‚ â”‚  â”Œâ”€ CreateUserUseCase.execute() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (200ms) â”€â”€â”€â”â”‚â”‚
â”‚ â”‚  â”‚                                                          â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”Œâ”€ PostgresUserRepository.save() â”€â”€â”€â”€â”€â”€â”€â”€â”€ (40ms) â”€â”€â”€â”â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚  â”œâ”€ INSERT INTO users ...                           â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚ â”‚  â”‚                                                          â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”Œâ”€ KafkaEventPublisher.publish() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (150ms) â”€â”€â”â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚  â”œâ”€ kafka.send(user.created)                        â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ” Insight: Kafka tarda 150ms de 250ms totales (60% del tiempo)
```

**AnÃ¡lisis**:
- Total: 250ms
- PostgreSQL: 40ms (16%)
- Kafka: 150ms (60%) â† **Cuello de botella**
- LÃ³gica aplicaciÃ³n: 10ms (4%)
- Overhead: 50ms (20%)

**AcciÃ³n**: Optimizar Kafka (async, batching, compression)

---

### **Spans AutomÃ¡ticos**

Spring Boot **ya crea spans automÃ¡ticamente** para:
- âœ… HTTP requests (`spring-webmvc`)
- âœ… JPA queries (`spring-data-jpa`)
- âœ… Kafka producers/consumers (`spring-kafka`)
- âœ… RestTemplate/WebClient calls
- âœ… JDBC queries

**No necesitas cÃ³digo adicional** âœ…

---

### **Spans Manuales (Custom)**

Para operaciones especÃ­ficas, usa `@NewSpan` o `Tracer`:

```java
@Service
@RequiredArgsConstructor
public class ComplexBusinessLogic {

    private final Tracer tracer;

    public void processOrder(Order order) {
        // Crear span manual
        Span span = tracer.nextSpan().name("process-order");

        try (Tracer.SpanInScope ws = tracer.withSpan(span.start())) {
            // AÃ±adir tags al span
            span.tag("order.id", order.getId());
            span.tag("order.amount", String.valueOf(order.getAmount()));

            // LÃ³gica de negocio compleja
            validateOrder(order);
            calculateTax(order);
            saveOrder(order);

        } finally {
            span.end();
        }
    }
}
```

---

## PropagaciÃ³n de TraceId/SpanId: Deep Dive

### **Â¿CÃ³mo se Genera el TraceId y SpanId?**

**Micrometer Tracing** (integrado con Spring Boot) genera automÃ¡ticamente estos identificadores:

| ID | DescripciÃ³n | Formato | Ejemplo |
|----|-------------|---------|---------|
| **Trace ID** | Identificador Ãºnico del request completo | 128-bit hex | `f47ac10b8c4211eb8dcd0242ac130003` |
| **Span ID** | Identificador Ãºnico de cada operaciÃ³n | 64-bit hex | `1a2b3c4d5e6f7890` |
| **Parent Span ID** | ID del span padre (si existe) | 64-bit hex | `0a1b2c3d4e5f6789` |

**GeneraciÃ³n automÃ¡tica**:
1. **Primer request** (sin header de tracing):
   - Micrometer genera un **nuevo Trace ID** aleatorio
   - Genera el **primer Span ID** (span raÃ­z)
   - Parent Span ID = null (es el span root)

2. **Operaciones hijas** (dentro del mismo servicio):
   - **Trace ID se mantiene** (mismo request)
   - Se genera un **nuevo Span ID** para cada operaciÃ³n
   - Parent Span ID = Span ID del padre

3. **Llamadas entre servicios** (HTTP/Kafka):
   - **Trace ID se propaga** (mismo request distribuido)
   - Se genera un **nuevo Span ID** en el servicio destino
   - Parent Span ID = Span ID del servicio origen

---

### **PropagaciÃ³n en HTTP (W3C Trace Context)**

**Micrometer Tracing usa el estÃ¡ndar W3C Trace Context** para propagar trazas en HTTP.

#### **Header: `traceparent`**

Formato: `00-{trace-id}-{parent-id}-{trace-flags}`

**Ejemplo real**:
```http
traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-1a2b3c4d5e6f7890-01
             â”‚  â”‚                                â”‚                â”‚
             â”‚  Trace ID (128-bit)               Span ID (64-bit) Flags (01 = sampled)
             Version (00)
```

**Flags**:
- `01` = Sampled (se estÃ¡ trackeando este request)
- `00` = Not sampled (no se trackea - ahorra overhead)

#### **Header: `tracestate` (Opcional)**

Formato: `vendor1=value1,vendor2=value2`

**Ejemplo**:
```http
tracestate: zipkin=sampled,datadog=s:1;o:rum
```

Permite a cada vendor aÃ±adir su metadata custom.

---

### **PropagaciÃ³n en Kafka**

**Micrometer Tracing propaga automÃ¡ticamente el contexto en headers de Kafka**.

#### **Headers de Kafka con Tracing**

Cuando produces un mensaje a Kafka, Micrometer aÃ±ade estos headers:

| Header Key | Valor | DescripciÃ³n |
|------------|-------|-------------|
| `traceparent` | `00-{trace-id}-{span-id}-01` | W3C Trace Context (mismo formato HTTP) |
| `tracestate` | (opcional) | Vendor-specific metadata |
| `X-B3-TraceId` | `{trace-id}` | Formato B3 (backward compatibility) |
| `X-B3-SpanId` | `{span-id}` | Formato B3 |
| `X-B3-ParentSpanId` | `{parent-span-id}` | Formato B3 |
| `X-B3-Sampled` | `1` o `0` | Si estÃ¡ siendo sampled |

**Ejemplo de headers en Kafka**:
```
traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-2b3c4d5e6f7a8b9c-01
X-B3-TraceId: f47ac10b8c4211eb8dcd0242ac130003
X-B3-SpanId: 2b3c4d5e6f7a8b9c
X-B3-ParentSpanId: 1a2b3c4d5e6f7890
X-B3-Sampled: 1
```

#### **Consumer Lee los Headers**

Cuando el consumer recibe el mensaje:
1. **Spring Kafka** lee automÃ¡ticamente los headers de tracing
2. **Micrometer Tracing** extrae el Trace ID y Span ID
3. **ContinÃºa la traza** en el consumer (mismo Trace ID)
4. **Crea nuevo Span** para el procesamiento del consumer

**NO necesitas cÃ³digo manual** - es automÃ¡tico âœ…

---

### **Flujo End-to-End: POST /api/v1/users**

Veamos cÃ³mo se propaga el traceId en un flujo completo de este proyecto:

#### **Paso 1: Request HTTP al API**

**Cliente**:
```bash
curl -X POST http://localhost:8080/api/v1/users \
  -H "Content-Type: application/json" \
  -d '{"username": "johndoe", "email": "john@example.com"}'
```

**Spring Boot recibe el request**:
- â“ Â¿Tiene header `traceparent`? â†’ NO (request nuevo)
- âœ… **Micrometer genera Trace ID**: `f47ac10b8c4211eb8dcd0242ac130003`
- âœ… **Span ID (HTTP)**: `1a2b3c4d5e6f7890`

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,1a2b3c4d5e6f7890] INFO - Received POST /api/v1/users
                    â”‚                                       â”‚
                    Trace ID                                Span ID (HTTP span)
```

---

#### **Paso 2: UserController â†’ CreateUserService**

**CÃ³digo** (`UserController.java:42`):
```java
@PostMapping
public ResponseEntity<UserResponse> createUser(@RequestBody @Valid CreateUserRequest request) {
    // Trace ID se propaga automÃ¡ticamente (ThreadLocal)
    CreateUserCommand command = userRestMapper.toCommand(request);
    UserResult result = createUserUseCase.execute(command);
    return ResponseEntity.status(201).body(userRestMapper.toResponse(result));
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `2b3c4d5e6f7a8b9c` (para el Service)
- Parent Span ID: `1a2b3c4d5e6f7890` (el HTTP span)

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - Creating user: username=johndoe
```

---

#### **Paso 3: CreateUserService â†’ PostgreSQL**

**CÃ³digo** (`CreateUserService.java:119`):
```java
User user = User.create(command.username(), command.email());
User savedUser = userRepository.save(user);  // â† Span automÃ¡tico de JPA
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `3c4d5e6f7a8b9cde` (para la query SQL)
- Parent Span ID: `2b3c4d5e6f7a8b9c` (el Service span)

**Query SQL ejecutada**:
```sql
INSERT INTO users (id, username, email, enabled, created_at)
VALUES ('550e8400-...', 'johndoe', 'john@example.com', true, '2024-01-15 10:30:00')
```

**Span en Zipkin**:
- Nombre: `INSERT users`
- DuraciÃ³n: `40ms`
- Tags: `db.system=postgresql`, `db.statement=INSERT INTO users...`

---

#### **Paso 4: CreateUserService â†’ Kafka Producer**

**CÃ³digo** (`CreateUserService.java:138`):
```java
UserCreatedEvent event = UserCreatedEvent.from(
    savedUser.getId(),
    savedUser.getUsername().getValue(),
    savedUser.getEmail().getValue()
);
userEventPublisher.publish(event);  // â† Span automÃ¡tico de Kafka
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `4d5e6f7a8b9cdef0` (para Kafka send)
- Parent Span ID: `2b3c4d5e6f7a8b9c` (el Service span)

**Headers de Kafka enviados**:
```
Key: 550e8400-e29b-41d4-a716-446655440000 (userId)
Headers:
  - traceparent: 00-f47ac10b8c4211eb8dcd0242ac130003-4d5e6f7a8b9cdef0-01
  - X-B3-TraceId: f47ac10b8c4211eb8dcd0242ac130003
  - X-B3-SpanId: 4d5e6f7a8b9cdef0
  - X-B3-ParentSpanId: 2b3c4d5e6f7a8b9c
  - X-B3-Sampled: 1
```

**Span en Zipkin**:
- Nombre: `send user.created`
- DuraciÃ³n: `150ms`
- Tags: `messaging.system=kafka`, `messaging.destination=user.created`

---

#### **Paso 5: Kafka Consumer (Servicio de Notificaciones)**

**Consumer recibe el mensaje** (`UserEventsKafkaConsumer.java:45`):

```java
@KafkaListener(topics = "user.created", groupId = "notifications-service")
public void handleUserCreated(UserCreatedEvent event, @Header(KafkaHeaders.RECEIVED_KEY) String key) {
    // Micrometer Tracing lee los headers automÃ¡ticamente
    log.info("Received UserCreatedEvent: userId={}", event.userId());
    emailService.sendWelcomeEmail(event.email(), event.username());
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo - propagado desde Kafka headers)
- **Nuevo Span ID**: `5e6f7a8b9cdef012` (para el consumer)
- Parent Span ID: `4d5e6f7a8b9cdef0` (el Kafka producer span)

**Log en consola**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,5e6f7a8b9cdef012] INFO - Received UserCreatedEvent: userId=550e8400...
```

**Span en Zipkin**:
- Nombre: `poll user.created`
- DuraciÃ³n: `5ms`
- Tags: `messaging.system=kafka`, `messaging.source=user.created`

---

#### **Paso 6: EmailService (con Circuit Breaker)**

**CÃ³digo** (`EmailService.java:25`):
```java
@CircuitBreaker(name = "emailService", fallbackMethod = "sendEmailFallback")
public void sendWelcomeEmail(String email, String username) {
    log.info("Sending welcome email to {}", email);
    // SimulaciÃ³n de envÃ­o de email
    // En producciÃ³n: llamada a SendGrid, SES, etc.
}
```

**Micrometer Tracing**:
- Trace ID: `f47ac10b8c4211eb8dcd0242ac130003` (mismo)
- **Nuevo Span ID**: `6f7a8b9cdef01234` (para el email send)
- Parent Span ID: `5e6f7a8b9cdef012` (el consumer span)

**Span en Zipkin**:
- Nombre: `sendWelcomeEmail`
- DuraciÃ³n: `100ms`
- Tags: `email.recipient=john@example.com`, `circuit-breaker=emailService`

---

### **VisualizaciÃ³n Completa en Zipkin**

Cuando buscas el Trace ID `f47ac10b8c4211eb8dcd0242ac130003` en Zipkin, ves:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace: f47ac10b8c4211eb8dcd0242ac130003                    Total: 295ms         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚ â”Œâ”€ POST /api/v1/users â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 295ms â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Span ID: 1a2b3c4d5e6f7890                                                    â”‚â”‚
â”‚ â”‚ Service: hexarch                                                              â”‚â”‚
â”‚ â”‚ Tags: http.method=POST, http.status_code=201                                 â”‚â”‚
â”‚ â”‚                                                                               â”‚â”‚
â”‚ â”‚  â”Œâ”€ CreateUserService.execute() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 290ms â”€â”€â”€â”€â”â”‚â”‚
â”‚ â”‚  â”‚ Span ID: 2b3c4d5e6f7a8b9c                                                â”‚â”‚â”‚
â”‚ â”‚  â”‚ Service: hexarch                                                          â”‚â”‚â”‚
â”‚ â”‚  â”‚                                                                           â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”Œâ”€ INSERT users â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 40ms â”€â”€â”€â”â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Span ID: 3c4d5e6f7a8b9cde                                            â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Service: hexarch                                                      â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Tags: db.system=postgresql, db.statement=INSERT INTO users...        â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚ â”‚  â”‚                                                                           â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”Œâ”€ send user.created â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 150ms â”€â”€â”â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Span ID: 4d5e6f7a8b9cdef0                                            â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Service: hexarch                                                      â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Tags: messaging.system=kafka, messaging.destination=user.created     â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â”‚ â”‚                                                                               â”‚â”‚
â”‚ â”‚  â”Œâ”€ poll user.created â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 105ms â”€â”€â”â”‚â”‚
â”‚ â”‚  â”‚ Span ID: 5e6f7a8b9cdef012                                                â”‚â”‚â”‚
â”‚ â”‚  â”‚ Service: notifications-service                                            â”‚â”‚â”‚
â”‚ â”‚  â”‚ Tags: messaging.system=kafka, messaging.source=user.created              â”‚â”‚â”‚
â”‚ â”‚  â”‚                                                                           â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”Œâ”€ sendWelcomeEmail â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 100ms â”€â”â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Span ID: 6f7a8b9cdef01234                                            â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Service: notifications-service                                        â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â”‚ Tags: email.recipient=john@example.com, circuit-breaker=emailService â”‚â”‚â”‚â”‚
â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AnÃ¡lisis del Timeline**:
- HTTP Request: `0ms - 295ms` (295ms total)
- Service execution: `0ms - 290ms` (290ms)
  - PostgreSQL INSERT: `0ms - 40ms` (40ms)
  - Kafka send: `40ms - 190ms` (150ms) â† **60% del tiempo**
- Kafka consumer: `190ms - 295ms` (105ms)
  - Email send: `195ms - 295ms` (100ms) â† **95% del consumer**

**Insights**:
1. Kafka produce es el cuello de botella (150ms de 295ms = 51%)
2. Email send tambiÃ©n es lento (100ms)
3. PostgreSQL es eficiente (40ms)

---

### **CÃ³mo Buscar y Analizar Trazas en Zipkin UI**

#### **1. Acceder a Zipkin**

```bash
# Levantar Zipkin con docker-compose
docker-compose up -d zipkin

# Acceder a Zipkin UI
http://localhost:9411
```

---

#### **2. Buscar Trazas por Criterio**

**Filtros disponibles**:

| Filtro | DescripciÃ³n | Ejemplo |
|--------|-------------|---------|
| **Service Name** | Filtrar por servicio | `hexarch` |
| **Span Name** | Filtrar por operaciÃ³n especÃ­fica | `POST /api/v1/users` |
| **Tags** | Buscar por tags custom | `http.status_code=500` |
| **Duration** | Min/Max duraciÃ³n | `> 500ms` (encontrar lentos) |
| **Limit** | NÃºmero de resultados | `10`, `50`, `100` |
| **Lookback** | Ventana de tiempo | `Last hour`, `Last 15 minutes` |

---

#### **3. Buscar Errores (Status 5xx)**

**Objetivo**: Encontrar todas las trazas con errores en las Ãºltimas 24 horas.

**Pasos**:

1. **Click en "Search"** (lupa arriba a la derecha)

2. **Configurar filtros**:
   ```
   Service Name: hexarch
   Tags: error=true
   Lookback: 24 hours
   Limit: 50
   ```

3. **Click en "Run Query"**

4. **Resultado**: Lista de trazas ordenadas por timestamp

**Ejemplo de traza con error**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace: a1b2c3d4e5f67890 (ERROR)                  Total: 50ms     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€ POST /api/v1/users â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 50ms â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ERROR: UserAlreadyExistsException                             â”‚â”‚
â”‚ â”‚ Tags: http.status_code=409, error=true                        â”‚â”‚
â”‚ â”‚ Stack Trace:                                                  â”‚â”‚
â”‚ â”‚   com.example.hexarch.user.domain.exception                   â”‚â”‚
â”‚ â”‚     .UserAlreadyExistsException: Username 'johndoe' exists    â”‚â”‚
â”‚ â”‚   at CreateUserService.execute(CreateUserService.java:108)    â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### **4. Buscar Trazas Lentas (Performance)**

**Objetivo**: Encontrar requests que tardan mÃ¡s de 500ms.

**Pasos**:

1. **Click en "Search"**

2. **Configurar filtros**:
   ```
   Service Name: hexarch
   Min Duration: 500ms
   Lookback: 1 hour
   Limit: 20
   ```

3. **Click en "Run Query"**

4. **Ordenar por duraciÃ³n** (columna "Duration")

**AnÃ¡lisis**:
- Click en una traza especÃ­fica
- Ver el timeline (waterfall chart)
- Identificar el span mÃ¡s lento (barra mÃ¡s larga)
- Ver tags del span para entender el contexto

**Ejemplo**:
```
POST /api/v1/users - 1250ms
  â”œâ”€ CreateUserService - 1245ms
  â”‚  â”œâ”€ PostgreSQL INSERT - 45ms  âœ… Normal
  â”‚  â””â”€ Kafka send - 1200ms  âš ï¸ SLOW! (96% del tiempo)
```

**AcciÃ³n**: Investigar por quÃ© Kafka tarda 1200ms (network issue? broker overloaded?)

---

#### **5. Buscar por Trace ID EspecÃ­fico**

**Caso de uso**: Un usuario reporta un error y te da el Trace ID de su request.

**Pasos**:

1. **Click en "Search"**

2. **Pegar Trace ID**:
   ```
   Trace ID: f47ac10b8c4211eb8dcd0242ac130003
   ```

3. **Click en "Run Query"**

4. **Ver traza completa**:
   - Timeline de todos los spans
   - Latencias de cada operaciÃ³n
   - Tags y annotations
   - Logs asociados (si estÃ¡n configurados)

---

#### **6. Analizar Dependencies (Service Map)**

**Objetivo**: Ver cÃ³mo se comunican los servicios entre sÃ­.

**Pasos**:

1. **Click en "Dependencies"** (menÃº superior)

2. **Seleccionar ventana de tiempo**:
   ```
   Lookback: Last hour
   ```

3. **Resultado**: Grafo de dependencias

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   hexarch   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º PostgreSQL (40ms avg)
       â”‚
       â””â”€â”€â–º Kafka (150ms avg)
              â”‚
              â””â”€â”€â–º notifications-service
                      â”‚
                      â””â”€â”€â–º EmailService (100ms avg)
```

**Insights**:
- Latencia promedio entre servicios
- NÃºmero de llamadas
- Error rate por conexiÃ³n
- Cuellos de botella visuales

---

#### **7. Comparar Trazas (Before vs After Optimization)**

**Caso de uso**: Optimizaste Kafka y quieres comparar el performance.

**Pasos**:

1. **Buscar trazas ANTES de la optimizaciÃ³n**:
   ```
   Service Name: hexarch
   Span Name: send user.created
   Lookback: Last 7 days (antes del deploy)
   ```
   - DuraciÃ³n promedio: `150ms`

2. **Buscar trazas DESPUÃ‰S de la optimizaciÃ³n**:
   ```
   Service Name: hexarch
   Span Name: send user.created
   Lookback: Last hour (despuÃ©s del deploy)
   ```
   - DuraciÃ³n promedio: `50ms`

3. **Resultado**: Mejora del 67% (de 150ms â†’ 50ms) âœ…

---

### **Ejemplo PrÃ¡ctico: Troubleshooting de un Error Real**

**Escenario**: Un usuario reporta que no recibe el email de bienvenida.

#### **Paso 1: Obtener el Trace ID**

**OpciÃ³n A**: Del log de la aplicaciÃ³n
```bash
# Buscar en logs por email del usuario
grep "john@example.com" /var/log/hexarch/application.log

# Output:
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - Creating user: email=john@example.com
```

**OpciÃ³n B**: Del response HTTP (si lo incluyes en headers)
```bash
curl -v http://localhost:8080/api/v1/users ...
< X-Trace-Id: f47ac10b8c4211eb8dcd0242ac130003
```

---

#### **Paso 2: Buscar la Traza en Zipkin**

1. Pegar Trace ID en Zipkin: `f47ac10b8c4211eb8dcd0242ac130003`
2. Click "Run Query"

---

#### **Paso 3: Analizar el Timeline**

**Resultado en Zipkin**:
```
POST /api/v1/users - 295ms âœ…
  â”œâ”€ CreateUserService - 290ms âœ…
  â”‚  â”œâ”€ INSERT users - 40ms âœ…
  â”‚  â””â”€ send user.created - 150ms âœ…
  â””â”€ poll user.created - MISSING âŒ â† El consumer no procesÃ³ el mensaje!
```

**ObservaciÃ³n**: El mensaje se enviÃ³ a Kafka correctamente, pero NO hay span del consumer.

---

#### **Paso 4: Investigar el Consumer**

**Posibles causas**:
1. âœ… **Consumer no estÃ¡ corriendo** â†’ Revisar `docker-compose ps`
2. âœ… **Consumer tiene errores** â†’ Revisar logs del consumer
3. âœ… **Message en Dead Letter Topic** â†’ Revisar topic `user.created.dlt`
4. âœ… **Circuit Breaker OPEN** â†’ EmailService estÃ¡ fallando

**Verificar logs del consumer**:
```bash
docker-compose logs notifications-service | grep "john@example.com"

# Output:
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,5e6f7a8b9cdef012] ERROR - Circuit breaker OPEN - Email no enviado a john@example.com
```

**Root Cause Encontrado**: Circuit Breaker estÃ¡ OPEN porque el servicio de email (SendGrid, SES, etc.) estÃ¡ caÃ­do.

---

#### **Paso 5: Verificar Circuit Breaker**

```bash
# Revisar mÃ©tricas de Circuit Breaker
curl http://localhost:8080/actuator/metrics/resilience4j.circuitbreaker.state

{
  "name": "resilience4j.circuitbreaker.state",
  "measurements": [
    { "statistic": "VALUE", "value": 1.0 }  // 1.0 = OPEN
  ],
  "availableTags": [
    { "tag": "name", "values": ["emailService"] }
  ]
}
```

**Confirmado**: Circuit Breaker estÃ¡ OPEN.

---

#### **Paso 6: SoluciÃ³n**

1. **Verificar servicio externo** (SendGrid, SES): Â¿EstÃ¡ disponible?
2. **Esperar a que Circuit Breaker pase a HALF_OPEN** (despuÃ©s de `wait-duration`)
3. **Reprocesar mensajes del DLT** (Dead Letter Topic) cuando el servicio se recupere

---

### **ConfiguraciÃ³n de Sampling (ProducciÃ³n)**

En producciÃ³n, **no trackees el 100% de los requests** (overhead alto).

**Recomendaciones de sampling**:

| TrÃ¡fico | Sampling Rate | JustificaciÃ³n |
|---------|---------------|---------------|
| **< 100 req/s** | `1.0` (100%) | Bajo overhead, trackea todo |
| **100-1000 req/s** | `0.1` (10%) | Balance entre overhead y visibilidad |
| **> 1000 req/s** | `0.01` (1%) | Solo para identificar patrones, no debugging individual |

**ConfiguraciÃ³n en `application.yaml`**:
```yaml
management:
  tracing:
    sampling:
      probability: ${TRACING_SAMPLING_RATE:0.1}  # 10% por defecto
```

**Variables de entorno por environment**:
```bash
# Local/Dev: 100% sampling
TRACING_SAMPLING_RATE=1.0

# Staging: 50% sampling
TRACING_SAMPLING_RATE=0.5

# Production: 10% sampling
TRACING_SAMPLING_RATE=0.1

# Production (alta carga): 1% sampling
TRACING_SAMPLING_RATE=0.01
```

---

### **Mejores PrÃ¡cticas de Tracing**

#### **1. AÃ±adir Tags Custom en Spans**

**Tags Ãºtiles**:
```java
@Service
public class CreateUserService {

    private final Tracer tracer;

    public UserResult execute(CreateUserCommand command) {
        // Obtener span actual
        Span span = tracer.currentSpan();

        if (span != null) {
            // AÃ±adir tags de negocio
            span.tag("user.username", command.username());
            span.tag("user.email", command.email());
            span.tag("business.operation", "user-registration");
        }

        // ... resto de la lÃ³gica
    }
}
```

**Beneficio**: Filtrar en Zipkin por `user.username=johndoe` o `business.operation=user-registration`.

---

#### **2. Propagar Trace ID en Responses HTTP**

**AÃ±ade el Trace ID al response header** para que el cliente pueda reportarlo en caso de error.

**CÃ³digo** (`GlobalResponseFilter.java`):
```java
@Component
public class TraceIdResponseFilter implements Filter {

    private final Tracer tracer;

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
            throws IOException, ServletException {

        HttpServletResponse httpResponse = (HttpServletResponse) response;

        // Obtener Trace ID actual
        Span span = tracer.currentSpan();
        if (span != null) {
            String traceId = span.context().traceId();
            httpResponse.setHeader("X-Trace-Id", traceId);
        }

        chain.doFilter(request, response);
    }
}
```

**Response**:
```http
HTTP/1.1 201 Created
X-Trace-Id: f47ac10b8c4211eb8dcd0242ac130003
Content-Type: application/json
...
```

**Beneficio**: El cliente puede reportar el Trace ID en soporte: "Mi request con Trace ID `f47ac10b...` fallÃ³".

---

#### **3. Logging con Trace ID**

Micrometer Tracing **automÃ¡ticamente aÃ±ade Trace ID y Span ID a los logs** (ya estÃ¡ configurado en este proyecto).

**Log format en `logback-spring.xml`**:
```xml
<pattern>%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %5p - %m%n</pattern>
```

**Output**:
```
2024-01-15 10:30:00 [f47ac10b8c4211eb8dcd0242ac130003,2b3c4d5e6f7a8b9c] INFO - User created: userId=550e8400
```

**Beneficio**: Correlacionar logs con trazas en Zipkin.

---

#### **4. Monitorizar Latencias con Alertas**

**Crear alerta en Grafana**:
```promql
# Latencia p99 de POST /api/v1/users > 500ms
histogram_quantile(0.99,
  rate(http_server_requests_seconds_bucket{
    uri="/api/v1/users",
    method="POST"
  }[5m])
) > 0.5
```

**AcciÃ³n**: Si se dispara, buscar trazas en Zipkin con `Min Duration: 500ms` para identificar el cuello de botella.

---

## Correlation ID: Tracing de Negocio

### **Â¿QuÃ© es Correlation ID?**

**Correlation ID** es un **identificador de negocio** que:
- Correlaciona logs entre mÃºltiples servicios
- Es independiente de Trace ID (tÃ©cnico)
- Se propaga en header HTTP: `X-Correlation-ID`

**Diferencias**:

| Concepto | PropÃ³sito | Scope | Ejemplo |
|----------|-----------|-------|---------|
| **Trace ID** | Tracing tÃ©cnico | Request HTTP completo | `f47ac10b-8c42-11eb` |
| **Correlation ID** | Tracing de negocio | Proceso completo (mÃºltiples requests) | `order-2024-001` |

**Ejemplo**:
```
Usuario hace pedido:
1. POST /orders â†’ correlationId: order-2024-001
2. Kafka: OrderCreatedEvent â†’ correlationId: order-2024-001
3. Payment Service procesa â†’ correlationId: order-2024-001
4. Notification Service envÃ­a email â†’ correlationId: order-2024-001

Buscar logs: "order-2024-001" â†’ Ves TODO el flujo
```

---

### **ImplementaciÃ³n en Hexarch**

**`CorrelationIdFilter.java`**:
```java
@Component
@Order(1) // Ejecutar PRIMERO
@Slf4j
public class CorrelationIdFilter extends OncePerRequestFilter {

    private static final String CORRELATION_ID_HEADER = "X-Correlation-ID";
    private static final String CORRELATION_ID_MDC_KEY = "correlationId";

    @Override
    protected void doFilterInternal(
            HttpServletRequest request,
            HttpServletResponse response,
            FilterChain filterChain
    ) throws ServletException, IOException {

        // 1. Obtener o generar Correlation ID
        String correlationId = extractOrGenerateCorrelationId(request);

        // 2. AÃ±adir al MDC para logs
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId);

        // 3. AÃ±adir header a response
        response.setHeader(CORRELATION_ID_HEADER, correlationId);

        try {
            filterChain.doFilter(request, response);
        } finally {
            // 4. Limpiar MDC (evita memory leaks)
            MDC.remove(CORRELATION_ID_MDC_KEY);
        }
    }

    private String extractOrGenerateCorrelationId(HttpServletRequest request) {
        String correlationId = request.getHeader(CORRELATION_ID_HEADER);

        if (correlationId == null || correlationId.isBlank()) {
            correlationId = UUID.randomUUID().toString();
            log.debug("Generated new Correlation ID: {}", correlationId);
        } else {
            log.debug("Using existing Correlation ID: {}", correlationId);
        }

        return correlationId;
    }
}
```

**Uso**:
```bash
# Request CON Correlation ID
curl -H "X-Correlation-ID: my-custom-id-123" \
     http://localhost:8080/api/v1/users/550e8400

# Logs:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - Fetching user: 550e8400
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] my-custom-id-123 INFO - User found: johndoe

# Request SIN Correlation ID (se genera automÃ¡ticamente)
curl http://localhost:8080/api/v1/users/550e8400

# Response header:
X-Correlation-ID: 7c3e1f2a-9b8d-4e7f-a1c2-3d4e5f6a7b8c
```

---

## GestiÃ³n de Logs: ELK vs Loki

### **Â¿DÃ³nde ver los logs?**

#### **Desarrollo Local** ğŸ–¥ï¸
Los logs se muestran en la **consola** (stdout):
```bash
./mvnw spring-boot:run
# Ves logs en tiempo real:
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO - User created: userId=123
```

#### **ProducciÃ³n** ğŸ¢
En producciÃ³n necesitas **agregaciÃ³n de logs** porque:
- âŒ MÃºltiples instancias (10+ pods) â†’ No puedes hacer `kubectl logs` en cada uno
- âŒ Logs efÃ­meros â†’ Si el pod muere, los logs se pierden
- âŒ Sin bÃºsqueda â†’ No puedes buscar "todos los logs con correlationId=X"

**SoluciÃ³n**: Sistema centralizado de logs

---

### **OpciÃ³n 1: ELK Stack (Elasticsearch + Logstash + Kibana)** ğŸ”¥

**Componentes**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   App       â”‚â”€â”€â”€â”€â–¶â”‚  Logstash    â”‚â”€â”€â”€â”€â–¶â”‚ Elasticsearch   â”‚â—€â”€â”€â”€â”€â”‚ Kibana  â”‚
â”‚ (Spring)    â”‚     â”‚ (Procesa)    â”‚     â”‚ (Almacena)      â”‚     â”‚ (UI)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- âœ… Muy maduro (10+ aÃ±os en producciÃ³n)
- âœ… BÃºsqueda full-text potente (encuentra cualquier palabra en logs)
- âœ… Dashboards ricos en Kibana
- âœ… IntegraciÃ³n con APM, Machine Learning, alertas avanzadas

**Contras**:
- âŒ **Pesado**: Elasticsearch consume ~2GB RAM mÃ­nimo
- âŒ **Complejo**: Requiere expertise para configurar/mantener
- âŒ **Costoso**: Infraestructura cara a escala

**CuÃ¡ndo usar**:
- Empresas grandes con equipo dedicado
- Necesitas bÃºsqueda full-text avanzada
- Ya tienes Elasticsearch en la empresa

---

### **OpciÃ³n 2: Grafana Loki + Promtail** â­ **Recomendado**

**Componentes**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   App       â”‚â”€â”€â”€â”€â–¶â”‚  Promtail    â”‚â”€â”€â”€â”€â–¶â”‚     Loki        â”‚
â”‚ (Spring)    â”‚     â”‚ (Agente)     â”‚     â”‚ (Almacena)      â”‚
â”‚  stdout     â”‚     â”‚ Lee logs     â”‚     â”‚ Logs indexados  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚    Grafana      â”‚
                                          â”‚ Logs + MÃ©tricas â”‚
                                          â”‚    + Traces     â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- âœ… **Ligero**: ~200MB RAM (10x menos que Elasticsearch)
- âœ… **Simple**: ConfiguraciÃ³n mÃ­nima
- âœ… **Unified Observability**: Todo en Grafana (logs + mÃ©tricas + traces)
- âœ… **CorrelaciÃ³n fÃ¡cil**: Ver logs y mÃ©tricas del mismo timestamp
- âœ… **Gratis y open-source**

**Contras**:
- âŒ No hace bÃºsqueda full-text (usa labels e Ã­ndices)
- âŒ Menos features que Kibana (pero suficientes para 90% casos)

**CuÃ¡ndo usar**:
- Proyectos pequeÃ±os/medianos
- Quieres simplicidad
- Ya usas Grafana para mÃ©tricas (sinergia)

**Diferencia clave**:
- **Elasticsearch**: Indexa TODO el texto â†’ Puedes buscar cualquier palabra
- **Loki**: Indexa solo labels (app, level, host) â†’ MÃ¡s rÃ¡pido y ligero

---

### **Comparativa RÃ¡pida**

| Aspecto | ELK Stack | Loki + Grafana |
|---------|-----------|----------------|
| **Setup** | Complejo | Simple |
| **RAM** | ~2GB+ | ~200MB |
| **BÃºsqueda** | Full-text | Labels + grep |
| **UI** | Kibana | Grafana |
| **Curva aprendizaje** | Alta | Baja |
| **Costo infra** | Alto | Bajo |
| **Observability** | Solo logs | Logs + MÃ©tricas + Traces |

---

## Setup Local

### **Docker Compose completo (con Loki)**

**`docker-compose-observability.yml`**:
```yaml
version: '3.8'

services:
  # PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hexarch_db
      POSTGRES_USER: hexarch
      POSTGRES_PASSWORD: hexarch123
    ports:
      - "5432:5432"

  # Kafka + Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Prometheus (mÃ©tricas)
  prometheus:
    image: prom/prometheus:v2.50.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'

  # Loki (almacena logs)
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml

  # Promtail (envÃ­a logs a Loki)
  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml
      - ./logs:/var/log/hexarch  # Logs de la app
    command: -config.file=/etc/promtail/config.yml

  # Grafana (dashboards: logs + mÃ©tricas + traces)
  grafana:
    image: grafana/grafana:10.3.0
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources

  # Zipkin (distributed tracing)
  zipkin:
    image: openzipkin/zipkin:3.0
    ports:
      - "9411:9411"
```

---

### **ConfiguraciÃ³n de Loki**

**`monitoring/loki/loki-config.yml`**:
```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 168h

storage_config:
  boltdb:
    directory: /tmp/loki/index
  filesystem:
    directory: /tmp/loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: false
  retention_period: 0s
```

---

### **ConfiguraciÃ³n de Promtail**

**`monitoring/promtail/promtail-config.yml`**:
```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Logs de Hexarch (Spring Boot)
  - job_name: hexarch
    static_configs:
      - targets:
          - localhost
        labels:
          job: hexarch
          app: hexarch-user-service
          __path__: /var/log/hexarch/spring.log

    # Pipeline para parsear logs
    pipeline_stages:
      # Regex para extraer campos del log
      - regex:
          expression: '^(?P<timestamp>\S+\s+\S+) \[(?P<traceId>[^\,]+),(?P<spanId>[^\]]+)\] (?P<correlationId>\S+) (?P<level>\S+)\s+-\s+(?P<message>.*)$'

      # Extraer labels para indexar (bÃºsquedas rÃ¡pidas)
      - labels:
          level:
          traceId:
          correlationId:

      # Timestamp del log
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05'
```

---

### **ConfiguraciÃ³n de Grafana Datasources**

**`monitoring/grafana/datasources/datasources.yml`**:
```yaml
apiVersion: 1

datasources:
  # Prometheus (mÃ©tricas)
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: false

  # Loki (logs)
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
    jsonData:
      maxLines: 1000

  # Zipkin (traces)
  - name: Zipkin
    type: zipkin
    access: proxy
    url: http://zipkin:9411
```

---

### **Configurar Spring Boot para escribir logs a archivo**

**`application.yaml`**:
```yaml
logging:
  file:
    name: logs/spring.log  # Promtail leerÃ¡ de aquÃ­
    max-size: 100MB
    max-history: 30  # Mantener 30 dÃ­as

  pattern:
    # Mismo formato que consola (para parsear con Promtail)
    file: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
    console: "%d{yyyy-MM-dd HH:mm:ss} [%X{traceId},%X{spanId}] %X{correlationId} %5p - %msg%n"
```

---

### **Comandos**

```bash
# 1. Crear directorios
mkdir -p monitoring/{loki,promtail,grafana/datasources,prometheus}
mkdir -p logs

# 2. Crear archivos de configuraciÃ³n (copiar YAML de arriba)

# 3. Levantar infraestructura
docker-compose -f docker-compose-observability.yml up -d

# 4. Verificar servicios
docker-compose ps

# 5. Ejecutar aplicaciÃ³n
./mvnw spring-boot:run

# 6. Acceder a UIs
# Prometheus: http://localhost:9090
# Grafana:    http://localhost:3000 (admin/admin)
# Zipkin:     http://localhost:9411
# Loki API:   http://localhost:3100/metrics
```

---

## Buscar Logs en Grafana

### **1. Acceder a Grafana**
```
http://localhost:3000
Login: admin / admin
```

### **2. Ir a Explore**
```
MenÃº lateral â†’ Explore (Ã­cono de brÃºjula)
Datasource: Loki
```

### **3. Ejemplos de Queries LogQL**

#### **Todos los logs de la app**:
```logql
{job="hexarch"}
```

#### **Solo logs de ERROR**:
```logql
{job="hexarch", level="ERROR"}
```

#### **Buscar por Correlation ID**:
```logql
{job="hexarch", correlationId="550e8400-e29b-41d4"}
```

#### **Buscar por Trace ID**:
```logql
{job="hexarch", traceId="f47ac10b"}
```

#### **Filtrar por contenido (grep-like)**:
```logql
{job="hexarch"} |= "User created"
```

#### **Logs de los Ãºltimos 5 minutos con ERROR**:
```logql
{job="hexarch", level="ERROR"} [5m]
```

#### **Contar errores por minuto**:
```logql
rate({job="hexarch", level="ERROR"}[1m])
```

---

### **4. CorrelaciÃ³n: Logs + MÃ©tricas + Traces**

**Escenario**: Usuario reporta "la creaciÃ³n de usuario estÃ¡ lenta"

**Paso 1**: Ver mÃ©trica de latencia
```
Datasource: Prometheus
Query: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket{uri="/api/v1/users"}[5m]))
```

**Paso 2**: Identificar request lento
```
Datasource: Zipkin
Search: minDuration > 500ms
```

**Paso 3**: Ver logs de ese trace
```
Datasource: Loki
Query: {job="hexarch", traceId="f47ac10b"}
```

**Resultado**: Ves TODA la historia del request lento ğŸ¯

---

### **5. Dashboard Unificado en Grafana**

**Panel 1: MÃ©tricas**
```
Requests/sec, Error rate, Latency p99
```

**Panel 2: Logs en tiempo real**
```logql
{job="hexarch"} | level="ERROR"
```

**Panel 3: Trace spans**
```
Zipkin: requests mÃ¡s lentos
```

**Captura de pantalla** (ejemplo):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hexarch Observability Dashboard          [Last 15 min â–¼]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š MÃ‰TRICAS                                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚ â”‚ Req/s   â”‚ â”‚ Errors  â”‚ â”‚ p99     â”‚ â”‚ Users   â”‚          â”‚
â”‚ â”‚  42     â”‚ â”‚  0.5%   â”‚ â”‚ 120ms   â”‚ â”‚  1,234  â”‚          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                            â”‚
â”‚ ğŸ“ LOGS (Ãºltimos 50)                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ 10:30:00 [f47ac] 550e INFO  - User created: id=123  â”‚  â”‚
â”‚ â”‚ 10:30:01 [a23bc] 7f2a WARN  - Retry attempt 2/3     â”‚  â”‚
â”‚ â”‚ 10:30:02 [c45de] 9d4b ERROR - Email send failed     â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                            â”‚
â”‚ ğŸ”— TRACES (slowest 10)                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ POST /users - 520ms [Ver span timeline]             â”‚  â”‚
â”‚ â”‚ GET /users/123 - 380ms [Ver span timeline]          â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Soluciones Cloud (Managed)

Si tu empresa usa **cloud providers**, puedes usar servicios managed que eliminan el trabajo de mantener la infraestructura:

### **AWS**

**CloudWatch**:
- **CloudWatch Logs**: Almacena logs de ECS/EKS/Lambda
- **CloudWatch Metrics**: MÃ©tricas custom + mÃ©tricas de AWS services
- **CloudWatch Insights**: Queries sobre logs (SQL-like)
- **X-Ray**: Distributed tracing

**Setup**:
```yaml
# application.yaml
logging:
  config: classpath:logback-spring-cloudwatch.xml

management:
  metrics:
    export:
      cloudwatch:
        namespace: Hexarch
        enabled: true
```

**Pros**:
- âœ… Cero mantenimiento
- âœ… IntegraciÃ³n nativa con servicios AWS
- âœ… Escalabilidad automÃ¡tica

**Contras**:
- âŒ Caro a escala (factura por GB de logs)
- âŒ UI no tan buena como Grafana/Kibana
- âŒ Vendor lock-in

---

### **Azure**

**Azure Monitor**:
- **Log Analytics**: Logs centralizados (usa KQL query language)
- **Application Insights**: APM + distributed tracing
- **Metrics**: MÃ©tricas custom

**Setup**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>com.microsoft.azure</groupId>
    <artifactId>applicationinsights-spring-boot-starter</artifactId>
</dependency>
```

```yaml
# application.yaml
azure:
  application-insights:
    instrumentation-key: ${APPINSIGHTS_INSTRUMENTATIONKEY}
```

---

### **Google Cloud Platform**

**Cloud Logging (antes Stackdriver)**:
- Logs centralizados
- IntegraciÃ³n con GKE, Cloud Run, App Engine
- Queries con Log Explorer

**Cloud Trace**: Distributed tracing

---

### **Datadog / New Relic / Splunk** ğŸ’°

Soluciones **SaaS todo-en-uno**:

**Datadog**:
```yaml
# application.yaml
management:
  metrics:
    export:
      datadog:
        api-key: ${DD_API_KEY}
        application-key: ${DD_APP_KEY}
        enabled: true
```

**Pros**:
- âœ… UI excelente (mejor que cloud providers)
- âœ… APM + Logs + MÃ©tricas + Traces unificado
- âœ… Alerting avanzado
- âœ… Machine Learning para anomaly detection

**Contras**:
- âŒ **Muy caro**: $15-50 USD/host/mes
- âŒ Vendor lock-in

**CuÃ¡ndo usar**: Empresas con presupuesto que quieren lo mejor sin complicaciones

---

### **Comparativa: On-Premise vs Cloud**

| Aspecto | Loki/ELK (Self-hosted) | Cloud Managed (AWS/Azure/GCP) | SaaS (Datadog/New Relic) |
|---------|------------------------|-------------------------------|--------------------------|
| **Costo** | Infra + tiempo de setup | Pay-per-use (puede ser caro) | Caro (~$20/host/mes) |
| **Mantenimiento** | TÃº lo mantienes | Proveedor cloud | Proveedor SaaS |
| **Escalabilidad** | Manual | AutomÃ¡tica | AutomÃ¡tica |
| **UI** | Grafana/Kibana (muy buena) | BÃ¡sica | Excelente |
| **Vendor Lock-in** | âŒ No | âš ï¸ Medio | âœ… SÃ­ |
| **Setup** | Complejo | Medio | Simple (agente) |

---

### **RecomendaciÃ³n segÃºn contexto**

#### **Startup/Proyecto personal**:
â†’ **Grafana Loki** (gratis, simple, suficiente)

#### **Empresa pequeÃ±a/mediana** (< 50 servicios):
â†’ **Loki** si tienes DevOps o **CloudWatch/Azure Monitor** si usas cloud

#### **Empresa grande** (50+ servicios):
â†’ **ELK Stack** (self-hosted) o **Datadog** (si tienes presupuesto)

#### **Regulaciones estrictas** (banca, salud):
â†’ **ELK on-premise** (control total de datos)

---

## Mejores PrÃ¡cticas de Logs en ProducciÃ³n

### **1. Structured Logging (JSON)**

**Problema**: Logs de texto son difÃ­ciles de parsear
```
2024-01-15 10:30:00 User johndoe created with ID 123
```

**SoluciÃ³n**: JSON structured logs
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "traceId": "f47ac10b",
  "correlationId": "550e8400",
  "message": "User created",
  "userId": "123",
  "username": "johndoe"
}
```

**Configurar en Spring Boot**:
```xml
<!-- pom.xml -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

```xml
<!-- logback-spring.xml -->
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
        <includeMdcKeyName>traceId</includeMdcKeyName>
        <includeMdcKeyName>spanId</includeMdcKeyName>
        <includeMdcKeyName>correlationId</includeMdcKeyName>
    </encoder>
</appender>
```

**Beneficio**: FÃ¡cil de parsear y buscar en Elasticsearch/Loki

---

### **2. Log Retention Policy**

**No guardes logs para siempre** (costoso y poco Ãºtil):

| Tipo | Retention | RazÃ³n |
|------|-----------|-------|
| **DEBUG** | 1 dÃ­a | Solo para troubleshooting activo |
| **INFO** | 30 dÃ­as | Suficiente para anÃ¡lisis reciente |
| **WARN** | 90 dÃ­as | Detectar problemas recurrentes |
| **ERROR** | 180 dÃ­as | Cumplimiento y anÃ¡lisis de incidentes |

**Configurar en Loki**:
```yaml
limits_config:
  retention_period: 720h  # 30 dÃ­as
```

**Configurar en Elasticsearch**:
```bash
# Borrar Ã­ndices mÃ¡s viejos de 30 dÃ­as
curator delete indices --older-than 30 --time-unit days
```

---

### **3. Log Sampling**

**Problema**: Demasiados logs en producciÃ³n (millones/dÃ­a)

**SoluciÃ³n**: Sample logs de INFO, loguea todos los ERROR

```java
@Component
public class SamplingLogger {

    private final Logger log = LoggerFactory.getLogger(SamplingLogger.class);
    private final Random random = new Random();
    private final double sampleRate = 0.1; // 10%

    public void infoSampled(String message, Object... args) {
        if (random.nextDouble() < sampleRate) {
            log.info(message, args);
        }
    }

    public void error(String message, Throwable ex) {
        log.error(message, ex);  // SIEMPRE loguea errores
    }
}
```

---

### **4. Sensitive Data Masking**

**NUNCA loguees datos sensibles**:
- âŒ Passwords
- âŒ NÃºmeros de tarjeta de crÃ©dito
- âŒ API keys / tokens
- âŒ PII (Personally Identifiable Information): SSN, DNI, etc.

**MAL**:
```java
log.info("User login: username={}, password={}", username, password);  // âŒ NUNCA
```

**BIEN**:
```java
log.info("User login: username={}", username);  // âœ… Sin password

// Si necesitas loguear email (PII), enmascara
log.info("User created: email={}", maskEmail(email));
// Output: "User created: email=j***@example.com"
```

**Enmascarar automÃ¡ticamente**:
```java
public class SensitiveDataConverter extends ClassicConverter {
    private static final Pattern EMAIL = Pattern.compile("([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})");

    @Override
    public String convert(ILoggingEvent event) {
        String message = event.getFormattedMessage();
        return EMAIL.matcher(message).replaceAll("***@$2");
    }
}
```

---

### **5. Correlation ID Best Practices**

**Propagar Correlation ID a TODOS los servicios downstream**:

```java
@Component
public class RestTemplateInterceptor implements ClientHttpRequestInterceptor {

    @Override
    public ClientHttpResponse intercept(
            HttpRequest request,
            byte[] body,
            ClientHttpRequestExecution execution
    ) throws IOException {

        // Obtener Correlation ID del MDC
        String correlationId = MDC.get("correlationId");

        // AÃ±adirlo al header del request saliente
        if (correlationId != null) {
            request.getHeaders().add("X-Correlation-ID", correlationId);
        }

        return execution.execute(request, body);
    }
}
```

**Resultado**: Puedes trazar un request a travÃ©s de 10+ microservicios con un solo ID ğŸ¯

---

### **6. Log Levels en ProducciÃ³n**

**ConfiguraciÃ³n recomendada**:
```yaml
logging:
  level:
    root: INFO  # Default para todo

    # Tu aplicaciÃ³n: INFO
    com.example.hexarch: INFO

    # LibrerÃ­as externas: WARN (reducir ruido)
    org.springframework: WARN
    org.hibernate: WARN
    com.zaxxer.hikari: WARN

    # DEBUG solo para troubleshooting
    # com.example.hexarch.user.infrastructure: DEBUG  # Descomentar si necesitas debug
```

**Cambio dinÃ¡mico** (sin reiniciar app):
```bash
# Activar DEBUG temporalmente para un package
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "DEBUG"}'

# Volver a INFO
curl -X POST http://localhost:8080/actuator/loggers/com.example.hexarch.user \
  -H "Content-Type: application/json" \
  -d '{"configuredLevel": "INFO"}'
```

---

## Ejemplos PrÃ¡cticos en el CÃ³digo

### **UbicaciÃ³n en Hexarch**

```
src/main/java/
â”œâ”€â”€ user/
â”‚   â””â”€â”€ application/
â”‚       â””â”€â”€ service/
â”‚           â””â”€â”€ CreateUserUseCase.java       â† Logs INFO + MÃ©trica counter
â”‚
â”œâ”€â”€ notifications/
â”‚   â””â”€â”€ application/
â”‚       â””â”€â”€ service/
â”‚           â””â”€â”€ EmailService.java            â† Logs WARN/ERROR + Timer metric
â”‚
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ infrastructure/
â”‚       â””â”€â”€ web/
â”‚           â””â”€â”€ CorrelationIdFilter.java     â† Correlation ID propagation
â”‚
â””â”€â”€ config/
    â””â”€â”€ MetricsConfig.java                   â† MÃ©tricas customizadas
```

---

### **Ver mÃ©tricas en acciÃ³n**

**1. Crear usuario**:
```bash
curl -X POST http://localhost:8080/api/v1/users \
  -H "Content-Type: application/json" \
  -d '{"username": "johndoe", "email": "john@example.com"}'
```

**2. Ver logs** (consola):
```
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Creating user: username=johndoe
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - User created: userId=123
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Publishing event: UserCreatedEvent
2024-01-15 10:30:00 [f47ac10b,1a2b3c4d] 550e8400 INFO  - Event published to Kafka topic: user.created
```

**3. Ver mÃ©tricas**:
```bash
curl http://localhost:8080/actuator/prometheus | grep users_created
# users_created_total{status="success",environment="local"} 1.0
```

**4. Ver trace en Zipkin**:
- URL: http://localhost:9411
- Buscar trace: `f47ac10b-8c42-11eb-8dcd-0242ac130003`
- Ver timeline de spans

---

## Alerting

### **Alertas en Prometheus**

**`monitoring/prometheus/alerts.yml`**:
```yaml
groups:
  - name: hexarch_alerts
    interval: 30s
    rules:
      # CPU alta
      - alert: HighCPUUsage
        expr: process_cpu_usage > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"

      # Error rate alta
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status=~"5.."}[5m]) / rate(http_server_requests_seconds_count[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}% (threshold: 5%)"

      # Latencia p99 alta
      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(http_server_requests_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p99 latency detected"
          description: "p99 latency is {{ $value }}s (threshold: 500ms)"
```

---

### **Notificaciones en Grafana**

**Configurar Slack**:
```yaml
# monitoring/grafana/alerting/notification-channels.yml
apiVersion: 1

notifiers:
  - name: slack
    type: slack
    uid: slack1
    settings:
      url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
      recipient: '#alerts'
      username: Grafana
```

---

## Checklist de Observabilidad

### âœ… **Logs**
- [x] Usar SLF4J + Logback
- [x] Formato estructurado con correlationId
- [x] Nivel correcto (INFO para eventos, ERROR para fallos)
- [x] NO logear la misma exception mÃºltiples veces
- [x] Incluir contexto (userId, traceId, correlationId)

### âœ… **MÃ©tricas**
- [x] Actuator habilitado con endpoint `/actuator/prometheus`
- [x] MÃ©tricas customizadas de negocio (users.created.total)
- [x] Tags para filtrar (environment, status)
- [x] Dashboards en Grafana

### âœ… **Trazas**
- [x] Micrometer Tracing configurado
- [x] Zipkin endpoint configurado
- [x] Sampling rate ajustado (100% dev, 10% prod)
- [x] Correlation ID propagado entre servicios

### âœ… **Alerting**
- [x] Alertas configuradas (CPU, error rate, latency)
- [x] Notificaciones a Slack/PagerDuty
- [x] Runbooks documentados (quÃ© hacer cuando alerta se dispara)

---

## Recursos

- [Micrometer Documentation](https://micrometer.io/docs)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Zipkin Documentation](https://zipkin.io/)
- [OpenTelemetry](https://opentelemetry.io/)
- [SLF4J Documentation](https://www.slf4j.org/manual.html)

---

**Ãšltima actualizaciÃ³n**: 2025-10-30
